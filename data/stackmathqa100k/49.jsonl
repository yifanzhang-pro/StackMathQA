{"Q": "Perfect numbers $n$ such that $2^k(n+1)$ is also perfect The smallest two perfect numbers $n=6$ and $m=28$ satisfy\n$$\n\\frac{m}{n+1} = 2^k\n$$\nwith $k=2.$\nQuestion: Are there more pairs of perfect numbers $n,m$  with $n < m$\nand such that\n$$\n\\frac{m}{n+1} = 2^k\n$$\nfor some positive integer $k>0.$\nObserve that the perfect number $n$ , the smallest of $n,m$\nmay be also an odd number.\n", "A": "[After typing out this attempt at a \"partial\" answer, I realized that the details have already been worked out by Luis, Gerhard and Todd.  I am posting it as an answer for anybody else who might be interested in how the final result is obtained. - Arnie]\nSuppose $m$ is even and $n$ is odd.\nThen if $m$ and $n$ are perfect numbers, we have the forms\n$$m = 2^{p-1}({2^p} - 1),$$\nwhere $p$ and ${2^p} - 1$ are primes, and\n$$n = {q^r}{s^2},$$\nwhere $q$ is prime with $q \\equiv r \\equiv 1 \\pmod 4$ and $\\gcd(q,s) = 1$.\nNow, from the additional constraint\n$$\\frac{m}{n + 1} = 2^k,$$\nwhere $k > 0$ is an integer, we obtain the equation\n$$m = {2^k}(n + 1).$$\nWriting out this last equation in full by plugging in the respective forms for $m$ and $n$ as before, we get\n$$2^{p-1}({2^p} - 1) = {2^k}({q^r}{s^2} + 1).$$\nBy divisibility considerations, since we can assume without loss of generality that $p \\geq 2$, $k \\geq 1$ and $r \\geq 1$, and since $n \\equiv 1 \\pmod 4$, we get\n$$\\gcd(2^{p-1}, {q^r}{s^2} + 1) = 2 \\Longrightarrow 2^{p-2} \\mid 2^k.$$\nSimilarly, $\\gcd({2^k},{2^p} - 1) = 1$ and $({q^r}{s^2} + 1) = n + 1 \\equiv 2 \\pmod 4 \\Longrightarrow 2^{k+1} \\mid 2^{p-1} \\Longrightarrow 2^k \\mid 2^{p-2}$.\nThus,\n$$2^k = 2^{p - 2}.$$\nThis gives\n$$k = p - 2.$$\nConsequently, we get\n$$\\frac{m}{n + 1} = 2^k = 2^{p-2} = \\frac{2^{p-1}({2^p} - 1)}{{q^r}{s^2} + 1},$$\nwhich yields\n$$\\frac{1}{2} = \\frac{2^p - 1}{{q^r}{s^2} + 1}.$$\nThis implies\n$${q^r}{s^2} + 1 = 2^{p+1} - 2.$$\nThis finally gives (as Gerhard, Todd and Luis had already noted)\n$${q^r}{s^2} = n = 2^{p+1} - 3.$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/64340", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "7", "answer_count": 2, "answer_id": 1}}
{"Q": "Trigonometric identity needed for sums involving secants I am looking for a closed-form formula for the following sum:\n$\\displaystyle \\sum_{k=0}^{N}{\\frac{\\sin^{2}(\\frac{k\\pi}{N})}{a \\cdot \\sin^{2}(\\frac{k\\pi}{N})+1}}=\\sum_{k=0}^{N}{\\frac{1}{a+\\csc^{2}(\\frac{k\\pi}{N})}}$.\nIs such a formula known?\n", "A": "This may not be of much (any!) help, but Mathematica 7 gives a closed-form solution in terms of QPolyGamma functions:\n$\\frac{\\psi _{e^{-\\frac{2 i \\pi }{n}}}^{(0)}\\left(1-\\frac{\\log\n   \\left(\\frac{a-2 \\sqrt{a+1}+2}{a}\\right)}{\\log \\left(e^{-\\frac{2 i\n   \\pi }{n}}\\right)}\\right)-\\psi _{e^{-\\frac{2 i \\pi\n   }{n}}}^{(0)}\\left(n-\\frac{\\log \\left(\\frac{a-2\n   \\sqrt{a+1}+2}{a}\\right)}{\\log \\left(e^{-\\frac{2 i \\pi\n   }{n}}\\right)}+1\\right)+\\sqrt{a+1} n \\log \\left(e^{-\\frac{2 i \\pi\n   }{n}}\\right)}{a \\sqrt{a+1} \\log \\left(e^{-\\frac{2 i \\pi\n   }{n}}\\right)}$\n$+$\n$\\frac{\\psi _{e^{-\\frac{2 i \\pi }{n}}}^{(0)}\\left(n-\\frac{\\log\n   \\left(\\frac{a+2 \\sqrt{a+1}+2}{a}\\right)}{\\log \\left(e^{-\\frac{2 i\n   \\pi }{n}}\\right)}+1\\right)-\\psi _{e^{-\\frac{2 i \\pi\n   }{n}}}^{(0)}\\left(1-\\frac{\\log \\left(\\frac{a+2\n   \\sqrt{a+1}+2}{a}\\right)}{\\log \\left(e^{-\\frac{2 i \\pi\n   }{n}}\\right)}\\right)}{a \\sqrt{a+1} \\log \\left(e^{-\\frac{2 i \\pi\n   }{n}}\\right)}$\n$\\psi^{(0)}_q$ is the q-PolyGamma function. \n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/122231", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 3, "answer_id": 2}}
{"Q": "Weiestrass Form  How to convert this to weiestrass form?\n$x^{2}y^{2}-2\\left( 1+2\\rho \\right) xy^{2}+y^{2}-x^{2}-2\\left( 1+2\\rho\n\\right) x-1=0$\n", "A": "You can rewrite the form as\n\\begin{equation*}\ny^2=\\frac{x^2+2(2\\rho+1)x+1}{x^2-2(2\\rho+1)x+1}\n\\end{equation*}\nso, for rational solutions (which I presume you want), there exists $z \\in \\mathbb{Q}$ with\n\\begin{equation*}\nz^2=(x^2+2(2\\rho+1)x+1)(x^2-2(\\rho+1)x+1)=x^4-2(8\\rho^2+8\\rho+1)x^2+1\n\\end{equation*}\nThis quartic can be transformed to an equivalent elliptic curve using the method described by Mordell in his book Diophantine Equations. We get (after some fiddling)\n\\begin{equation*}\nv^2=u(u+4\\rho^2+4\\rho)(u+4\\rho^2+4\\rho+1)\n\\end{equation*}\nwith $x=v/u$.\nFor example, $\\rho=11$ gives a rank $1$ elliptic curve with point $(147,8190)$, giving $x=8190/147$ and $y=\\pm 527/163$.\nThis elliptic curve could be transformed to Weierstrass form if you want, but the above form is probably more useful.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/130893", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "How many solutions to $2^a + 3^b = 2^c + 3^d$? A few weeks ago, I asked on math.stackexchange.com how many quadruples of non-negative integers $(a,b,c,d)$  satisfy the following equation:\n$$2^a + 3^b = 2^c + 3^d \\quad (a \\neq c)$$\nI found 5 quadruples:  $5 = 2^2 + 3^0 = 2^1 + 3^1$, $11 = 2^3 + 3^1 = 2^1 + 3^2$, $17 = 2^4 + 3^0 = 2^3 + 3^2$, $35 = 2^5 + 3^1 = 2^3 + 3^3$, $259 = 2^8 + 3^1 = 2^4 + 3^5$\nI didn't get an answer, but only a link to an OEIS sequence (no more quadruples below $10^{4000}$), so I'm asking the same question here. \n\nIs there a way to prove that they are [not] infinite?\n\nAnd, more generally, are there known tuples for which the following equation:\n$$p_{i_1}^{a_1} + p_{i_2}^{a_2} + ... + p_{i_n}^{a_n}=p_{i_1}^{b_1} + p_{i_2}^{b_2} + ... + p_{i_n}^{b_n}$$\nholds for infinitely many  (or holds only for finitely many) $a_i,b_i$?\n", "A": "Here is a proof of finiteness, along the lines of Jordan's answer.  Assume without loss that $a>c$ and $d>b$.  Then\n$$2^a-2^c=3^d-3^b,$$\nor equivalently\n$$\\frac{1-3^{b-d}}{1-2^{c-a}}=\\frac{2^a}{3^d}.$$\nSince $a>d$, Matveev's explicit bound for linear forms in logarithms implies that\n$$\\Bigl\\lvert\\frac{2^{c-a}-3^{b-d}}{1-2^{c-a}}\\Bigr\\rvert=\\lvert 2^a 3^{-d}-1\\rvert \\ge (ea)^{-R}$$\nwhere \n$$\nR:=e\\cdot 2^{3.5}30^5\\log 3.$$\nNext, $2^c$ is the largest power of $2$ which divides $3^{d-b}-1$; if $2^i$ denotes the largest power of $2$ which divides $d-b$, then either $[i=0\\,\\text{ and }\\,c=1]$ or $[i>0\\,\\text{ and }\\,c=i+2]$.  Likewise, $b=0$ if and only if $a\\not\\equiv c\\pmod{2}$; and if $a\\equiv c\\pmod{2}$ then $3^{b-1}$ is the largest power of $3$ which divides $a-c$.  So in any case we have $c\\le 2+\\log_2(d-b)$ and\n$b\\le 1+\\log_3(a-c)$.  For any fixed value of $d$ there are only finitely many possibilities for $a$ (since $2^{a-1}\\le 2^a-2^c<3^d$), and hence also for $b$ and $c$.  So assume that $d$ (and hence $a$) is sufficiently large; then $c\\le 2+\\log_2(d)<2+\\log_2(a)$ and $b\\le 1+\\log_3(a)$ while $\\log_3(2^{a-1})<d$, so $b\\le\\log_3(d)+r$ for some absolute constant $r$.  Now\n$$\\Bigl\\lvert\\frac{2^{c-a}-3^{b-d}}{1-2^{c-a}}\\Bigr\\rvert$$\nis at most roughly $2^{-a}$, which is smaller than $(ea)^{-R}$ whenever $a$ is sufficiently large.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/164624", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "11", "answer_count": 6, "answer_id": 0}}
{"Q": "Combinatorial identity involving the square of $\\binom{2n}{n}$ Is there any closed formula for \n$$\n\\sum_{k=0}^n\\frac{\\binom{2k}{k}^2}{2^{4k}}\n$$\n?\nThis sum of is made out of the square of terms $a_{k}:=\\frac{\\binom{2k}{k}}{2^{2k}}$ \nI have been trying to verify that $$\n\\lim_{n\\to\\infty} (2n+1)\\left[\\frac{\\pi}{4}-\\sum_{k=0}^{n-1}\\frac{\\left(\\sum_{j=0}^k a^2_{j}\\right)}{(2k+1)(2k+2)}\\right] -\\frac{1}{2}{\\sum_{k=0}^na^2_{k}}=\\frac{1}{2\\pi},\n$$\nwhich seems to be true numerically using Mathematica.\nThe question above is equivalent to finding some formula for $$b_{n}:=\\frac{1}{2^{2n}}\\sum_{j=0}^n\\frac{\\binom{2n+1}{j}}{2n+1-j}.$$ This is because one can verify that \n$$(2n+1)b_n=2nb_{n-1}+a_n,\\qquad a_{n+1}=\\frac{2n+1}{2n+2}a_n,$$\nand combining these two we get\n$$(2n+2)a_{n+1}b_{n}-(2n)a_nb_{n-1}=a_n^2$$\nSumming we get\n$$\\sum_{k=0}^na_k^2=(2n+1)a_nb_n.$$\nI also know that \n$$\n\\frac{\\binom{2n}{n}}{2^{2n}}=\\binom{-1/2}{n},\n$$\nso that\n$$\n\\sum_{k=0}^{\\infty}\\frac{\\binom{2k}{k}}{2^{2k}}x^k=(1-x)^{-1/2},\\quad |x|<1.\n$$\nI have also seen the identity\n$$\n\\sum_{k=0}^n\\frac{\\binom{2k}{k}}{2^{2k}}=\\frac{2n+1}{2^{2n}}\\binom{2n}{n}.\n$$\n", "A": "The limit I want to verify is \n$$\n\\lim_{n\\to\\infty} (2n+1)\\left[\\frac{\\pi}{4}-\\sum_{k=0}^{n-1}\\frac{\\left(\\sum_{j=0}^k a^2_{j}\\right)}{(2k+1)(2k+2)}\\right] -\\frac{1}{2}{\\sum_{k=0}^na^2_{k}}=\\frac{1}{2\\pi}\n$$\nFor this it is sufficient to prove that the above expression under the limit is bounded above. I know this is true because of the original problem this limit is coming from, but I do not have a short prove. Then, given that such expression is bounded, we can argue as follows: using summation by parts we see that $$\n\\sum_{k=0}^{n-1}\\left(\\frac{1}{2k+1}-\\frac{1}{2k+3}\\right)\\sum_{j=0}^ka^2_{j}=\\sum_{k=0}^n\\frac{a^2_{k}}{2k+1}-\\frac{1}{2n+1}\\sum_{k=0}^na^2_{k}\n$$ and so we can write the limit as\n\\begin{align*}\n\\lim_{n\\to\\infty} (2n+1)\\left[\\frac{\\pi}{4}-\\frac{1}{2}\\sum_{k=0}^n\\frac{a^2_{k}}{2k+1}-\\sum_{k=0}^{n-1}\\frac{\\sum_{j=0}^ka^2_{j}}{(2k+1)(2k+2)(2k+3)}\\right]\n\\end{align*}\nSince the limit of the bracket must be zero in under for the whole expression to remain bounded above, $\\pi/4$ must equal the series (sum from $k=0$ up to $\\infty$) and since \n\\begin{align*}\na_{n}:=\\frac{1}{2^{2n}}&\\binom{2n}{n}= \\frac{\\Gamma(1/2)\\Gamma(n+1/2)}{\\pi\\Gamma(n+1)}=  \\frac{1+O(1/n)}{\\sqrt{\\pi n}}\n\\end{align*} \nthe limit becomes \n\\begin{align*}\n&\\lim_{n\\to\\infty}(2n+1)\\left[\\frac{1}{2}\\sum_{k=n+1}^\\infty\\frac{a^2_{k}}{2k+1}+\\sum_{k=n}^{\\infty}\\frac{\\sum_{j=0}^ka^2_{j}}{(2k+1)(2k+2)(2k+3)}\\right]\\\\\n=&\\lim_{n\\to\\infty} \\frac{(2n+1)}{2\\pi}\\sum_{k=n+1}^\\infty\\frac{1+O(1/k)}{k(2k+1)}+ (2n+1)O\\left(\\sum_{k=n}^{\\infty}\\frac{\\sum_{j=0}^k\\frac{1}{j}}{(2k+1)(2k+2)(2k+3)}\\right)\\\\\n=&\\frac{1}{2\\pi}.\n\\end{align*}\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/167355", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "11", "answer_count": 4, "answer_id": 1}}
{"Q": "Number of zeros of a polynomial in the unit disk Suppose $m$ and $n$ are two nonnegative integers. What is the number of zeros  of the polynomial $(1+z)^{m+n}-z^n$ in the unit ball $|z|<1$?\nSome calculations for small values of $m$ and $n$ suggests the following formula:\n$$n-1+2\\left\\lfloor\\frac{m-n+5}{6} \\right\\rfloor$$\nDoes this formula work for all values of $m$ and $n$?\n", "A": "Here is my solution of this problem. So we have next equation for the zeros:\n$$\n(1+z)^{n+m}=z^n\n$$\nWe can modify it like that:\n$$\n\\Bigl(1+\\frac{1}{z}\\Bigr)^n \\Bigl(1+z\\Bigr)^m = 1\n$$\nNext we can mark the first factor as $re^{i\\varphi}$, so the equation splits into two ones:\n$$\n\\Bigl(1+z\\Bigr)^m = re^{i\\varphi} \\\\\n\\Bigl(1+\\frac{1}{z}\\Bigr)^n = \\frac{1}{r}e^{-i\\varphi}\n$$\nLet's consider the first equation. We have to extract the root:\n$$\n1 + z = r^{\\frac{1}{m}} e^{i\\frac{\\varphi + 2 \\pi k}{m}}\n$$\nNext we take away $1$ and write down the module of $z$ using the condition $|z|<1$:\n$$\n|z|^2 = |r^{\\frac{1}{m}} e^{i\\frac{\\varphi + 2 \\pi k}{m}} - 1|^2 = r^{\\frac{2}{m}} - 2 r^{\\frac{1}{m}} \\cos \\frac{\\varphi + 2 \\pi k}{m} + 1 < 1\n$$\nFinally, we divide by $r^{\\frac{1}{m}}$, so:\n$$\nr^{\\frac{1}{m}} < 2 \\cos \\frac{\\varphi + 2 \\pi k}{m}\n$$\nAt the same time we know that $r^{\\frac{1}{m}}<1$, so we have to understand, which inequation is stronger. Let's mark $z=\\rho e^{i\\psi}$ and write down the following inequation:\n$$\n\\Bigl|1 + \\frac{1}{z}\\Bigr|^2 = \\rho^{-2} + 2\\rho^{-1} \\cos \\psi + 1 > 1\n$$\nNext,\n$$\n\\rho \\cos \\psi + 1 > \\frac{1}{2}\n$$\nIt's clear that the left part equals $\\Re \\sqrt[m]{re^{i\\varphi}}$, so:\n$$\nr^{\\frac{1}{m}} \\cos \\frac{\\varphi + 2 \\pi k}{m} > \\frac{1}{2}\n$$\nBecause of $r^{\\frac{1}{m}} < 1$ we have:\n$$\n\\cos \\frac{\\varphi + 2 \\pi k}{m} > \\frac{1}{2}\n$$\nTherefore $r^{\\frac{1}{m}} < 1$ is stronger and we have $\\cos \\frac{\\varphi + 2 \\pi k}{m} > \\frac{1}{2}$. Next, we perform the same procedure for the second equation, and finally obtain another inequation:\n$$\n\\cos \\frac{-\\varphi + 2 \\pi k'}{n} < \\frac{1}{2}\n$$\nLet's transform these inequations:\n$$\n-\\frac{m}{6} < \\frac{\\varphi}{2\\pi} + k < \\frac{m}{6} \\\\\n\\frac{n}{6} < -\\frac{\\varphi}{2\\pi} + k' < \\frac{5n}{6}\n$$\nWe have to take away $\\varphi$, so:\n$$\n-\\frac{m}{6} - \\frac{\\varphi}{2\\pi} < k < \\frac{m}{6} - \\frac{\\varphi}{2\\pi}\n$$\nAnd:\n$$\n-\\frac{m}{6} + \\frac{n}{6} - k' < k < \\frac{m}{6} + \\frac{5n}{6} - k'\n$$\nSo, finally:\n$$\n\\frac{n-m}{6} < \\ell < \\frac{5n+m}{6}\n$$\nwhere $\\ell = k + k'$. The number of $\\ell$'s satisfying this inequation defines the number of zeros in the unit disk.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/171895", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "22", "answer_count": 2, "answer_id": 0}}
{"Q": "Number of intervals needed to cross, Brownian motion Let $B_t$ be a standard Brownian motion. Let $E_{j, n}$ denote the event$$\\left\\{B_t = 0 \\text{ for some }{{j-1}\\over{2^n}} \\le t \\le {j\\over{2^n}}\\right\\},$$and let$$K_n = \\sum_{j = 2^n + 1}^{2^{2n}} 1_{E_{j,n}},$$where $1$ denotes indicator function. I have three questions.\n\n\n*\n\n*What is $\\lim_{n \\to \\infty} \\mathbb{P}\\{K_n = 0\\}$?\n\n*What is $\\lim_{n \\to \\infty} 2^{-n} \\mathbb{E}[K_n]$?\n\n*Does there exist $\\rho > 0$ such that for $\\mathbb{P}\\{K_n \\ge \\rho2^{n}\\} \\ge \\rho$ for all $n$?\n\n", "A": "I'll address the second question on the expected value of the sum $K_n$.\nLet $\\phi(x)$ and $\\Phi(x)$ be the probability density function and cumulative distribution functions for a standard normal distribution.\nLet $h(a,b)$ be the probability that a Brownian motion without drift returns to $0$ at some time in $[a,b]$. Let $h(b)=h(1,b)$. Then by rescaling, $h(a,b)=h(1,b/a)=h(b/a)$. We can calculate this exactly.\nFor $x \\gt 0$ let $f(x,t)$ be the probability that a Brownian motion released at position $x$ will hit $0$ by time $t$. Let $f(x) = f(x,1)$. By rescaling, $f(x,t)= f(\\frac{x}{\\sqrt{t}},1) = f(\\frac{x}{\\sqrt{t}})$. By reflection, $f(x) = 2 \\Phi(-x) = 2-2\\Phi(x)$. \n$$\\begin{eqnarray}h(b) &=& 2 \\int_0^\\infty \\phi(x) f(x,b-1)~dx \\newline &=&2 \\int_0^\\infty \\phi(x)\\cdot 2 \\Phi\\left(\\frac{-x}{\\sqrt{b-1}}\\right)~dx\\end{eqnarray}$$ \nWe can use differentiation under the integral sign. $h(1)=0$ and $h(b) = \\int_1^b h'(t) dt$. \n$$\\begin{eqnarray} h'(b) &=& 4 \\int_0^\\infty \\phi(x) \\phi\\left(\\frac{x}{\\sqrt{b-1}}\\right) \\left(\\frac{1}{2} \\frac{x}{(b-1)^{3/2}}\\right) dx \\newline &=&\\frac{2}{(b-1)^{3/2}}\\int_0^\\infty x \\phi(x) \\phi\\left( \\frac{x}{\\sqrt{b-1}}\\right) dx \\newline &=& \\frac{2}{(b-1)^{3/2}} \\int_0^\\infty \\frac{x}{2 \\pi} e^{-x^2 \\cdot \\left(\\frac{1}{2} + \\frac{1}{2(b-1)}\\right)}dx \\newline &=& \\frac{1}{\\pi b \\sqrt{b-1}}\\end{eqnarray}$$ \nSo, $h(b) = \\int_1^b \\frac{dy}{\\pi y \\sqrt{y-1}} = 1-\\frac{2}{\\pi} \\arcsin \\frac{1}{\\sqrt{b}}$.\n$\\mathbb{P}(E_{j+1,n})$ is the probability that the Brownian motion returns to $0$ on $\\left[\\frac{j}{2^n},\\frac{j+1}{2^n}\\right]$ which is $h(\\frac{j}{2^n},\\frac{j+1}{2^n}) = h(1 + \\frac{1}{j}) = 1-\\frac{2}{\\pi} \\arcsin \\frac{1}{\\sqrt{1+1/j}}.$ That can be simplified to $1-\\frac{2}{\\pi}(\\frac{\\pi}{2} - \\arctan \\frac{1}{\\sqrt{j}}) = \\frac{2}{\\pi}\\arctan \\frac{1}{\\sqrt{j}}$. For large $j$, this is approximately $\\frac{2}{\\pi} \\frac{1}{\\sqrt{j}}$. \n$$\\mathbb{E}(K_n) \\sim \\sum_{j=2^n}^{2^{2n}-1} \\frac{2}{\\pi} \\frac{1}{\\sqrt{j}} \\approx \\frac{2}{\\pi} \\int_{2^n}^{2^{2n}} \\frac{1}{\\sqrt{x}} dx =\\frac{4}{\\pi}(2^n -2^{n/2}) \\sim \\frac{4}{\\pi} 2^n.$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/221115", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "6", "answer_count": 4, "answer_id": 0}}
{"Q": "Number of all different $n\\times n$ matrices where sum of rows and columns is $3$ For a given positive integer $n$, I need to learn the number of $n\\times n$ matrices of nonnegative integers with the following restrictions:\n\n\n*\n\n*The sum of each row and column is equal to $3$.\n\n*Two matrices are considered equal if one can be obtained by permuting rows and/or columns.\n\n\nFor example, for $n=2$ there are two different matrices as follows:\n$$M_1=\\begin{pmatrix}\n1&2\\\\2&1\n\\end{pmatrix},\\qquad M_2=\\begin{pmatrix}\n3&0\\\\0&3\n\\end{pmatrix}.$$\nFor $n=3$ there are five different matrices as follows:\n$$\\begin{pmatrix}\n1&1&1\\\\1&1&1\\\\1&1&1\n\\end{pmatrix},\\quad \\begin{pmatrix}\n0&1&2\\\\1&2&0\\\\2&0&1\n\\end{pmatrix}, \\quad \\begin{pmatrix}\n0&1&2\\\\1&1&1\\\\2&1&0\n\\end{pmatrix}, \\quad \\begin{pmatrix}\n1&2&0\\\\2&1&0\\\\0&0&3\n\\end{pmatrix}, \\quad \\begin{pmatrix}\n3&0&0\\\\0&3&0\\\\0&0&3\n\\end{pmatrix}.$$\n", "A": "This problem was solved by Ron Read in his PhD thesis (University of London, 1958). Without requirement 2 there is a summation which isn't too horrible. With requirement 2 added as well, Read's solution needs the cycle index polynomial of a group and you could reasonably call it a solution in principle.\nThe problem is easier to handle in the asymptotic sense. Without requirement 2, the number is asymptotically\n$$ \\frac{(3n)!}{6^{2n}}\\exp\\Bigl(2 - \\frac{2}{9n} + O(n^{-2})\\Bigr),$$\nsee this paper.\nWith requirement 2, counting equivalence classes, the key thing to note is that asymptotically almost all of them have only trivial symmetry group, so asymptotically you can divide by $(n!)^2$.  See this paper.\nFor small sizes, starting with $n=1$, I get 1, 2, 5, 12, 31, 103, 383, 1731, 9273, 57563, 406465.  This sequence is OEIS A232215 but its a bit hard to see that given the non-combinatorial description.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/251916", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "8", "answer_count": 2, "answer_id": 1}}
{"Q": "Efficiently lifting $a^2+b^2 \\equiv c^2 \\pmod{n}$ to coprime integers Let $n$ be integer with unknown factorization. Assume factoring $n$\nis inefficient.\nLet $a,b,c$ satisfy $a^2+b^2 \\equiv c^2 \\bmod{n}, 0 \\le a,b,c \\le n-1$.\nIs it possibly to lift the above\ncongruence to coprime integers in $O(\\mathsf{polylog}(n))$ time with probability at least $O\\Big(\\frac1{\\mathsf{polylog}(n)}\\Big)$?\ni.e., find coprime integers $A,B,C$ satisfying $$A^2+B^2=C^2, A \\equiv a \\bmod{n},B \\equiv b \\bmod{n},C \\equiv c \\bmod{n}$$\nIf we drop the coprime constraint, the problem is easy.\nI do not know if this is equivalent to factoring $n$.\n\nExplaining per comments.\nWrite $A=a+a'n, B=b+b'n, C=c+b'n$ for unknown integers $a',b'$.\nThen $A^2+B^2-C^2=0$ is linear in $b'$.\nThen $b'=-1/2*(a'^2*n^2 + 2*a*a'*n + a^2 + b^2 - c^2)/((b - c)*n)$\nSince $n$ divides $a^2+b^2-c^2$, $b'= -1/2*(a'^2n+2a a'+ (a^2+b^2-c^2)/n)/(b-c) $.\nIf we can trial factor $b-c$ (it is prime with probability $1/\\log{n}$),\nwe try to solve $(a'^2n+2a a'+ (a^2+b^2-c^2)/n)=0$ modulo $2(b-c)$ for $a'$.\nIf solution exists, we know $a',b'$ and the lift.\nIf we can't factor $b-c$ or solution doesn't exist, replace $b$\nwith $b+b''n$, this doesn't change the congruence and we will hit\nprimes/numbers we can trial factor in the arithmetic progression\n$b-c + b''n$.\nThe problem with this approach is the lift is not coprime.\n\n", "A": "Unless I'm mistaken, if we had an efficient algorithm we would be able to factor integers efficiently.  We may suppose $n$ is odd.\nRandomly choose \ncoprime integers $X, Y$, not both odd, in some large interval.  Then $A = X^2 - Y^2$, $B = 2 X Y$,\n$C = X^2 + Y^2$ are a primitive Pythagorean triple. Now compute reduced residues mod $n' = 2n$, $a, b, c$, of $A, B, C$ respectively, and give them to the algorithm (with $n$ replaced by $n'$),\nobtaining $A', B', C'$ forming a primitive Pythagorean triple with\n$A' \\equiv a \\equiv A \\mod n'$, $B' \\equiv b \\equiv B \\mod n'$, $C' \\equiv c \\equiv C \\mod n'$. In particular, $B'$ is even.  Thus there are coprime integers $X'$, $Y'$ not both odd, with\n$A' = X'^2 - Y'^2$, $B' = 2 X' Y'$, $C' = X'^2 + Y'^2$, and these \nare efficiently computable from $A', B', C'$ by $X' = \\sqrt{(A' + C')/2}$, $Y' = B'/(2X')$.  We then have $2 X'^2 = A' + C' \\equiv A + C = 2 X^2 \\mod 2n$ so that $X'^2 \\equiv X^2 \\mod n$.  Now if $n$ is composite, we should have with probability bounded away from $0$, $X' \\not \\equiv \\pm X \\mod n$, e.g. if $n = pq$ we might have taken $X'', Y''$ instead of $X, Y$, where $X'' \\equiv X \\mod 2p$, $Y'' \\equiv Y \\mod 2p$, $X'' \\equiv -X \\mod q$, $Y'' \\equiv Y\\mod q$, obtaining the same $a,b,c$.\nBut if so, $\\gcd(X'-X,n)$ and $\\gcd(X'+X,n)$ gives us a nontrivial factorization of $n$.  \n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/252523", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 1, "answer_id": 0}}
{"Q": "A four-variable maximization problem We let function\n\\begin{equation}\n\\begin{aligned}\nf(x_1,~x_2,~x_3,~x_4) ~&=~ \\sqrt{(x_1+x_2)(x_1+x_3)(x_1+x_4)} \\\\\n        &+ \\sqrt{(x_2+x_1)(x_2+x_3)(x_2+x_4)} \\\\\n        &+ \\sqrt{(x_3+x_1)(x_3+x_2)(x_3+x_4)} \\\\\n        &+ \\sqrt{(x_4+x_1)(x_4+x_2)(x_4+x_3)},\n\\end{aligned}\n\\end{equation}\nwhere variables $x_1,~x_2,~x_3,~x_4$ are positive and satisfy $x_1+x_2+x_3+x_4 ~=~ 1$. We want to prove that $f(x_1,~x_2,~x_3,~x_4)$ attains its global maximum when $x_1=x_2=x_3=x_4=\\frac{1}{4}$.\nThis looks a difficult problem even if it is at high-school level. Any clues? Your ideas are greatly appreciated.\n", "A": "Using the inequality of the means for 2 variables, $(\\sqrt{ab}\\leq\\frac{a+b}{2})$ for positive $a$ and $b$, equality only when $a=b$ we have\n\\begin{equation}\n\\begin{aligned}\n&\\sqrt{(x_1+x_2)(x_1+x_3)(x_1+x_4)} + \\sqrt{(x_2+x_1)(x_2+x_3)(x_2+x_4)} \\\\&=\\sqrt{(x_1+x_2)}(\\sqrt{(x_1+x_3)(x_1+x_4)}+\\sqrt{(x_2+x_3)(x_2+x_4)})\\\\ &\\leq \\sqrt{(x_1+x_2)}(\\frac{(x_1+x_3)+(x_1+x_4)}{2}+\\frac{(x_2+x_3)+(x_2+x_4)}{2})\\\\&=\\sqrt{(x_1+x_2)}(x_1+x_2+x_3+x_4)\\\\&=\\sqrt{(x_1+x_2)}\n\\end{aligned}\n\\end{equation}\nwith equality attained only when $x_3=x_4$.\nSimilarly or by swapping $x_1$ and $x_3$, $x_2$ and $x_4$ we have\n\\begin{equation}\n\\begin{aligned}\n&\\sqrt{(x_3+x_1)(x_3+x_2)(x_3+x_4)} + \\sqrt{(x_4+x_1)(x_4+x_2)(x_4+x_3)} \\\\&\\leq\\sqrt{(x_3+x_4)}\n\\end{aligned}\n\\end{equation}\nwith equality attained only when $x_1=x_2$.\nAdding the two inequalities we obtain\n\\begin{equation}\n\\begin{aligned}\nf(x_1,~x_2,~x_3,~x_4) ~&\\leq \\sqrt{(x_1+x_2)}+\\sqrt{(x_3+x_4)}\n\\end{aligned}\n\\end{equation}\nBy Jensen's Inequality since $-\\sqrt{x}$ is convex for $0\\leq x \\leq 1$ we have \n\\begin{equation}\n\\begin{aligned}\n\\frac{\\sqrt{(x_1+x_2)}+\\sqrt{(x_3+x_4)}}{2}\\leq \\sqrt{\\frac{(x_1+x_2)+(x_3+x_4)}{2}}=\\sqrt{\\frac{1}{2}}\n\\end{aligned}\n\\end{equation}\nwith equality attained only when $(x_1+x_2)=(x_3+x_4)=\\frac{1}{2}$.\nHence \n\\begin{equation}\n\\begin{aligned}\nf(x_1,~x_2,~x_3,~x_4) ~&\\leq \\sqrt{2}\n\\end{aligned}\n\\end{equation}\nwith equality only attained if $x_1=x_2$, $x_3=x_4$ and $(x_1+x_2)=(x_3+x_4)=\\frac{1}{2}$ which is equivalent to $x_1=x_2=x_3=x_4=\\frac{1}{4}.$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/346297", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 2, "answer_id": 0}}
{"Q": "Limit of alternated row and column normalizations Let $E_0$ be a matrix with non-negative entries.\nGiven $E_n$, we apply the following two operations in sequence to produce $E_{n+1}$.\nA. Divide every entry by the sum of all entries in its column (to make the matrix column-stochastic).\nB. Divide every entry by the sum of all entries in its row (to make the matrix row-stochastic).\nFor example:\n$E_0=\\begin{pmatrix}\n\\frac{2}{5} & \\frac{1}{5} & \\frac{2}{5} & 0 & 0\\\\ \n\\frac{1}{5} & 0 & \\frac{7}{10} & \\frac{1}{10} & 0\\\\ \n0 & 0 & 0 & \\frac{3}{10} & \\frac{7}{10}\n\\end{pmatrix}\\overset{A}{\\rightarrow}\\begin{pmatrix}\n\\frac{2}{3} & 1 & \\frac{4}{11} & 0 & 0\\\\ \n\\frac{1}{3} & 0 & \\frac{7}{11} & \\frac{1}{4} & 0\\\\ \n0 & 0 & 0 & \\frac{3}{4} & 1\n\\end{pmatrix}\\overset{B}{\\rightarrow}\\begin{pmatrix}\n\\frac{22}{67} & \\frac{33}{67} & \\frac{12}{67} & 0 & 0\\\\ \n\\frac{44}{161} & 0 & \\frac{12}{23} & \\frac{33}{161} & 0\\\\ \n0 & 0 & 0 & \\frac{3}{7} & \\frac{4}{7}\n\\end{pmatrix}=E_1$\nWhat is the limit of $E_n$ as $n \\to \\infty$?\n\nAdditional remarks.\nIn my problem, the matrix has $c\\in \\{1,2,\\dots,5\\}$ rows and $r=5$ columns (note that the two letters are reversed, but in the original context of this problem these letters $r$ and $c$ do not actually stand for rows and columns). So $E_0$ can be $1\\times 5$, $2\\times 5$, ... or $5\\times 5$.\nWe denote with $(e_n)_{ij}$ the entries of $E_{n}$; hence $(e_n)_{ij}\\in[0;1]$ and $\\forall i \\sum_{j=1}^{r}(e_n)_{ij}=1$ for $n>0$.\nI managed to express $(e_{n+1})_{ij}$ as a function of $(e_{n})_{ij}$ :\n$$(e_{n+1})_{ij}=\\frac{\\frac{(e_{n})_{ij}}{\\sum_{k=1}^{c}(e_n)_{kj}}}{\\sum_{l=1}^{r}\\frac{(e_n)_{il}}{\\sum_{k=1}^{c}(e_n)_{kl}}}$$\nWhat I can't seem to find now is an expression $(e_{n})_{ij}$ as a function of $(e_{0})_{ij}$, to be able to calculate $\\underset{n \\to +\\infty }{lim}(e_n)_{ij}$\nI wrote code to compute this iteration; when I ran it with the previous example $E_0$, I found out that:\n$E_0=\\begin{pmatrix}\n\\frac{2}{5} & \\frac{1}{5} & \\frac{2}{5} & 0 & 0\\\\ \n\\frac{1}{5} & 0 & \\frac{7}{10} & \\frac{1}{10} & 0\\\\ \n0 & 0 & 0 & \\frac{3}{10} & \\frac{7}{10}\n\\end{pmatrix}\\overset{n \\rightarrow+\\infty}{\\rightarrow}E_n=\\begin{pmatrix}\n\\frac{7}{25} & \\frac{3}{5} & \\frac{3}{25} & 0 & 0\\\\ \n\\frac{8}{25} & 0 & \\frac{12}{25} & \\frac{1}{5} & 0\\\\ \n0 & 0 & 0 & \\frac{2}{5} & \\frac{3}{5}\n\\end{pmatrix}$\nNot only do the row sums equal $1$, but the column sums equal $\\frac{3}{5}$: it seems that in this process column sums converge to $\\frac{c}{r}$.\nI'm not a mathematician so I was looking for a simple inductive proof. I tried to express $E_2$ (and so on) as a function of $E_0$, but it quickly gets overwhelming, starting from $E_2$...\n", "A": "When $E_0$ is square (i.e., $r = c$) this procedure is called Sinkhorn iteration or the Sinkhorn-Knopp algorithm (see this Wikipedia page). You can find a wealth of results by Googling those terms, the most well-known of which is that if $E_0$ has strictly positive entries (and again, is square) then the limit of $E_n$ indeed exists and is doubly stochastic.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/349274", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "6", "answer_count": 2, "answer_id": 0}}
{"Q": "$\\varepsilon$-net of a $d$-dimensional unit ball formed by power set of $V = \\{+1, 0 -1\\}^d$ I have a set of $d$-dimensional vectors $V = \\{+1, 0, -1\\}^d $. Then $P(V)$ constitutes the power set of $V$. I now construct a set of unit vectors $V_{\\mathrm{sum}}$ from the power set $P(V)$ such that\n$$\nV_{\\mathrm{sum}} = \\left\\{\\frac{\\bar{v}}{\\|\\bar{v}\\|} \\quad \\Bigg|  \\quad \\bar{v} = \\sum_{v \\in S} v, \\quad \\forall S \\in P(V)\\right\\}\n$$ \nThat is, each subset $S \\in P(V)$ contributes to a vector in $V_{\\mathrm{sum}}$ formed as a sum of all the vectors in the subset $S$ and then taking the unit vector in that direction.\nNote that there could be duplicates. For example, for $d = 3$, the vector $(\\frac{1}{\\sqrt{3}},\\frac{1}{\\sqrt{3}},\\frac{1}{\\sqrt{3}})$ can be formed as a sum of vectors of any of the following subsets $$S_1 = \\{(1,0,0),(0,1,0),(0,0,1)\\},\\\\ S_2 = \\{(1,1,0\n),(1,0,1),(0,1,1)\\},\\\\ S_3 = \\{(1,1,1)\\}.$$\nand many more possibilities. \nNow I want to find the maximal isolation of a vector from $\\,V_{\\mathrm{sum}}\\,$ from the remaining vectors of $\\,V_{\\mathrm{sum}},\\,$ i.e. the maximum of Euclidean distance between any vector in $V_{\\mathrm{sum}}$ to its closest vector in $V_{\\mathrm{sum}}$. Is there an easy way to upper bound this max distance?\nIn other words, if I consider $V_{\\mathrm{sum}}$ to be an $\\varepsilon$-net to the surface of the unit ball in $d$-dimensions, then I want to find an upper bound on $\\varepsilon$. Any weak upper bound on $\\varepsilon$ should suffice. The goal is to show that $V_{\\mathrm{sum}}$ forms a better $\\varepsilon$-net than the unit vectors formed from the vectors in $V$.\n", "A": "Since the notation quickly becomes cumbersome for any $S \\in 2^{V}$ define\n\\begin{equation}\nv_S \\overset{\\text{def}}{=} \\sum_{v \\in S} v,\n\\end{equation}\nand let\n\\begin{equation}\n\\hat v_S \\overset{\\text{def}}{=} \\frac{v_S}{\\|v_S\\| },\n\\end{equation}\nIf we fix a $v_S \\in \\text{span}(V)$\nthen the goal is to find/bound\n\\begin{equation}\n\\min_{w_T \\in V_\\text{sum}} |\\hat v_S- \\hat w_T| =\n\\end{equation}\n\\begin{equation}\n = \\min_{w \\in V_\\text{sum}}\\left|\\frac{1}{\\|w_T \\| \\|v_S \\| } \\right|\\left| \\| w_T \\|  v_S - \\|v_S \\| w_T  \\right|\n\\end{equation}\nand then use that to find/bound the value of\n\\begin{equation}\n\\max_{v_S \\in V_\\text{sum}}\\min_{w_T \\in V_\\text{sum}} |v_S-w_T| .\n\\end{equation}\nTo that end notice that\n\n\n*\n\n*if $S = \\{0\\}$ then $\\hat v_T$ doesn't make sense so that we can\nalways assume that $\\exists v' \\in S$ such that $|v'_i|=1 $ (as a matter of fact we can further assume $0 \\not\\in S$ since it has no effect)\n\n*furthermore if $\\forall v' \\in S$ we have that $-v' \\in S$ then we have that $v_S = 0$ so that we can also assume that $\\exists v' \\in S$ such that $-v' \\not\\in S$\n\n*taking this idea even further we have that if $ v \\in S$ and $- v \\in S $ then $v_S = v_{S \\setminus \\{ v, -v\\}}$ and therefore we can assume that $v \\in S \\implies -v \\notin S$\n\n*generalizing this concept further we have that if $ T \\subset S$ and $v_T = 0 $ then $v_S = v_{S \\setminus T}$ and therefore we can assume that $(\\not\\exists T \\subset S)(w_T = 0 )$\nTherefore if we define the support of $v$ as the following \n\\begin{equation}\n\\text{supp}(v) = \\{i \\in [n] \\ | \\ v_i \\neq 0\\}, \n\\end{equation}\nwe can use the preceding claims to deduce the following: \n\nLemma $(\\forall v_S \\in \\text{span}(V))(\\exists m \\in [n])$ such that both\n  \n  \n*\n  \n*$(v_S)_m =  \\min\\{ |(v_S)_i| \\ | \\ i \\in [n] \\}$\n  \n*either $e_m \\not\\in S$ or $-e_m \\not\\in S$\nwhere \\begin{equation}\n(e_m)_i = \\begin{cases} 1 & \\text{if } i = m  \\\\ \n0 & \\text{o.w.}\\end{cases} . \n\\end{equation} \n(Proof): By the previous claims we can assume W.L.O.G. that $v_S$ is reduced; i.e. \\begin{equation}\n(\\not\\exists T \\subset S)(w_T = 0 ).\n\\end{equation} Let $m$ satisfy $(v_S)_m =  \\min\\{ |(v_S)_i| \\ | \\ i \\in [n] \\}$ then by assumption either $e_m \\not\\in $ or $-e_m \\not\\in S$. QED\n\nTherefore W.L.O.G. assume that $S$ satisfies the properties above and let $m \\in [n]$ the index that satisfies the properties of the lemma and define\n\\begin{equation}\nT = S  \\cup \\{e_m \\},\n\\end{equation}\nso that\n\\begin{equation}\n(w_T)_i = \\begin{cases} v_i \\pm 1 & \\text{if } i = m \\\\ \nv_i & \\text{o.w.}\\end{cases} . \n\\end{equation}\n Notice that if $\\| v_S \\|= \\sqrt k$ then $\\|w_T \\|= \\sqrt{k \\pm  \\epsilon}$ for some $\\epsilon \\leq |2v_m + 1|$; therefore we have that\n\\begin{equation}\n\\min_{w_T \\in V_\\text{sum}} |\\hat v_S- \\hat w_T| \\leq  \\frac{1}{\\sqrt k  \\sqrt{k \\pm  \\epsilon} } \\left| \\sqrt{k \\pm  \\epsilon}  v_S - \\sqrt{k} w_T  \\right|\n\\end{equation}\n\\begin{equation}\n=     \\frac{1 }{ \\sqrt k  \\sqrt{k \\pm  \\epsilon} }   \\sqrt{ \\left(\\sqrt{k} v_m -  \\sqrt{k \\pm  \\epsilon}(w_T )_m  \\right)^2+ ( \\sqrt{k \\pm  \\epsilon}   - \\sqrt{k})^2  \\sum_{i \\neq m } v_i^2 }\n\\end{equation}\n\\begin{equation}\n=     \\frac{1 }{ \\sqrt k  \\sqrt{k \\pm  \\epsilon} }   \\sqrt{ \\left(\\sqrt{k} v_m -  \\sqrt{k \\pm  \\epsilon}v _m \\pm  \\sqrt{k \\pm  \\epsilon} \\right)^2+ ( \\sqrt{k \\pm  \\epsilon}   - \\sqrt{k})^2  \\sum_{i \\neq m } v_i^2 }.\n\\end{equation}\nBut notice that \n\\begin{equation}\n\\left(\\sqrt{k} v_m -  \\sqrt{k \\pm  \\epsilon}v _m \\pm  \\sqrt{k \\pm  \\epsilon} \\right)^2 = \n\\end{equation}\n\\begin{equation}\n= \\left(\\sqrt{k} v_m -  \\sqrt{k \\pm  \\epsilon}v _m \\pm  \\sqrt{k \\pm  \\epsilon} \\right)^2 -\\left(\\sqrt{k} v_m -  \\sqrt{k \\pm  \\epsilon}v _m  \\right)^2 + \\left(\\sqrt{k} v_m -  \\sqrt{k \\pm  \\epsilon}v _m   \\right)^2 \n\\end{equation}\n\\begin{equation}\n= 2\\left(\\sqrt{k}  -  \\sqrt{k \\pm  \\epsilon} \\right)  \\left(k \\pm  \\epsilon \\right)v_m  + \\left(\\sqrt{k}  -  \\sqrt{k \\pm  \\epsilon} \\right)^2 v_m^2;\n\\end{equation}\nand therefore have that\n\\begin{equation}\n\\min_{w_T \\in V_\\text{sum}} |\\hat v_S- \\hat w_T| \\leq\n\\end{equation}\n\\begin{equation}\n\\leq     \\frac{1 }{ \\sqrt k  \\sqrt{k \\pm  \\epsilon} }   \\sqrt{ 2\\left(\\sqrt{k}  -  \\sqrt{k \\pm  \\epsilon} \\right)  \\left(k \\pm  \\epsilon \\right)v_m + \\left(\\sqrt{k}  -  \\sqrt{k \\pm  \\epsilon} \\right)^2 v_m^2\n+ ( \\sqrt{k \\pm  \\epsilon}   - \\sqrt{k})^2  \\sum_{i \\neq m } v_i^2 } \n\\end{equation}\n\\begin{equation}\n=    \\frac{1 }{ \\sqrt k  \\sqrt{k \\pm  \\epsilon} }   \\sqrt{ 2\\left(\\sqrt{k}  -  \\sqrt{k \\pm  \\epsilon} \\right)  \\left(k \\pm  \\epsilon \\right)v_m \n+ ( \\sqrt{k \\pm  \\epsilon}   - \\sqrt{k})^2  \\sum_{i \\in [n]} v_i^2 } \n\\end{equation}\n\\begin{equation}\n=    \\frac{1 }{ \\sqrt k  \\sqrt{k \\pm  \\epsilon} }   \\sqrt{ 2\\left(\\sqrt{k}  -  \\sqrt{k \\pm  \\epsilon} \\right)  \\left(k \\pm  \\epsilon \\right)v_m \n+ ( \\sqrt{k \\pm  \\epsilon}   - \\sqrt{k})^2  k  } \n\\end{equation}\nSince $x \\geq 0 \\land y \\geq 0 \\implies \\sqrt {x+y} \\leq  \\sqrt x + \\sqrt y $ we further get that\n\\begin{equation}\n \\min_{w_T \\in V_\\text{sum}} |\\hat v_S- \\hat w_T| \\leq \\frac{ \\sqrt{\\left(\\sqrt{k}  -  \\sqrt{k \\pm  \\epsilon} \\right)  \\left(k \\pm  \\epsilon \\right)}    }{ \\sqrt k  \\sqrt{k \\pm  \\epsilon} }\\sqrt{2v_m}    +  \\frac{\\left| \\sqrt{k \\pm  \\epsilon}   - \\sqrt{k}\\right|   }{ \\sqrt k  \\sqrt{k \\pm  \\epsilon} }   \\sqrt{k},\n\\end{equation}\nwhich W.L.O.G., after possibly relableing $k \\leftarrow k-\\epsilon$, we have\n\\begin{equation}\n\\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S- \\hat w_T| \\leq  \\frac{ \\sqrt{\\left(\\sqrt{k}  -  \\sqrt{k +  \\epsilon} \\right)  \\left(k + \\epsilon \\right)}   }{ \\sqrt k  \\sqrt{k +  \\epsilon} }\\sqrt{2v_m }   + \\frac{ \\sqrt{k +  \\epsilon}   - \\sqrt{k}  }{  \\sqrt{k +  \\epsilon} } \n\\end{equation}\n\\begin{equation}\n = \\left(\\frac{\\sqrt{\\epsilon} }{\\sqrt 2 k^{\\frac{7}{4}}} + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{11}{4}}} \\right) \\right)\\sqrt{2v_m } +  \\left(\\frac{\\epsilon}{2k^{\\frac{3}{2}}} + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \\right)\n\\right) \n\\end{equation}\n\\begin{equation}\n = \\frac{\\sqrt{\\epsilon} }{\\sqrt 2 k^{\\frac{7}{4}}}  \\sqrt{2v_m } +  \\frac{\\epsilon}{2k^{\\frac{3}{2}}} + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \n\\right) =  \\frac{\\sqrt{\\epsilon} }{ k^{\\frac{7}{4}}}  \\sqrt{v_m } +  \\frac{\\epsilon}{2k^{\\frac{3}{2}}} + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \n\\right).\n\\end{equation}\nby expanding the Puiseux series.\nBut recall that either $\\| v_S \\|= k^{\\frac{1}{2}}$ or $\\| v_S \\|= (k+\\epsilon)^{\\frac{1}{2}}$ (depending on whether we relabeled) by definition so that\n\\begin{equation}\n|v_m| \\leq \\frac{1}{|\\text{supp}(v_S)|}k^{\\frac{1}{2}}\n\\end{equation}\nby the pigeon-hole principle and therefore\n\\begin{equation}\n\\epsilon < 2|v_m|+1 \\leq \\frac{2}{|\\text{supp}(v_S)|}k^{\\frac{1}{2}}+1\n\\end{equation}\nand therefore \n\\begin{equation}\n\\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S- \\hat w_T| \n =    \\frac{\\sqrt{\\epsilon} }{ k^{\\frac{7}{4}}}  \\sqrt{v_m } +  \\frac{\\epsilon}{2k^{\\frac{3}{2}}} + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \n\\right)\n\\end{equation}\n\\begin{equation}\n =   \\frac{\\sqrt{\\epsilon} }{ \\sqrt{|\\text{supp}(v_S)|} k^{\\frac{7}{4}}}  k^{\\frac{1}{4}} +  \\frac{k^{\\frac{1}{2}}}{|\\text{supp}(v_S)| k^{\\frac{3}{2}}} + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \n\\right)\n\\end{equation}\n\\begin{equation}\n =   \\frac{\\sqrt{\\epsilon} }{ \\sqrt{|\\text{supp}(v_S)|} k^{\\frac{3}{2}}} +  \\frac{1}{|\\text{supp}(v_S)| k}     + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \n\\right) \n\\end{equation}\n\\begin{equation}\n =   \\left( \\frac{2}{|\\text{supp}(v_S)|}k^{\\frac{1}{2}}+1\\right)^{\\frac{1}{2}}               \\frac{1 }{ \\sqrt{|\\text{supp}(v_S)|} k^{\\frac{3}{2}}}  +  \\frac{1}{|\\text{supp}(v_S)| k}       + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \n\\right) ,\n\\end{equation}\nand once again applying the rule $x \\geq 0 \\land y \\geq 0 \\implies \\sqrt {x+y} \\leq  \\sqrt x + \\sqrt y $ we get that \n\\begin{equation}\n \\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S- \\hat w_T| \n =    \n\\end{equation}\n\\begin{equation}\n\\left( \\frac{2}{|\\text{supp}(v_S)|}k^{\\frac{1}{2}}\\right)^{\\frac{1}{2}}               \\frac{1 }{ \\sqrt{|\\text{supp}(v_S)|} k^{\\frac{3}{2}}}   +\\frac{1 }{ \\sqrt{|\\text{supp}(v_S)|} k^{\\frac{3}{2}}}       +\\frac{1 }{ |\\text{supp}(v_S)| k}      + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}} \n\\right) \n\\end{equation}\n\\begin{equation}\n=   \\frac{\\sqrt{2}k^{\\frac{1}{4}} }{ |\\text{supp}(v_S)| k^{\\frac{3}{2}}} +\\frac{1 }{ |\\text{supp}(v_S)| k}          + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{3}{2}}}\n\\right) \n\\end{equation}\n\\begin{equation}\n= \\frac{\\sqrt{2}}{ |\\text{supp}(v_S)| k^{\\frac{5}{4}}}  +\\frac{1 }{ |\\text{supp}(v_S)| k}     + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{2}}}\n\\right) \n\\end{equation}\n\\begin{equation}\n= \\frac{1 }{ |\\text{supp}(v_S)| k}     + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{4}}}\n\\right) \n\\end{equation}\n\nTherefore the bound you are looking for is \\begin{equation}  \\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S-\n \\hat w_T|   = \\frac{1 }{ |\\text{supp}(v_S)| k}     + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{4}}}\n\\right) \n\\end{equation}\nIn particular since $|\\text{supp}(v_S)|$ is an integer and $|\\text{supp}(v_S)|> 1$ we can weaken this to\\begin{equation}  \\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S-\n \\hat w_T|   =  \\frac{1 }{  k}     + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{4}}}\n\\right) \n\\end{equation}\nOr recalling that $k = \\| v_S \\|^2$ we can equivalently right this as \\begin{equation}  \\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S-\n \\hat w_T|   = \\frac{1 }{ |\\text{supp}(v_S)| \\| v_S \\|^2}     + \\mathcal{O} \\left(\\frac{1}{\\| v_S \\|^{\\frac{5}{2}}}\n\\right) \n\\end{equation}\nand\\begin{equation}  \\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S-\n \\hat w_T|   =  \\frac{1 }{  \\| v_S \\|^2 }     + \\mathcal{O} \\left(\\frac{1}{\\| v_S \\|^{\\frac{5}{2}}}\n\\right) \n\\end{equation}\nBut most importantly we have that the vectors in $V_\\text{sum}$ get arbitrarily close for large $n$; i.e. by choosing say $S = \\{e_i \\ | \\ i \\in [n]\\}$ we have that\n\\begin{equation}  \\lim_{n \\to \\infty }\\max_{v_S \\in V_\\text{sum}}  \\min_{w_T \\in V_\\text{sum}} |\\hat v_S-\n \\hat w_T|    =\n\\end{equation}\n\\begin{equation} =\\lim_{n \\to \\infty } \\frac{1 }{ |\\text{supp}(v_S)| k}     + \\mathcal{O} \\left(\\frac{1}{k^{\\frac{5}{4}}} \\right)  \\leq  \\lim_{n \\to \\infty } \\frac{1 }{ |n| n}     + \\mathcal{O} \\left(\\frac{1}{n^{\\frac{5}{4}}} \\right)  = 0\n\\end{equation}\n\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/360487", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 1, "answer_id": 0}}
{"Q": "Looking for a combinatorial proof for a Catalan identity Let $C_n=\\frac1{n+1}\\binom{2n}n$ be the familiar Catalan numbers.\n\nQUESTION. Is there a combinatorial or conceptual justification for this identity?\n$$\\sum_{k=1}^n\\left[\\frac{k}n\\binom{2n}{n-k}\\right]^2=C_{2n-1}.$$\n\n", "A": "Expanding my previous comment into an answer at the OP's request. We can write\n$$\n\\frac{k}{n}\\binom{2n}{n-k}=A_k-B_k,\n$$\nwhere\n$$\nA_k=\\binom{2n-1}{n-k}=\\binom{2n-1}{n+k-1}, \\qquad B_k=\\binom{2n-1}{n+k}=\\binom{2n-1}{n-k-1}.\n$$\nThen\n$$\n\\sum_{k=1}^{n}\\left(\\frac{k}{n}\\binom{2n}{n-k}\\right)^2=\\sum_{k=1}^{n}(A_k^2+B_k^2)-\\sum_{k=1}^{n}(A_kB_k+B_kA_k).\n$$\nThe first sum on the right is\n$$\n\\sum_{k=1}^{n}\\left(\\binom{2n-1}{n-k}\\binom{2n-1}{n+k-1}+\\binom{2n-1}{n+k}\\binom{2n-1}{n-k-1}\\right)=\\\\\n=\\left(\\sum_{k=0}^{2n-1}\\binom{2n-1}{k}\\binom{2n-1}{2n-1-k}\\right)-\\binom{2n-1}{n}\\binom{2n-1}{n-1}=\\binom{4n-2}{2n-1}-\\binom{2n-1}{n}^2,\n$$\nand the second sum on the right is\n$$\n\\sum_{k=1}^{n}\\left(\\binom{2n-1}{n-k}\\binom{2n-1}{n+k}+\\binom{2n-1}{n+k}\\binom{2n-1}{n-k}\\right)=\\\\\n=\\left(\\sum_{k=0}^{2n-1}\\binom{2n-1}{k}\\binom{2n-1}{2n-k}\\right)-\\binom{2n-1}{n}^2=\\binom{4n-2}{2n}-\\binom{2n-1}{n}^2,\n$$\nso\n$$\n\\sum_{k=1}^{n}\\left(\\frac{k}{n}\\binom{2n}{n-k}\\right)^2=\\binom{4n-2}{2n-1}-\\binom{4n-2}{2n}=C_{2n-1}.\n$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/383314", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "13", "answer_count": 5, "answer_id": 2}}
{"Q": "Asymptotic analysis of $x_{n+1} = \\frac{x_n}{n^2} + \\frac{n^2}{x_n} + 2$ \nProblem: Let $x_1 = 1$ and $x_{n+1} = \\frac{x_n}{n^2} + \\frac{n^2}{x_n} + 2, \\ n\\ge 1$.\nFind the third term in the asymptotic expansion of $x_n$.\n\nI have posted it in MSE six months ago without solution for the third term\nhttps://math.stackexchange.com/questions/3801405/the-limit-and-asymptotic-analysis-of-a-n2-n-from-a-n1-fraca-nn.\nWe have $\\lim_{n\\to \\infty} (x_n - n) = \\frac{1}{2}$ (see [1]; I also give a solution with the help of computer in the link above).\nSo the first two terms in the asymptotic expansion of $x_n$ are $x_n \\sim n + \\frac{1}{2}$.\nEdit: In [1], the authors proved that $\\frac{1}{4n-2} \\le x_n - n - \\frac{1}{2} \\le \\frac{2}{2n-3}$ for all $n\\ge 3$.\nFor the third term, @Diger in MSE said $x_n \\sim n + \\frac{1}{2} + \\frac{5}{8n}$ (see @Diger's answer in the link above).\nHowever, I did some numerical experiment which does not support this result.\nI am not convinced of the numerical evidence due to finite precision arithmetic.\nI hope to prove or disprove it analytically.\nNumerical Experiment: If $x_n \\sim n + \\frac{1}{2} + \\frac{5}{8n}$,\nthen it should hold $16n(x_{2n} - 2n - \\frac{1}{2}) \\approx 5$ and $8(2n+1)(x_{2n+1} - (2n+1) - \\frac{1}{2}) \\approx 5$\nfor large $n$. When $n=1500$, I use Maple to get\n$16n(x_{2n} - 2n - \\frac{1}{2}) \\approx 4.368$ and $8(2n+1)(x_{2n+1} - (2n+1) - \\frac{1}{2}) \\approx 5.642$.\nWhen $n$ is larger (e.g., $n=10000$), the numerical result seems unreliable.\nI ${\\color{blue}{\\textbf{GUESS}}}$ that\n$$x_{2n} \\sim 2n + \\frac{1}{2} + \\frac{q_1}{2n},$$\n$$x_{2n+1} \\sim (2n+1) + \\frac{1}{2} + \\frac{q_2}{2n+1}$$\nwhere $q_1 + q_2 = \\frac{5}{4}$ and $q_1 \\ne q_2$ (if $q_1 = q_2$, then it is $x_n \\sim n + \\frac{1}{2} + \\frac{5}{8n}$).\n(Some numerical experiment shows $q_1 \\approx \\frac{61}{112}, q_2 \\approx \\frac{79}{112}$. But I am not convinced of it.)\nEdit: I give more analysis for my guess as an answer.\nAny comments and solutions are welcome and appreciated.\nReference\n[1] Yuming Chen, Olaf Krafft and Martin Schaefer, \u201cVariation of a Ukrainian Olympiad Problem: 10982\u201d,\nThe American Mathematical Monthly, Vol. 111, No. 7 (Aug. - Sep., 2004), pp. 631-632\n", "A": "Consider the substitutions\n\\begin{equation*}\n    x_n=n+1/2+y_n/n,\\quad y_n=u_n+5/8. \n\\end{equation*}\nThen $u_1=-9/8$ and\n\\begin{equation*}\n    u_{n+1}=f_n(u_n)\n\\end{equation*}\nfor $n\\ge1$, where\n\\begin{equation*}\n    f_n(u):=\\frac{-64 n^4 u-8 n^3 (4 u-13)+n^2 (56 u+115)+n (96 u+76)+4 (8 u+5)}{8 n^2 \\left(8 n^2+4 n+8 u+5\\right)}. \n\\end{equation*}\nDefine $c_n(u)$ by the identity\n\\begin{equation*}\n    f_n(u)=-u+\\frac{13}{8n}+\\frac{c_n(u)}{n^2}, \n\\end{equation*}\nso that\n\\begin{equation*}\n    c_n(u)=\\frac{n^2 \\left(64 u^2+96 u+63\\right)+n (11-8 u)+4 (8 u+5)}{8 \\left(8 n^2+4 n+8 u+5\\right)}. \n\\end{equation*}\nThen for $n\\ge1$\n\\begin{equation*}\n    u_{n+1}+u_n=\\frac{13}{8n}+\\frac{c_n(u)}{n^2} \\tag{1}\n\\end{equation*}\nand for $n\\ge2$\n\\begin{equation*}\n    u_{n+1}=f_n(f_{n-1}(u_{n-1}))=u_{n-1}-\\frac{13}{8n(n-1)}+\\frac{c_n(u_n)}{n^2}\n    -\\frac{c_{n-1}(u_{n-1})}{(n-1)^2}. \\tag{2}\n\\end{equation*}\nNote that\n\\begin{equation*}\n    u_{101}=-0.54\\ldots,\\quad u_{102}=0.56\\ldots,  \\tag{3}\n\\end{equation*}\nand\n\\begin{equation*}\n    0\\le c_n(u)\\le3  \n\\end{equation*}\nif $n\\ge10$ and $u\\in[-6/10,8/10]$. Therefore and because for natural $m\\ge102$ we have\n\\begin{equation*}\n    \\sum_{n=m}^\\infty\\Big(\\frac{13}{8n(n-1)}+\\frac3{(n-1)^2}\\Big)<\\frac5{m-2}\\le0.05,\n\\end{equation*}\nit follows from (2) and (3) by induction that for all $n\\ge101$ we have $u_n\\in[-6/10,8/10]$ and hence $0\\le c_n(u_n)\\le3$. So, again by (2), the sequences $(u_{2m})$ and $(u_{2m+1})$ are Cauchy-convergent and hence convergent. Moreover, by (1), $u_{n+1}+u_n\\to0$.\nThus, indeed\n\\begin{equation*}\n    y_{n+1}+y_n\\to5/4, \n\\end{equation*}\nand the sequences $(y_{2m})$ and $(y_{2m+1})$ are convergent. (The limits of these two sequences can in principle be found numerically with any degree of accuracy -- controlled by (2), say.)\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/384047", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "9", "answer_count": 1, "answer_id": 0}}
{"Q": "Decoupling a double integral I came across this question while making some calculations.\n\nQUESTION. Can you find some transformation to \"decouple\" the double integral as follows?\n$$\\int_0^{\\frac{\\pi}2}\\int_0^{\\frac{\\pi}2}\\frac{d\\alpha\\,d\\beta}{\\sqrt{1-\\sin^2\\alpha\\sin^2\\beta}}\n=\\frac14\\int_0^{\\frac{\\pi}2}\\frac{d\\theta}{\\sqrt{\\cos\\theta\\,\\sin\\theta}}\\int_0^{\\frac{\\pi}2}\\frac{d\\omega}{\\sqrt{\\cos\\omega\\,\\sin\\omega}}.$$\n\n", "A": "(Thanks go to Etanche and Jandri)\n\\begin{align}J&=\\int_0^{\\frac{\\pi}{2}}\\int_0^{\\frac{\\pi}{2}} \\frac{1}{\\sqrt{1-\\sin^2(\\theta)\\sin^2 \\varphi}}d\\varphi d\\theta\\\\\n &\\overset{z\\left(\\varphi\\right)=\\arcsin\\left(\\sin(\\theta)\\sin \\varphi\\right)}=\\int_0^{\\frac{\\pi}{2}} \\left(\\int_0^ \\theta\\frac{1}{\\sqrt{\\sin(\\theta-z)\\sin(\\theta+ z)}}dz\\right)d\\theta\\tag1\\\\\n &=\\frac{1}{2}\\int_0^{\\frac{\\pi}{2}} \\left(\\int_{u}^{\\pi-u}\\frac{1}{\\sqrt{\\sin u\\sin v}}dv\\right)du \\tag2\\\\\n &=\\frac{1}{2}\\int_0^{\\frac{\\pi}{2}} \\left(\\int_{u}^{\\frac{\\pi}{2}}\\frac{1}{\\sqrt{\\sin u\\sin v}}dv\\right)du+\\underbrace{\\frac{1}{2}\\int_0^{\\frac{\\pi}{2}} \\left(\\int_{\\frac{\\pi}{2}}^{\\pi-u}\\frac{1}{\\sqrt{\\sin u\\sin v}}dv\\right)du}_{w=\\pi-v}\\\\\n &=\\int_0^{\\frac{\\pi}{2}} \\left(\\int_{u}^{\\frac{\\pi}{2}}\\frac{1}{\\sqrt{\\sin u\\sin v}}dv\\right)du\\\\\n&\\overset{u\\longleftrightarrow v}=\\int_0^{\\frac{\\pi}{2}} \\left(\\int_{0}^{u}\\frac{1}{\\sqrt{\\sin u\\sin v}}dv\\right)du\\\\\n &=\\boxed{\\frac{1}{2}\\int_0^{\\frac{\\pi}{2}} \\int_0^{\\frac{\\pi}{2}}\\frac{1}{\\sqrt{\\sin u\\sin v}}dudv}\n \\end{align}\nand to obtain the form in the OP, finally substitute $u=2\\theta $, $v=2\\omega $.\n$(1)$: $\\displaystyle dz=\\dfrac{\\sqrt{\\sin^2\\theta-\\sin^2 z}}{\\sqrt{1-\\sin^2 z}}d\\varphi$, $\\sin^2 a-\\sin^2 b=\\sin(a-b)\\sin(a+b)$\n$(2)$: Change of variable $u=\\theta-z,v=\\theta+z$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/384145", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "17", "answer_count": 3, "answer_id": 2}}
{"Q": "A counterexample to: $\\frac{1-f(x)^2}{1-x^2}\\le f'(x)$ \u2014 revisited Can we find a counterexample to the following assertion?\nAssume that $f:[-1,1]\\to [-1,1]$ an odd function of class $C^3$, and assume thaht $f$ is a concave increasing diffeomorphism of $[0,1]$ onto itself. Then my examples say that $$\\frac{1-f(x)^2}{1-x^2}\\le f'(x),\\; x\\in (0,1).$$\n", "A": "I complete the reformulation given by Andrea Marino and give another counterexample.\nFirst, the inequality of the beginning can be written\n$$\\forall x \\in (0,1), \\quad \\frac{f'(x)}{1-f^2(x)} \\ge \\frac{1}{1-f^2(x)}$$\nand means that the function $x \\mapsto \\arg\\tanh(f(x))-\\arg\\tanh(x)$ is non-decreasing on $(0,1)$, or equivalently (composing with $\\tanh$) that the function\n$$g : x \\mapsto \\frac{f(x)-x}{1-xf(x)}$$\nis non-decreasing on $(0,1)$.\nNow, let\n$$f(x) := \\frac{1}{2} [x+1-(1-x)^3].$$\nThe function $f$ thus defined satisfies the assumptions. Let us compute the corresponding function $g$.\n\\begin{eqnarray*}\ng(x) &=& \\frac{[x+1-(1-x)^3]-2x}{2-x[x+1-(1-x)^3]} \\\\\n&=& \\frac{1-x-(1-x)^3}{2-x-x^2+x(1-x)^3} \\\\\n&=& \\frac{1-(1-x)^2}{2+x+x(1-x)^2} \\\\\n&=& \\frac{2x-x^2}{2+2x-2x^2+x^3} \\\\\n\\end{eqnarray*}\nThe quantities $u(x):=2x-x^2$ and $v(x):=2+2x-2x^2+x^3$ are positive on $[0,1]$ (since $x \\ge x^2$ on $[0,1]$), and $u'(1)=2-2=0$ whereas $v'(1)=2-4+3=1$. Hence $g$ is decreasing at the neighborhood of $1$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/421985", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "7", "answer_count": 2, "answer_id": 1}}
{"Q": "Parametrization of integral solutions of $3x^2+3y^2+z^2=t^2$ and rational solutions of $3a^2+3b^2-c^2=-1$ 1/ Is it known the parameterisation over $\\mathbb{Q}^3$ of the solutions of\n$3a^2+3b^2-c^2=-1$\n2/   Is it known the parameterisation over $\\mathbb{Z}^4$ of the solutions of\n$3x^2+3y^2+z^2=t^2$\nReferences, articles or books are welcome\nSincerely, John\n", "A": "For #1, we can take a particular solution such as $(a_0,b_0,c_0)=(0,0,1)$, and search parametric solution in the form: $(a,b,c)=(a_0+\\alpha t, b_0+\\beta t, c_0+t)$. Plugging it into the equation and solving for $t\\ne 0$, we get:\n$$t = \\frac{2}{3\\alpha^2 + 3\\beta^2 - 1}.$$\nSo, we get rational parametrization with parameters $\\alpha,\\beta\\in\\mathbb Q$:\n$$(a,b,c) = \\bigg(\\frac{2\\alpha}{3\\alpha^2 + 3\\beta^2 - 1},\\ \\frac{2\\beta}{3\\alpha^2 + 3\\beta^2 - 1},\\ 1 + \\frac{2}{3\\alpha^2 + 3\\beta^2 - 1}\\bigg).$$\n\nFor #2, we can similarly parametrize $3\\left(\\frac{x}{t}\\right)^2 + 3\\left(\\frac{y}{t}\\right)^2 + \\left(\\frac{z}{t}\\right)^2 = 1$ and then explicitly expand parameters as fractions, and set $t$ be the common denominator. This way we get parametrization:\n$$(x,y,z,t) = \\frac{p}{q}\\bigg(-2uw,\\ -2vw,\\ 3u^2 + 3v^2 - w^2,\\ 3u^2 + 3v^2 + w^2\\bigg),$$\nwhere parameters $u,v,w\\in\\mathbb Z$, and parameters $p,q\\in\\mathbb Z$ allow to scale the variables, with the requirement that $q$ represents a common divisor of the variables.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/422125", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 2, "answer_id": 0}}
{"Q": "Irreducibility measure of integer polynomials (Partial) Question in short: Let $p$ be a monic integer polynomial of degree $n$. Is there a natural number $k$ with $0 \\leq k \\leq n$ such that $p+k$ is irreducible over the integers?\nLonger version:\nLet $p$ be a monic polynomial over the integers. Define the irreducibility measure $d(p)$ of $p$ as the smallest integer $k \\geq 0$ such that $p+k$ is irreducible over the integers.\nDefine $M_n:=$ sup $\\{ d(p) | deg(p)=n \\}$ for $n \\geq 2$. Here $deg(p)$ is the degree of $p$.\n\nQuestion: Is it true that $M_n \\leq n$? (Answer no, by Joachim K\u00f6nig). Is there a good bound for $M_n$ ?\n\nThe question is based on some small computer experiments.\nedit: Sorry I forgot the condition that the polynomials are monic (I did all computer experiments with that assumption. The answer by Joachim K\u00f6nig gives a counterexample in the non-monic case).\n", "A": "For $f=x^6 - 3x^5 - 2x^4 + 10x^3 + x^2 - 8x - 5$, one has\n$$f=(x^3 - 2x^2 - 2x + 5)(x^3 - x^2 - 2x - 1),$$\n$$f+1=(x-2)(x^5 - x^4 - 4x^3 + 2x^2 + 5x + 2),$$\n$$f+2=(x^2-x-1)(x^4 - 2x^3 - 3x^2 + 5x + 3),$$\n$$f+3=(x^2-2)(x^4 - 3x^3 + 4x + 1),$$\n$$f+4=(x+1)(x^5 - 4x^4 + 2x^3 + 8x^2 - 7x - 1),$$\n$$f+5=x(x^5 - 3x^4 - 2x^3 + 10x^2 + x - 8),$$\n$$f+6=(x-1)(x^5 - 2x^4 - 4x^3 + 6x^2 + 7x - 1).$$\n(Found more or less by brute force.)\nPS: In order to not cause unnecessary confusion, the \"answer\" giving a counterexample for the ``non-monic case\", currently mentioned in the OP, was $f(x)=6x^2+7x$; this was removed as a separate answer after the OP had been altered.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/441141", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "9", "answer_count": 1, "answer_id": 0}}
