{"Q": "Verification of the Poincare Algebra The generators of the Poincare group $P(1;3)$ are supposed to obey the following commutation relation to be verified:\n$$\\left[ M^{\\mu\\nu}, P^{\\rho} \\right] = i \\left(g^{\\nu\\rho} P^{\\mu} - g^{\\mu\\rho} P^{\\nu} \\right)$$\nwhere $M^{\\mu\\nu}$ are the 6 generators of the Lorentz group and $P^\\mu$ are the 4 generators of the four-dimensional translation group $T(4)$.\nFor $\\mu = 3, \\nu=1, \\rho=0$ the LHS becomes: $ [M^{31},P^{0}] = M^{31}P^{0} - P^{0}M^{31}$.\nHere $M^{31} = J^2 = -J_2= \\begin{pmatrix}\n       0 & 0 & 0 & 0   \\\\\n       0 & 0 & 0 & -i   \\\\\n       0 & 0 & 0 & 0   \\\\\n       0 & i & 0 & 0   \n     \\end{pmatrix}$ and $ P^0 = P_0 = -i \\begin{pmatrix}\n       0 & 0 & 0 & 0 & 1  \\\\\n       0 & 0 & 0 & 0 & 0  \\\\\n       0 & 0 & 0 & 0 & 0  \\\\\n       0 & 0 & 0 & 0 & 0  \\\\\n       0 & 0 & 0 & 0 & 0 \n     \\end{pmatrix}$.\nMy question is that how can I multiply $M^{31}$ and $P^0$ when they are $4\\times4$ and $5\\times 5$ matrices respectively? \n", "A": "Consider $$M_{31} = \\begin{pmatrix}\n       0 & 0 & 0 & 0  & 0 \\\\\n       0 & 0 & 0 & -i & 0  \\\\\n       0 & 0 & 0 & 0  & 0  \\\\\n       0 & i & 0 & 0  & 0  \\\\\n       0 & 0 & 0 & 0  & 0 \n     \\end{pmatrix} \\text{ and } P_0 = -i \\begin{pmatrix}\n       0 & 0 & 0 & 0 & 1  \\\\\n       0 & 0 & 0 & 0 & 0  \\\\\n       0 & 0 & 0 & 0 & 0  \\\\\n       0 & 0 & 0 & 0 & 0  \\\\\n       0 & 0 & 0 & 0 & 0 \n     \\end{pmatrix},$$\nThen the commutator vanishes! As expected from $\\left[ M_{31}, P_{0} \\right] = i \\left(g_{10} P_{3} - g_{30} P_{1} \\right) = 0$.\nIf you take \n$$M_{01} = \n\\begin{pmatrix}\n 0 & i & 0 & 0 & 0 \\\\\n i & 0 & 0 & 0 & 0 \\\\\n 0 & 0 & 0 & 0 & 0  \\\\\n 0 & 0 & 0 & 0 & 0  \\\\\n 0 & 0 & 0 & 0 & 0 \n\\end{pmatrix}\n\\text{ and }\nP_0 = -i\n\\begin{pmatrix}\n  0 & 0 & 0 & 0 & 1  \\\\\n  0 & 0 & 0 & 0 & 0  \\\\\n  0 & 0 & 0 & 0 & 0  \\\\\n  0 & 0 & 0 & 0 & 0  \\\\\n  0 & 0 & 0 & 0 & 0 \n\\end{pmatrix},$$\nthen\n$$\n\\left[M_{01},P_0\\right] = -i\n\\begin{pmatrix}\n 0 & 0 & 0 & 0 & 0 \\\\\n 0 & 0 & 0 & 0 & 1 \\\\\n 0 & 0 & 0 & 0 & 0  \\\\\n 0 & 0 & 0 & 0 & 0  \\\\\n 0 & 0 & 0 & 0 & 0 \n\\end{pmatrix} = P_1.\n$$\nAnd so on!\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/127690", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "What does this imaginary number mean for time and velocity? As some have pointed out in the chat, perhaps the question that I should have asked is, am I really integrating for velocity? My integration might be misleading in that it integrates for something but probably not velocity. Velocity could not be in the same direction as acceleration unless the object is already at terminal velocity - in which case acceleration = 0 and it therefore has no direction. A paradox, which perhaps explains for my imaginary numbers. I believe that I have understood my conceptual misunderstanding.\nIn regards to 2D kinematics, I essentially did partial fractions and integrated for time as a function of velocity, and suddenly, I have to deal with an imaginary number! My specific problem is not so much about my working out - it's about why I am obtaining imaginary numbers? Is this inherent of the coefficient of drag and lift equations? I can't see why it would be.\nI initially had multiple acceleration functions in terms of velocity, using the equations for coefficient of drag, lift and gravity.\n\\begin{align}\nma_x &= F_L\\sin\\theta-F_D\\cos\\theta \\\\\nma_y&=mg-F_L\\cos\\theta-F_D\\sin\\theta\n\\end{align}\nwith\n$$\nF=C\\frac{pv^2}{2}A.\n$$\nI broke this down into horizontal ($h$) and vertical components ($l$). My third line comes from expanding and simplify the equations of coefficients of drag, lift and gravity. \n $$ acceleration{^2} = h^2 +l^2$$ \n $$  \\frac{dv}{dt} = \\sqrt{h^2 +l^2 }$$ \n$$\\sqrt{h^2 +l^2 } = \\sqrt{av^4 -bv^2 + \\frac{c}{a} }$$\n$v$ is velocity, $t$ is time, and all other letters are pre-determined constants.  Rearrange equation to produce integrals and isolate dt \n$$\\begin{align}\\int \\left ( \\frac{\\mathrm dv}{\\sqrt{av^4 -bv^2 + \\frac{c}{a}}} \\right ) &= \\int \\mathrm dt \\\\\n\\end{align} \\\\\n\\frac{\\mathrm dv}{\\sqrt{a[\\left(v^2 - \\frac{b}{2a}\\right)^2 - \\left(\\frac{b}{2a}\\right)^2 + \\frac{c}{a}]}} \\\n$$\nIn order to keep things easier to read, substitute a value for $D$.\n$$D = \\left(\\frac{b}{2a}\\right)^2 - \\frac{c}{a}$$ $$\n\\\\\n\\frac{\\mathrm dv}{\\sqrt{a[\\left(v^2 - \\frac{b}{2a}\\right)^2 - D]}} \\\\\n\\frac{1}{\\sqrt{a}} \\frac{\\mathrm dv}{\\sqrt{(v^2 - \\frac{b}{2a})^{2} - D}} \n$$\nPretend for a moment that constant $1/\\sqrt a$ is not there, to make it easier to write.\n$$\n\\frac{\\mathrm dv}{((v^2 - \\frac{b}{2a}) + D^{1/2})^{1/2}\\cdot((v^2 - \\frac{b}{2a}) - D^{1/2})^{1/2}} \n$$\nPartial fractions.\n$$\n\\int  \\frac{A}{((v^2 - \\frac{b}{2a}) + D^{1/2})^{1/2}} + \\frac{B}{((v^2 - \\frac{b}{2a}) - D^{1/2})^{1/2}} \\mathrm dv = t\n$$\nEquate coefficients.\n$$\nA\\sqrt{-2\\sqrt{D}} = 1.\n$$\nThis is what makes us have the imaginary number.\n$$\nA = \\frac{1}{\\sqrt{-2\\sqrt{D}}} $$ and $$ B = \\frac{1}{({4D)^{1/4}}}.\n$$\nI did everything else on Wolfram Alpha, including the integration. The result is,\n$$\n\\frac{\\log\\left(\\sqrt{2}\\sqrt{\\frac{-2a\\sqrt{D}+2av^2-b}{a}}+2v\\right)}{\\sqrt{2}\\sqrt[4]{D}}+\\frac{\\log\\left(\\sqrt{2}\\sqrt{\\frac{2a\\sqrt{D}+2av^2-b}{a}}+2v\\right)}{\\sqrt{2}\\sqrt{-\\sqrt D}}=t\n$$\n", "A": "Complex velocity doesn't make sense in physics so you have to choose the parameters $a,b,c$ so you don't get an imaginary velocity.\n\\begin{align*}\n & \\sqrt{a v^4- b v^2+\\frac{c}{a}}\\quad\\Rightarrow\\quad a v^4- b v^2+\\frac{c}{a} \\ge 0\\\\\n  &v^2 \\mapsto x\\quad\\Rightarrow\\\\ &g_1=a x^2- b x+\\frac{c}{a} \\ge 0\\\\\n  &g_1=(x-\\tau_1)\\,(x-\\tau_2)\\ge 0\\quad\\text{with:}\\\\\n  &\\tau_1=-\\frac{b}{2\\,a}+\\frac{1}{2\\,a}\\,\\sqrt{b^2-4\\,c}\\\\\n   &\\tau_2=-\\frac{b}{2\\,a}-\\frac{1}{2\\,a}\\,\\sqrt{b^2-4\\,c}\\\\\n   &\\quad \\Rightarrow\\quad \\\\&b^2-4\\,c \\ge 0\\quad b\\ge 2\\,\\sqrt{c}\n   \\,\\quad c \\ge 0\\\\\n   &\\text{with:}\\quad v^2=x\\quad\\Rightarrow\\quad x > 0&\\\\\\quad \\Rightarrow\\\\\n   &g_1\\ge 0\\quad \\,\\Rightarrow\\quad \\\\\\\\&x - \\tau_1\\ge 0 \\quad\\text{and}\\quad  x-\\tau_2\\ge 0 \\\\&\\text{or}\\\\\n   &x- \\tau_1\\le 0 \\quad\\text{and}\\quad  x- \\tau_2\\le 0\n\\end{align*}\nConsequences:\n\\begin{align*}\n  &c \\ge 0\\\\\n  &b \\ge 2\\sqrt{c}\\\\\n  &a > 0\\,,\\text{$x$ must be positive !!}\\\\\\\\\n  & \\tau_1 \\le x \\le \\inf\n\\end{align*}\nExample:\n\\begin{align*}\n  &c=3\\,,b=2\\sqrt{3}+3\\,,a=2\\\\\n  &\\Rightarrow\\\\\n  &\\tau_1=2.98\\,,\\tau_2=0.25\\\\\n  &x > \\tau_1=4\\,\\Rightarrow\\quad g_1=7.6 > 0\\\\\n  &v=\\sqrt{x}=2\\,,\\checkmark\n\\end{align*}\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/411362", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 1, "answer_id": 0}}
{"Q": "The Electromagetic Tensor and Minkowski Metric Sign Convention I am trying to figure out how to switch between Minkowski metric tensor sign conventions of (+, -, -, -) to (-, +, +, +) for the electromagnetic tensor $F^{\\alpha \\beta}$. \nFor the convention of (+, -, -, -) I know the contravariant and covarient forms of the electromagnetic tensor are:\n$$ F^{\\alpha \\beta} =\n    \\begin{bmatrix}\n    0 & -\\frac{E_{x}}{c} & -\\frac{E_{y}}{c} & -\\frac{E_{z}}{c} \\\\\n    \\frac{E_{x}}{c} & 0 & -B_{z} & B_{y} \\\\\n    \\frac{E_{y}}{c} & B_{z} & 0 &  -B_{x} \\\\\n    \\frac{E_{z}}{c} & -B_{y} & B_{x} & 0 \\\\\n    \\end{bmatrix}\n$$\nand\n$$ F_{\\alpha \\beta} = \\eta_{\\alpha \\mu} F^{\\mu v} \\eta_{v \\beta} = \n    \\begin{bmatrix}\n    0 & \\frac{E_{x}}{c} & \\frac{E_{y}}{c} & \\frac{E_{z}}{c} \\\\\n    -\\frac{E_{x}}{c} & 0 & -B_{z} & B_{y} \\\\\n    -\\frac{E_{y}}{c} & B_{z} & 0 &  -B_{x} \\\\\n    -\\frac{E_{z}}{c} & -B_{y} & B_{x} & 0 \\\\\n    \\end{bmatrix}.\n$$\nNow for the convention of (-, +, +, +) are the contravariant and covariant forms of the electromagnetic tensor just switched from above along with signs?:\n$$ F^{\\alpha \\beta}= \n    \\begin{bmatrix}\n    0 & \\frac{E_{x}}{c} & \\frac{E_{y}}{c} & \\frac{E_{z}}{c} \\\\\n    -\\frac{E_{x}}{c} & 0 & B_{z} & -B_{y} \\\\\n    -\\frac{E_{y}}{c} & -B_{z} & 0 &  B_{x} \\\\\n    -\\frac{E_{z}}{c} & B_{y} & -B_{x} & 0 \\\\\n    \\end{bmatrix}\n$$\nand\n$$ F_{\\alpha \\beta} = \\eta_{\\alpha \\mu} F^{\\mu v} \\eta_{v \\beta} =\n    \\begin{bmatrix}\n    0 & -\\frac{E_{x}}{c} & -\\frac{E_{y}}{c} & -\\frac{E_{z}}{c} \\\\\n    \\frac{E_{x}}{c} & 0 & B_{z} & -B_{y} \\\\\n    \\frac{E_{y}}{c} & -B_{z} & 0 &  B_{x} \\\\\n    \\frac{E_{z}}{c} & B_{y} & -B_{x} & 0 \\\\\n    \\end{bmatrix}~?\n$$\nBasically, I am trying to figure out how to switch between the two sign conventions.\n", "A": "I use this way:\n\\begin{equation}\\tag{1}\nF_{ab} = \\partial_a \\, A_b - \\partial_b \\, A_a,\n\\end{equation}\nwhere \n\\begin{equation}\\tag{2}\nA^a = (\\phi, \\, A_x, \\, A_y, \\, A_z), \\qquad\\qquad A_a = (\\phi, - A_x, - A_y, - A_z).\n\\end{equation}\nThen, we have:\n\\begin{align}\nE_i &= \\Big( -\\, \\vec{\\nabla} \\, \\phi - \\frac{\\partial \\vec{A}}{\\partial t} \\Big)_i, \\tag{3} \\\\[12pt]\nB_i &= (\\vec{\\nabla} \\times \\vec{A})_i. \\tag{4}\n\\end{align}\n(1) and sign convention (2) implies\n\\begin{equation}\\tag{5}\nF_{0 i} = \\partial_0 \\, A_i - \\partial_i \\, A_0 \\equiv E_i.\n\\end{equation}\nAlso: $F^{0 i} = -\\, E_i$.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/476673", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 2, "answer_id": 0}}
{"Q": "Landau-Lifshitz Equation of Motion for Triangular Heisenberg Antiferromagnet There is a paper (PhysRevB.95.014435) in which the dispersion relation for some Heisenberg model on the honeycomb lattice is derived from the Landau-Lifshitz equation:\n\\begin{align}\n\\frac{d S_i}{dt} = - S_i \\times \\mathcal H_{\\rm eff} \n\\end{align}\nTheir attempt from Eq. 2 to Eq.4 is pretty simple and I'll try the same for the 2D triangular Heisenberg antiferromagnet (THAF) (in xy-plane), which has a much simpler Hamiltonian:\n\\begin{align}\n \\mathcal H = \\sum_{\\langle {ij}\\rangle  } J S_i S_j,\\quad  \\mathcal H_{\\rm eff} = J \\sum_j S_j \n\\end{align}\nwhere $\\langle {ij}\\rangle$ sums over all nearest neighbors.\nThere are some papers out there (for example PhysRevB.74.180403) which have derived the dispersion to be\n\\begin{align}\n\\omega_{\\bf k} = \\sqrt{(1- \\gamma_{\\bf k} ) ( 1+ 2 \\gamma_{\\bf k} ) } \\label{eq:thaf_disp}\n\\end{align}\nwith\n\\begin{align}\n\\gamma_{\\bf k} = \\frac{1}{z} \\sum_{j} \\mathrm{e}^{i \\bf{k}( \\bf{R}_i - \\bf{R}_j )} =  \\frac{1}{3}\\left(\\cos k_{x}+2 \\cos \\frac{k_{x}}{2} \\cos \\frac{\\sqrt{3}}{2} k_{y}\\right)  \\, . \n\\end{align}\nThe ground-state of the THAF is the $120^{\\circ}$-Neel order. My idea is similar to the derivation in Linear Spin Wave Theory and I'm starting by some rotation of spin vectors\n\\begin{align}\nS_{i \\in A} &= (\\delta m_i^{x}, \\delta m_i^{y}, 1)  \\\\\nS_{i \\in B } &= ( \\sqrt{3}/2 \\delta m_i^{y} - 1/2 \\delta m_i^{x}, -\\sqrt{3}/2 \\delta m_i^{x} - 1/2 \\delta m_i^{y}, 1) \\\\\nS_{i \\in C} &= ( -\\sqrt{3}/2 \\delta m_i^{y} - 1/2 \\delta m_i^{x}, \\sqrt{3}/2 \\delta m_i^{x} - 1/2 \\delta m_i^{y}, 1) \n\\end{align}\nwhere A,B,C are the three sublattices of the ground-state and  $\\delta m \\ll 1$ . Then I tried to solve the Landau-Lifshitz equation:\n\\begin{align*}\n \\frac{d S_{i \\in A}}{dt} &=- \\begin{pmatrix}\n \\delta m_i^{x} \\\\ \\delta m_i^{y} \\\\ 1\n \\end{pmatrix} \\times \\left(\\sum_j J S_{j\\in B} +  J S_{j \\in C}\\right)  =- \\sum_j J \\begin{pmatrix}\n \\delta m_i^{x} \\\\ \\delta m_i^{y} \\\\ 1\n \\end{pmatrix} \\times \\begin{pmatrix}\n - \\delta m_j^{x} \\\\ - \\delta m_j^{y} \\\\ 2 \n \\end{pmatrix} \\approx - \\sum_jJ \\begin{pmatrix}\n \\delta m_j^{y} + 2 \\delta m_i^{y} \\\\ - \\delta m_j^{x} - 2 \\delta m_i^{x} \\\\ 0 \n \\end{pmatrix} \\\\\n \\frac{d S_{i \\in B}}{d t} &= -\\begin{pmatrix}\n \\frac{\\sqrt{3}}{2} \\delta m_i^{y} - \\frac{1}{2}\\delta m_i^{x} \\\\ -\\frac{\\sqrt{3}}{2} \\delta m_i^{x} - \\frac{1}{2} \\delta m_i^{y} \\\\ 1 \n \\end{pmatrix} \\times \\left(\\sum_j J S_{j \\in A} + J S_{j \\in C} \\right) \\\\\n &= - \\sum_j J \\begin{pmatrix}\n\\frac{\\sqrt{3}}{2} \\delta m_i^{y} - \\frac{1}{2} \\delta m_i^{x} \\\\ -\\frac{\\sqrt{3}}{2} \\delta m_i^{x} - \\frac{1}{2} \\delta m_i^{y} \\\\ 1 \n \\end{pmatrix}  \\times \\begin{pmatrix}\n \\frac{1}{2} \\delta m_j^{x} - \\frac{\\sqrt{3}}{2} \\delta m_j^{y} \\\\ \\frac{\\sqrt{3}}{2} \\delta m_j^{x} + \\frac{1}{2} \\delta m_j^{y} \\\\ 2 \n \\end{pmatrix} \\approx - \\sum_j J \\begin{pmatrix}\n -(\\sqrt{3} \\delta m_i^{x} + \\delta m_i^{y}) - ( \\frac{\\sqrt{3}}{2} \\delta m_j^{x} + \\frac{1}{2} \\delta m_j^{y} ) \\\\ \\frac{1}{2} \\delta m_j^{x} - \\frac{\\sqrt{3}}{2}  \\delta m_j^{y}  - (\\sqrt{3} \\delta m_i^{y} -  \\delta m_i^{x}) \\\\ 0 \n \\end{pmatrix} \\\\\n &=\\sum_j  J\\begin{pmatrix}\n \\frac{\\sqrt{3}}{2} (2 \\delta m_i^{x} + \\delta m_j^{x} ) + \\frac{1}{2}(2 \\delta m_i^{y} +\\delta m_j^{y} ) \\\\ \n\\frac{\\sqrt{3}}{2} (2\\delta m_i^{y} + \\delta m_j^{y} ) -\\frac{1}{2} (2\\delta m_i^{x} + \\delta m_j^{x}  ) \\\\\n0\n \\end{pmatrix} \\\\\n \\frac{d S_{i \\in C}}{d t} &= - \\sum_j \\begin{pmatrix}\n -\\frac{\\sqrt{3}}{2} \\delta m_i^{y} - \\frac{1}{2} \\delta m_i^{x} \\\\ \\frac{\\sqrt{3}}{2} \\delta m_i^{x} - \\frac{1}{2} \\delta m_i^{y} \\\\ 1 \n \\end{pmatrix} \\times \\begin{pmatrix}\n \\frac{\\sqrt{3}}{2} \\delta m_j^{y} + \\frac{1}{2} \\delta m_j^{x} \\\\ -\\frac{\\sqrt{3}}{2} \\delta m_j^{x} + \\frac{1}{2} \\delta m_j^{y}  \\\\\n 2 \n \\end{pmatrix} \\approx - \\sum_j J \\begin{pmatrix}\n \\sqrt{3} \\delta m_i^{x} - \\delta m_i^{y} - (-\\frac{\\sqrt{3}}{2} \\delta m_j^{x} + \\frac{1}{2} \\delta m_j^{y}) \\\\\n (\\frac{\\sqrt{3}}{2} \\delta m_j^{y} + \\frac{1}{2} \\delta m_j^{x}) + \\sqrt{3} \\delta m_i^{y} + \\delta m_i^{x} \\\\ 0 \n \\end{pmatrix} \\\\\n &= \\sum_j  J \\begin{pmatrix}\n\\frac{1}{2} (2\\delta m_i^{y} + \\delta m_j^{y}) - \\frac{\\sqrt{3}}{2} (2 \\delta m_i^{x} + \\delta m_j^{x}) \\\\\n- \\frac{\\sqrt{3}}{2} (2\\delta m_i^{y} + \\delta m_j^{y}) - \\frac{1}{2} (2\\delta m_i^{x} + \\delta m_j^{x}) \\\\ 0 \n \\end{pmatrix}\n\\end{align*}\nBy using Bloch-Theorem:\n\\begin{align}\n\\delta m_i^{x} = X \\exp(i \\left(  \\bf{k} \\bf{R}_i - \\omega t \\right)  ),  \\quad \\delta m_i^{y} = Y \\exp(i \\left(  \\bf{k} \\bf{R}_i - \\omega t \\right)  )\n\\end{align}\nSince I only have now one sublattice I don't need $X_A$, $X_B$ and $X_C$ etc. like in the paper. If you compare left-hand and right-hand side of the those equations of motions all do have the same structure. This structure looks like\n\\begin{align}\n i \\omega \\begin{pmatrix}\n X \\\\\n Y\n \\end{pmatrix} \\mathrm{e}^{i (\\bf{k} \\bf{R}_i - \\omega t)} = \\sum_j J \\begin{pmatrix}\n - 2 Y  \\\\\n 2X   \n \\end{pmatrix}\\mathrm{e}^{i (\\bf{k} \\bf{R}_i - \\omega t)} + \\sum_j J\\begin{pmatrix}\n -Y \\\\\n X\n \\end{pmatrix} \\mathrm{e}^{i (\\bf{k} \\bf{R}_j - \\omega t)} \n\\end{align}\nwhere the Bloch theorem is already used.\nThis would then lead to the following matrix\n\\begin{align}\n i \\omega \\begin{pmatrix}\n X \\\\\n Y\n \\end{pmatrix} = J  \\begin{pmatrix}\n 0 & -2 - \\gamma_k \\\\\n 2  + \\gamma_k & 0 \n \\end{pmatrix} \\begin{pmatrix}\n X \\\\\n Y \n \\end{pmatrix} = H \\begin{pmatrix}\n X \\\\\n Y \n \\end{pmatrix}\n\\end{align}\nThe paper sugested using $\\psi^{\\pm} = (X\\pm iY)/\\sqrt{2}$. This can be achieved by the Matrix\n\\begin{align}\nU = \\begin{pmatrix}\n1 & i \\\\\n1 & -i \n\\end{pmatrix}\n\\end{align}\nand by calculating $i/2 \\sigma_z UHU^{-1}$ I ended up with an hermitian matrix which uses $\\psi^{\\pm}$ as the amplitudes like sugested in the paper above:\n\\begin{align}\n\\begin{pmatrix}\n- \\gamma_k - 2 & 0 \\\\\n0 & \\gamma_k + 2\n\\end{pmatrix} \n\\end{align}\nwhich would lead to $\\omega_k = \\pm \\sqrt{(\\gamma_k + 2)^2}$ which is obviously wrong but I cannot figure out where my mistake is or where I'm thinking wrong.\n", "A": "I see two possible problems in your consideration.\n\n*\n\n*You've investigated perturbations of ferromagnetic ground state. When spin variations $\\delta m$ are zeros, spins on three sublattices are the same:\n$$\nS_i = (0, 0, 1),\\quad \\forall i.\n$$\n\n\n*The Landau-Lifshitz equation is a nonlinear one. Effective field ${\\cal H}_{i,{\\rm eff}}$ depends on neighboring spins. Hence you need to take into account variations of effective field:\n$$\n\\frac{d \\delta S_i}{dt} = -\\delta S_i \\times {\\cal H}_{i,{\\rm eff}} - S_i \\times \\delta {\\cal H}_{i,{\\rm eff}}.\n$$\nI didn't analyze your application of the Bloch theorem. I think there also could be problems. Neel state on triangular lattice is invariant under translation of states of triangular cells of spins, not of individual spins.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/589583", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 1, "answer_id": 0}}
{"Q": "Problem with the proof that for every timelike vector there exists an inertial coordinate system in which its spatial coordinates are zero I am reading lecture notes on special relativity and I have a problem with the proof of the following proposition.\nProposition. If $X$ is timelike, then there exists an inertial coordinate system in which $X^1 = X^2 = X^3 = 0$.\nThe proof states that as $X$ is timelike, it has components of the form $(a, p\\,\\mathbf{e})$, where $\\mathbf{e}$ is a unit spatial vector and $\\lvert a \\rvert > \\lvert p \\rvert$. Then one considers the following four four-vectors:\n\\begin{align*}\n\\frac{1}{\\sqrt{a^2 - p^2}}(a, p\\,\\mathbf{e}) & & \\frac{1}{\\sqrt{a^2 - p^2}}(p, a\\,\\mathbf{e}) & & (0, \\mathbf{q}) & & (0, \\mathbf{r})\\,,\n\\end{align*}\nwhere $\\mathbf{q}$ and $\\mathbf{r}$ are chosen so that $(\\mathbf{e}, \\mathbf{q}, \\mathbf{r})$ form an orthonormal triad in Euclidean space. Then the proof concludes that these four-vectors define an explicit Lorentz transformation and stops there.\nFor me this explicit Lorentz transformation is represented by the following matrix.\n\\begin{bmatrix}\n\\frac{1}{\\sqrt{a^2 - p^2}} a & \\frac{p}{\\sqrt{a^2 - p^2}} & 0 & 0 \\\\\n\\frac{p}{\\sqrt{a^2 - p^2}} e^1 & \\frac{a}{\\sqrt{a^2 - p^2}} e^1 & q^1 & r^1 \\\\\n\\frac{p}{\\sqrt{a^2 - p^2}} e^2 & \\frac{a}{\\sqrt{a^2 - p^2}} e^2 & q^2 & r^2 \\\\\n\\frac{p}{\\sqrt{a^2 - p^2}} e^3 & \\frac{a}{\\sqrt{a^2 - p^2}} e^3 & q^3 & r^3 \\\\\n\\end{bmatrix}\nHowever, multiplying the column vector $(X^0, X^1, X^2, X^3)$ by the matrix above does not seem to yield a column vector whose spatial components are zero.\nWhat did I miss?\n", "A": "Actually, your matrix can be greatly simplified as\n$$\nM =\n\\begin{bmatrix}\n\\frac{1}{\\sqrt{a^2 - p^2}} a & \\frac{p}{\\sqrt{a^2 - p^2}} & 0 & 0 \\\\\n\\frac{p}{\\sqrt{a^2 - p^2}} & \\frac{a}{\\sqrt{a^2 - p^2}} & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n\\end{bmatrix}\n$$\nsince $(\\mathbf{e}, \\mathbf{q}, \\mathbf{r})$ forms an orthonormal triad, hence $e_1 = q_2 = r_3 = 1$ and the other coefficients are zero.\nNow, as pointed out by Valter Moretti in his comment, the matrix you're looking for is the inverse of this matrix. An easy calculation gives the inverse.\n$$\nM^{-1} =\n\\frac{1}{(a^2 - p^2)^{\\frac{3}{2}}} \n\\begin{bmatrix}\na(a^2 - p^2) & -p(a^2 - p^2) & 0 & 0 \\\\\n-p(a^2 - p^2) & a(a^2 - p^2) & 0 & 0 \\\\\n0 & 0 & (a^2 - p^2)^{\\frac{3}{2}} & 0 \\\\\n0 & 0 & 0 & (a^2 - p^2)^{\\frac{3}{2}}\n\\end{bmatrix}\n$$\nFinally, one easily checks the result as follows.\n$$\nM^{-1} \\times \n\\begin{bmatrix}\na \\\\\np \\\\\n0 \\\\\n0\n\\end{bmatrix}\n= \n\\begin{bmatrix}\n\\sqrt{a^2 - p^2} \\\\\n0 \\\\\n0 \\\\\n0 \n\\end{bmatrix}\n$$\nNote that taking $\\mathbf{q}$ and $\\mathbf{r}$ such that $(\\mathbf{e}, \\mathbf{q}, \\mathbf{r})$ forms an orthonormal triad is equivalent to doing a spatial rotation such that only $X^1$ is nonvanishing. Thus, a more geometric, less algebraic, proof will start with a spatial rotation then will proceed with a boost along the $x$-axis.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/592938", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 3, "answer_id": 0}}
{"Q": "Dimensional regularization: order of integration This is a two-loop calculation in dim reg where I seem to be getting different results by integrating it in different orders. I am expanding it about $D=1$. What rule am I breaking?\n$$\\int \\frac{d^{D} p}{(2\\pi)^D}\\frac{d^{D}q}{(2\\pi)^D}\\frac{p^2+4m^2}{(q^2+m^2)((q-p)^2+m^2)}=?$$\n\nIf we integrate $q$ first, the inner integral converges in $D=1$\n$$\\int \\frac{d^{D}q}{(2\\pi)^D}\\frac{1}{(q^2+m^2)((q-p)^2+m^2)}=\\frac{1}{m}\\frac{1}{p^2+4m^2}$$\nthen integrating over $p$, by the rules of dimensional regularization we have\n$$\\int \\frac{d^{D} p}{(2\\pi)^D}\\frac{1}{m}\\frac{p^2+4m^2}{p^2+4m^2}=0.$$\n\nIf we integrate $p$ first we have\n$$\\int \\frac{d^{D} p}{(2\\pi)^D}\\frac{p^2+4m^2}{(q-p)^2+m^2}=\\int \\frac{d^{D} u}{(2\\pi)^D}\\frac{u^2+2u\\cdot q +q^2+4m^2}{u^2+m^2}=\\frac{q^2+4m^2}{2m}+\\int \\frac{d^{D} u}{(2\\pi)^D}\\frac{u^2}{u^2+m^2}$$\nwhere in the last equality we threw away the $u\\cdot q$ term by symmetric integration, and split off the terms in the numerator that converge in $D=1$. The remaining term is a common integral in dim reg (though perhaps the limit $D=1$ is not)\n$$\\int \\frac{d^{D} u}{(2\\pi)^D}\\frac{u^2}{u^2+m^2}=\\frac{1}{(4\\pi)^{D/2}}\\frac{D}{2}\\Gamma(-D/2)(m^2)^{D/2}= -\\frac{m^2}{2m}$$\nwhere we used $\\Gamma(-1/2)=-2\\sqrt{\\pi}$.\nNow integrating the outer integral over $q$ using the same rules discussed above,\n$$\\int \\frac{d^{D} q}{(2\\pi)^D}\\frac{1}{2m}\\frac{q^2+3m^2}{q^2+m^2}=\\frac{1}{2}\\neq 0$$\nWhat part is invalid?\n", "A": "I'd say, when you set\n$$\n\\int \\frac{d^{D}q}{(2\\pi)^D}\\frac{1}{(q^2+m^2)((q-p)^2+m^2)}=\\frac{1}{m}\\frac{1}{p^2+4m^2}\n$$\nthe correct answer actually has a $+\\mathcal O(d-1)$ piece. The $p$ integral has $1/(d-1)$ divergences which, when multiplied by the missing subleading piece, leaves a finite contribution.\nWe can do the integrals exactly in $d$. For the $q$ integral we combine denominators \u00e0 la Feynman, and do the linear shift $q\\to q+(1-x)p$. We get\n$$\n\\frac{2 \\pi ^{d/2}}{(2 \\pi )^d \\Gamma \\left(\\frac{d}{2}\\right)}\\int_0^\\infty\\frac{q^{d-1}}{\\left(m^2-p^2 (x-1) x+q^2\\right)^2}\\,\\mathrm dq=\\frac{2^{-d-1} (2-d) \\pi ^{1-\\frac{d}{2}} \\csc \\left(\\frac{\\pi  d}{2}\\right) }{\\Gamma \\left(\\frac{d}{2}\\right)}\\left(\\frac{1}{m^2-p^2 (x-1) x}\\right)^{2-\\frac{d}{2}}\n$$\nNext we evaluate the $p$ integral:\n\\begin{align}\n-\\frac{2^{-d-1} (d-2) \\pi ^{1-\\frac{d}{2}} \\left(2 \\pi ^{d/2} \\csc \\left(\\frac{\\pi  d}{2}\\right)\\right)}{(2 \\pi )^d \\Gamma \\left(\\frac{d}{2}\\right)^2}\\int_0^\\infty p^{d-1} \\left(4 m^2+p^2\\right) \\left(\\frac{1}{m^2-p^2 (x-1) x}\\right)^{2-\\frac{d}{2}}\\,\\mathrm dp=\\\\\n=-2^{-2 d-1} d \\pi ^{-d} m^{2 d-2} (-((x-1) x))^{-\\frac{d}{2}-1} (8 d (x-1) x+d-8 (x-1) x) \\Gamma (-d)\n\\end{align}\nFinally, we perform the $x$ integral:\n\\begin{align}\n\\frac{2^{-2 d-1} (d-2) \\pi ^{1-d} m^{2 d-2} \\left(\\csc \\left(\\frac{\\pi  d}{2}\\right) \\Gamma \\left(\\frac{d}{2}+1\\right) \\Gamma (-d)\\right)}{\\Gamma \\left(2-\\frac{d}{2}\\right) \\Gamma \\left(\\frac{d}{2}\\right)^2}\\int_0^1((1-x) x)^{-\\frac{d}{2}-1} (-8 d (1-x) x+d+8 (1-x) x)\\,\\mathrm dx=\\\\\n\\color{red}{\\frac{2^{1-2 d} \\pi ^{2-d} m^{2 d-2} \\csc ^2\\left(\\frac{\\pi  d}{2}\\right)}{\\Gamma \\left(\\frac{d}{2}\\right)^2}}\n\\end{align}\nFor $d\\to 1$ you can expand this as\n$$\n=\\frac12+\\big(\\log\\frac{m}{\\pi}+\\frac12\\gamma\\big)(d-1)+O(d-1)^2\n$$\nwhere I haven't bothered to include the standard $\\mu^\\epsilon$ scale to get a dimensionally consistent series.\nWe correctly reproduce the leading $1/2$ result.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/619289", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 1, "answer_id": 0}}
{"Q": "Balmer proportionality How did Johannes Balmer arrive at\n$$\n\\lambda \\propto \\frac{n^2}{n^2-4}, \\quad (n=3,4,\\dots),\n$$\nand then how did Rydberg mathematically derive\n$$\n\\frac{1}{\\lambda}=R\\left(\\frac{1}{n^2_1}-\\frac{1}{n^2_2}\\right)?\n$$\nI know $n$ stands for the shells but in the textbook, it doesn't define what $n$ is at first. Was this because Balmer did not know what shells were at that time?\n", "A": "I recommend reading Balmer's original paper \"Notiz \u00fcber die Spektrallinien des Wasserstoffs\" (1885).\nBalmer took the known wavelengths of the visible hydrogen spectrum\n($H_\\alpha$, $H_\\beta$, $H_\\gamma$, $H_\\delta$) as measured by\n\u00c5ngstr\u00f6m with high precision.\nHe recognized they are related by certain fractions.\n$$\\begin{array}{c|c c c}\n  & \\lambda    \\\\ \\hline\n H_\\alpha  & 656.2 \\text{ nm} &= 364.56 \\text{ nm} \\cdot \\frac{9}{5}   &= 364.56 \\text{ nm} \\cdot \\frac{3^2}{3^2-4} \\\\ \\hline\n H_\\beta   & 486.1 \\text{ nm} &= 364.56 \\text{ nm} \\cdot \\frac{4}{3}   &= 364.56 \\text{ nm} \\cdot \\frac{4^2}{4^2-4} \\\\ \\hline\n H_\\gamma  & 434.0 \\text{ nm} &= 364.56 \\text{ nm} \\cdot \\frac{25}{21} &= 364.56 \\text{ nm} \\cdot \\frac{5^2}{5^2-4} \\\\ \\hline\n H_\\delta  & 410.1 \\text{ nm} &= 364.56 \\text{ nm} \\cdot \\frac{9}{8}   &= 364.56 \\text{ nm} \\cdot \\frac{6^2}{6^2-4}\n\\end{array}$$\nThis could be summarized in one formula.\n$$\\lambda=364.56 \\text{ nm} \\cdot \\frac{n^2}{n^2-4} \\quad\\text{with }n=3,4,5,6$$\nYou see, there was no physics involved here, \"only\" guessing a formula which exactly fits the experimentally measured numbers.\nRydberg rewrote Balmer's formula using the reciprocal wavelength\nbecause then it gets the simpler form of a difference between two terms.\n$$\\frac{1}{\\lambda}=\\frac{1}{91.13\\text{ nm}}\\left(\\frac{1}{2^2}-\\frac{1}{n^2}\\right) \\quad\\text{with }n=3,4,5,6,...$$\nHe predicted there would be even more spectral lines in the\nhydrogen spectrum according to this Rydberg formula (1888).\n$$\\frac{1}{\\lambda}=\\frac{1}{91.13\\text{ nm}}\\left(\\frac{1}{m^2}-\\frac{1}{n^2}\\right) \\quad\\text{with }m,n=1,2,3,4,5,...$$\nAnd indeed,\nsoon experimental physicists found these series of spectral lines\nin the ultraviolet and infrared part of the hydrogen spectrum.\n$$\\begin{align}\n\\text{Lyman series:}\\quad    & \\frac{1}{\\lambda}=\\frac{1}{91.13\\text{ nm}}\\left(\\frac{1}{1^2}-\\frac{1}{n^2}\\right) & \\text{with }n=2,3,4,5,... \\\\\n\\text{Paschen series:}\\quad  & \\frac{1}{\\lambda}=\\frac{1}{91.13\\text{ nm}}\\left(\\frac{1}{3^2}-\\frac{1}{n^2}\\right) & \\text{with }n=4,5,6,7,... \\\\\n\\text{Brackett series:}\\quad & \\frac{1}{\\lambda}=\\frac{1}{91.13\\text{ nm}}\\left(\\frac{1}{4^2}-\\frac{1}{n^2}\\right) & \\text{with }n=5,6,7,8,...\n\\end{align}$$\nAgain, there was no physical theory available yet.\nThis had to wait until the invention of quantum mechanics,\nbeginning with the Bohr model (1913) and its explanation\nof the Rydberg formula.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/734989", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 2, "answer_id": 0}}
