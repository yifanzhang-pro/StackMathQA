{"Q": "Expected value of a random variable Random variable $X$  has the probability density function\n\\begin{equation*}\nf\\left( x\\right) =\\left\\{ \n\\begin{array}{ccc}\nn\\left( \\frac{x}{\\theta }\\right) ^{n-1} & , & 0<x\\leqslant \\theta  \\\\ \nn\\left( \\frac{1-x}{1-\\theta }\\right) ^{n-1} & , & \\theta \\leqslant x<1%\n\\end{array}%\n\\right. \n\\end{equation*}\nshow that if $k\\in \\mathbb{N}$\n\\begin{equation*}\n\\mathrm{E}\\left( X^{k}\\right) =\\frac{n\\theta ^{k+1}}{n+k}+\\sum%\n\\limits_{i=0}^{k}\\left( -1\\right) ^{i}\\binom{k}{k-i}\\frac{n}{n+i}\\left(\n1-\\theta \\right) ^{i+1}\n\\end{equation*}\nIt is easy to find the first term of $\\mathrm{E}\\left( X^{k}\\right) $ but i\ncouldn't find the second one. i think i have to use beta distribution\nproperties. i tried to simulate the integral \n\\begin{equation*}\n\\int\\nolimits_{\\theta }^{1}nx^{k}\\left( \\frac{1-x}{1-\\theta }\\right) ^{n-1}%\n\\mathrm{d}x\n\\end{equation*}\nto beta pdf using $u=\\frac{x-1}{\\theta -1}$ transformation but i couldn't\nget a reasonable result. After this transformation is applied i have to find \n\\begin{equation*}\n\\int\\nolimits_{0}^{1}u^{n-1}\\left[ 1+u\\left( \\theta -1\\right) \\right] ^{k}%\n\\mathrm{d}x\n\\end{equation*}\nbut i couldn't. Also I tried to use the equality \n\\begin{equation*}\nx^{k}=1+\\left( x-1\\right) \\sum\\limits_{n=0}^{k-1}x^{n}\n\\end{equation*}\nbut i couldn't get the result.\n", "A": "$$\\begin{align*} {\\rm E}[X^k] &= \\int_{x=0}^\\theta x^k n \\biggl(\\frac{x}{\\theta}\\biggr)^{\\!n-1} \\, dx + \\int_{x=\\theta}^1 x^k n \\biggl(\\frac{1-x}{1-\\theta}\\biggr)^{\\!n-1} \\, dx \\\\ &= \\frac{n}{\\theta^{n-1}} \\int_{x=0}^\\theta x^{n+k-1} \\, dx + \\frac{n}{(1-\\theta)^{n-1}} \\int_{x=0}^{1-\\theta} (1-x)^k x^{n-1} \\, dx \\\\ &= \\frac{n}{\\theta^{n-1}} \\cdot \\frac{\\theta^{n+k}}{n+k} + \\frac{n}{(1-\\theta)^{n-1}} \\int_{x=0}^{1-\\theta} \\sum_{i=0}^{k} \\binom{k}{i} (-x)^i x^{n-1} \\, dx \\\\ &= \\frac{n \\theta^{k+1}}{n+k} + \\frac{n}{(1-\\theta)^{n-1}} \\sum_{i=0}^{k} (-1)^i \\binom{k}{k-i} \\int_{x=0}^{1-\\theta} x^{n+i-1} \\, dx \\\\ &= \\frac{n\\theta^{k+1}}{n+k} + \\frac{n}{(1-\\theta)^{n-1}} \\sum_{i=0}^k (-1)^i \\binom{k}{k-i} \\frac{(1-\\theta)^{n+i}}{n+i} \\\\ &= \\frac{n\\theta^{k+1}}{n+k} + \\sum_{i=0}^k (-1)^i \\binom{k}{k-i} \\frac{n}{n+i} (1-\\theta)^{i+1}.  \\end{align*}$$\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/93972", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "K-means++ algorithm I try to implement k-means++, but I'm not sure how it works. I have the following dataset:\n(7,1), (3,4), (1,5), (5,8), (1,3), (7,8), (8,2), (5,9), (8,0)\n\nFrom the wikipedia:\n\n\n*\n\n*Step 1: Choose one center uniformly at random from among the data points. \nlet's say the first centroid is 8,0\n\n*Step 2: For each data point x, compute D(x), the distance between x and the nearest center that has already been chosen. \nI calculate all each point's distance to tht point nr.9 (8,0)\n\n\n*\n\n*1 (7,1) distance = (8-7)^2 + (0-1)^2 = (1)^2 + (-1)^2 =  1 +  1 =  2\n\n*2 (3,4) distance = (8-3)^2 + (0-4)^2 = (5)^2 + (-4)^2 = 25 + 16 = 41\n\n*3 (1,5) distance = (8-1)^2 + (0-5)^2 = (7)^2 + (-5)^2 = 49 + 25 = 74\n\n*4 (5,8) distance = (8-5)^2 + (0-8)^2 = (3)^2 + (-8)^2 =  9 + 64 = 73\n\n*5 (1,3) distance = (8-1)^2 + (0-3)^2 = (7)^2 + (-3)^2 = 49 +  9 = 58\n\n*6 (7,8) distance = (8-7)^2 + (0-8)^2 = (1)^2 + (-8)^2 =  1 + 64 = 65\n\n*7 (8,2) distance = (8-8)^2 + (0-2)^2 = (0)^2 + (-2)^2 =  0 +  4 =  4\n\n*8 (5,9) distance = (8-5)^2 + (0-9)^2 = (3)^2 + (-9)^2 =  9 + 81 = 90\n\n\n*Step 3: Choose one new data point at random as a new center, using a weighted probability distribution where a point x is chosen with probability proportional to $D(x)^2$.\n\n*Step 4: Repeat Steps 2 and 3 until k centers have been chosen.\nCould someone explain in detail how to calculate the 3rd step?\n", "A": "For step 3, \n\nChoose one new data point at random as a new center, using a weighted\n  probability distribution where a point x is chosen with probability\n  proportional to $D(x)^2$.\n\nCompute all the $D(x)^2$ values and convert them to an array of cumulative sums. That way each item is represented by a range proportional to its value. Then pick a uniform random number in that range and see which item it corresponds to (using a binary search).\nFor instance, you have:\nD(x)^2 = [2, 41, 74, 73, 58, 65, 4, 90]\ncumulative D(x)^2 = [2, 43, 117, 190, 248, 313, 317, 407]\n\nSo pick a random number from [0, 407). Say you pick 123.45. It falls in the range [117, 190)  which corresponds to the 4th item. \n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/135403", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "5", "answer_count": 2, "answer_id": 1}}
{"Q": "Equation for the variance inflation factors Following a question asked earlier, the variance inflation factors (VIFs) can be expressed as\n$$\n\\textrm{VIF}_j = \\frac{\\textrm{Var}(\\hat{b}_j)}{\\sigma^2} =\n[\\mathbf{w}_j^{\\prime} \\mathbf{w}_j - \\mathbf{w}_j^{\\prime}\n\\mathbf{W}_{-j} (\\mathbf{W}_{-j}^{\\prime} \\mathbf{W}_{-j})^{-1}\n\\mathbf{W}_{-j}^{\\prime} \\mathbf{w}_j]^{-1}\n$$\n$\\mathbf{W}$ is the unit length scaled version of $\\mathbf{X}$\nCan anyone show me how to get from here to the equation\n$$\n\\textrm{VIF}_j = \\frac{1}{1-R_j^2}\n$$\n$R_j^2$ is the coefficient of multiple determination obtained from regressing $x_j$ on the other regressor variables.\nI'm having a lot of troubles getting these matrix operations right...\n", "A": "Assume all $X$ variables are standardized by the correlation transformation, like you mentioned, unit length scaled version of $\\mathbf{X}$. The standardized model does not change the correlation between $X$ variables. $VIF$ can be calculated when standardized transformation of the original linear model is made. Let's denote the design matrix after standardized transformation as \n\\begin{align*}\n\\mathbf{X^*} = \\begin{bmatrix} 1& X_{11}& \\ldots &X_{1,p-1} \\\\ 1& X_{21}& \\ldots &X_{2,p-1} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ 1& X_{n1}& \\ldots &X_{n,p-1} \\\\ \\end{bmatrix}.\n\\end{align*}\nThen \n\\begin{align*}\n\\mathbf{X^{*'}X^*} = \\begin{bmatrix} n & \\mathbf{0}' \\\\ \\mathbf{0} & \\mathbf{r}_{XX} \\end{bmatrix},\n\\end{align*}\nwhere $\\mathbf{r}_{XX}$ is the correlation matrix of $X$ variables. We also know that\n\\begin{align*}\n\\sigma^2\\{\\hat{\\beta}\\} \n& = \\sigma^2 (\\mathbf{X^{*'}X^*})^{-1}\\\\\n& = \\sigma^2 \\begin{bmatrix} \\frac{1}{n} & \\mathbf{0}' \\\\ \\mathbf{0} & \\mathbf{r}^{-1}_{XX}. \\end{bmatrix}\\\\\n\\end{align*}\n$VIF_k$ for $k=1,2,\\ldots,p-1$ is the $k$-th diagonal term of $\\mathbf{r}^{-1}_{XX}$. We only need to prove this for $k = 1$ because you can permute the rows and columns of $r_{XX}$ to get the result for other $k$.\nLet's define:\n\\begin{align*}\n\\mathbf{X}_{(-1)} = \\begin{bmatrix} X_{12}&\\ldots&X_{1,p-1} \\\\X_{22}&\\ldots&X_{2,p-1}\\\\ \\vdots & \\vdots & \\vdots \\\\ X_{n2}&\\ldots&X_{n,p-1} \\\\ \\end{bmatrix}, \\mathbf{X}_1 = \\begin{bmatrix} X_{11} \\\\ X_{21} \\\\ \\vdots \\\\ X_{n1} \\\\ \\end{bmatrix}.\n\\end{align*}\nNote that both matrices are different from design matrices. Since we only care about the coefficients of $X$ variables, the $1$-vector of a design matrix can be ignored in our calculation. Hence, by using Schur's complement, \n\\begin{align*}\nr^{-1}_{XX} (1,1)\n& = (r_{11} - r_{1\\mathbf{X}_{(-1)}} r^{-1}_{\\mathbf{X}_{(-1)}\\mathbf{X}_{(-1)}} r_{\\mathbf{X}_{(-1)}1})^{-1} \\\\\n& = (r_{11} - [r_{1\\mathbf{X}_{(-1)}} r^{-1}_{\\mathbf{X}_{(-1)}\\mathbf{X}_{(-1)}}] r_{\\mathbf{X}_{(-1)}\\mathbf{X}_{(-1)}} [r^{-1}_{\\mathbf{X}_{(-1)}\\mathbf{X}_{(-1)}} r_{\\mathbf{X}_{(-1)}1}])^{-1} \\\\\n& = (1-\\beta_{1\\mathbf{X}_{(-1)}}' \\mathbf{X}_{(-1)}' \\mathbf{X}_{(-1)} \\beta_{1\\mathbf{X}_{(-1)}} )^{-1},\n\\end{align*}\nwhere $\\beta_{1\\mathbf{X}_{(-1)}}$ is the regression coefficients of $X_1$ on $X_2, \\ldots, X_{p-1}$ except the intercept. In fact, the intercept should be the origin, since all $X$ variables are standardized with mean zero. \nOn the other hand, (it would be more straightforward if we can write everything in explicit matrix form)\n\\begin{align*}\nR_1^2\n& = \\frac{SSR}{SSTO} = \\frac{\\beta_{1\\mathbf{X}_{(-1)}}' \\mathbf{X}_{(-1)}' \\mathbf{X}_{(-1)} \\beta_{1\\mathbf{X}_{(-1)}}}{1} \\\\\n& = \\beta_{1\\mathbf{X}_{(-1)}}' \\mathbf{X}_{(-1)}' \\mathbf{X}_{(-1)} \\beta_{1\\mathbf{X}_{(-1)}}.\n\\end{align*}\nTherefore \n\\begin{align*}\nVIF_1 = r^{-1}_{XX} (1,1) = \\frac{1}{1-R_1^2}.\n\\end{align*}\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/244468", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "8", "answer_count": 1, "answer_id": 0}}
{"Q": "Probability of a person correctly guessing at least one number out of the two number another person chooses \nPerson A randomly chooses a number from 1 to 5 (inclusive) twice, so A ends up with 2 numbers chosen (can be the same number). Person B also makes a random choice from that list (only 1 number). What's the probability that B's choice match at least one of A's choices?\n\nMy interpretation of the question is: what's the probability that a randomly chosen number (call it $c$) between 1 and 5 is in the random set $[a, b],~ a $ and $b $are between 1 and 5.\nMy attempt of solving this question is the following:\nThere are 2 cases: 1.$ a$ and $b$ are different numbers; 2. $a$ and $b$ are the same.\\\ncase 1:\nif $a = b$, $\\mathbb{P}[c \\in \\{a, b\\}] = \\mathbb{P}[c = a] = \\frac{1}{5} $\ncase 2:\nif $a \\not= b$, $\\mathbb{P}[c \\in \\{a, b\\}] = \\mathbb{P}[c = a] + \\mathbb{P}[c = b]= \\frac{2}{5} $\nThe probability of case 1 occurring is $\\frac{1}{5}$. The calculation is similar to case 1. And the probability of case 2 occurring is $\\frac{4}{5}$ since its the complement of case 1. Then, the answer is $$\\mathbb{P}[\\text{case 1}] \\cdot\\frac{1}{5} + \\mathbb{P}[\\text{case 2}]\\cdot\\frac{2}{5} = \\frac{1}{5} \\cdot \\frac{1}{5} + \\frac{4}{5} \\cdot\\frac{2}{5} = \\frac{3}{5}$$\nHowever, the correct answer is $\\frac{9}{25}$. This is confirmed by a simulation I ran.\nWhat did I do wrong?\n", "A": "Your reasoning is correct up to the very last line:\n$$\\mathbb{P}[\\text{case 1}] \\cdot\\frac{1}{5} + \\mathbb{P}[\\text{case 2}]\\cdot\\frac{2}{5} = \\frac{1}{5} \\cdot \\frac{1}{5} + \\frac{4}{5} \\cdot\\frac{2}{5}$$\nBut this is not equal to $\\frac{3}{5}$.\nInstead:\n$$\\frac{1}{5} \\cdot \\frac{1}{5} + \\frac{4}{5} \\cdot\\frac{2}{5} = \\frac{1 \\cdot 1}{25} + \\frac{4 \\cdot 2}{25} = \\frac{9}{25}$$\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/586515", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
