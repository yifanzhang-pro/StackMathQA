{"Q": "Ramanujan and algebraic number theory One out of the almost endless supply of identities discovered by Ramanujan\nis the following:\n$$ \\sqrt[3]{\\rule{0pt}{2ex}\\sqrt[3]{2}-1} = \\sqrt[3]{\\frac19} - \\sqrt[3]{\\frac29} + \\sqrt[3]{\\frac49}, $$\nwhich has the following interpretation in algebraic number theory: the fundamental unit\n$\\sqrt[3]{2}-1$ of the pure cubic number field $K = {\\mathbb Q}(\\sqrt[3]{2})$ becomes a cube in the extension $L = K(\\sqrt[3]{3})$.\nAre there more examples of this kind in Ramanujan's work?\n", "A": "$$(7 \\sqrt[3]{20} - 19)^{1/6} = \\ \\sqrt[3]{\\frac{5}{3}}\n- \\sqrt[3]{\\frac{2}{3}},$$\n$$\\left( \\frac{3 + 2 \\sqrt[4]{5}}{3 - 2 \\sqrt[4]{5}}\n\\right)^{1/4}= \\  \\  \\frac{\\sqrt[4]{5} + 1}{\\sqrt[4]{5} - 1},$$\n$$\\left(\\sqrt[5]{\\frac{1}{5}} + \\sqrt[5]{\\frac{4}{5}}\\right)^{1/2}\n=  \\  \\ (1 + \\sqrt[5]{2} + \\sqrt[5]{8})^{1/5} =  \\ \\ \n\\sqrt[5]{\\frac{16}{125}} + \\sqrt[5]{\\frac{8}{125}} + \\sqrt[5]{\\frac{2}{125}} - \\sqrt[5]{\\frac{1}{125}},$$\nand so on. Many of these were submitted by Ramanujan as problems to the\nJournal of the Indian Mathematical Society. See the following link:\njims.ps for more precise references.\nQuote: \"although Ramanujan never used the term unit, and\nprobably did not formally know what a unit was,\nhe evidently realized their fundamental properties.\nHe then recognized that taking certain powers of units\noften led to elegant identities.\"\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/43388", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "30", "answer_count": 1, "answer_id": 0}}
{"Q": "A lower bound of a particular convex function Hello,\nI suspect this reduces to a homework problem, but I've been a bit hung up on it for the last few hours.  I'm trying to minimize the (convex) function $f(x) = 1/x + ax + bx^2$ , where $x,a,b>0$.  Specifically, I'm interested in the minimal objective function value as a function of $a$ and $b$.  Since finding the minimizer $x^*$ is tricky (requires solving a cubic), I figured I'd try and find a lower bound using the following argument:  if $b=0$, the minimizer is $x=1/\\sqrt{a}$ and the minimal value is $2\\sqrt{a}$.  If $a=0$, the minimizer is $x=(2b)^{-1/3}$ and the minimal value is $\\frac{3\\cdot2^{1/3}}{2}b^{1/3}$.  Therefore, one possible approximate solution is the convex combination\n$(\\frac{a}{a+b})\\cdot2\\sqrt{a} + (\\frac{b}{a+b})\\cdot\\frac{3\\cdot2^{1/3}}{2}b^{1/3}$.\nNumerical simulations suggest that the above expression is a lower bound for the minimal value.  Does this follow from some nice result about parameterized convex functions?  It seems like it shouldn't be hard to prove.  I guess in a nutshell I just want to prove that for all $x,a,b>0$ we have\n$(\\frac{a}{a+b})\\cdot2\\sqrt{a} + (\\frac{b}{a+b})\\cdot\\frac{3\\cdot2^{1/3}}{2}b^{1/3} \\leq 1/x + ax + bx^2$.  Thanks!\nEDIT:  It also appears that if I take the convex combination\n$(\\frac{a^{3/5}}{a^{3/5}+b^{2/5}})\\cdot2\\sqrt{a} + (\\frac{b^{2/5}}{a^{3/5}+b^{2/5}})\\cdot\\frac{3\\cdot2^{1/3}}{2}b^{1/3}$\nthen I get a tighter lower bound, and in fact the lower bound is within a factor of something like $3/2$ of the true minimal solution.\n", "A": "The first inequality is true. Write\n$$f=\\frac{a}{a+b}f_0+\\frac{b}{a+b}f_1,$$\nwhere $f_0$ and $f_1$ correspond to the case $b=0$ and $a=0$, respectively. You know that $f_0\\ge2\\sqrt a$ and $f_1\\ge\\frac{3\\cdot2^{1/3}}{2}b^{1/3}$. This implies\n$$f\\ge\\frac{a}{a+b}2\\sqrt a+\\frac{b}{a+b}\\frac{3\\cdot2^{1/3}}{2}b^{1/3}.$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/61946", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "3", "answer_count": 2, "answer_id": 0}}
{"Q": "General integer solution for $x^2+y^2-z^2=\\pm 1$ How to find general solution (in terms of parameters) for diophantine equations\n$x^2+y^2-z^2=1$ and $x^2+y^2-z^2=-1$?\nIt's easy to find such solutions for $x^2+y^2-z^2=0$ or $x^2+y^2-z^2-w^2=0$ or $x^2+y^2+z^2-w^2=0$, but for these ones I cannot find anything relevant.\n", "A": "I think that the solutions to $x^2+y^2-z^2=-1$ are  $x=RT-SU,y=RU+ST$ where $R^2+S^2-T^2-U^2=2$ then $z=R^2+S^2-1=T^2+U^2+1$ On the surface this looks similar to the solutions to the $+1$ case. However these are quite a bit rarer and depend on the locations of the primes. \nAs we know, an integer can be uniquely written as $n=ab^2$ where $a$ (the squarefree part of $n$) is a product of distinct primes. $n$ can be written as a sum of two squares $n=j^2+k^2$ precisely when  $a$ has no prime divisors of the form $4m+3$ (and we know in how many ways this can be done as well.) So the solutions depend on when we have 2 consecutive even numbers of this form. \nFor example $292=73\\cdot4^2$ and $290=2\\cdot5\\cdot329$ thus we know that there are expressions as a sum of two squares: $$292=6^2+16^2$$ $$290=1^2+17^2=11^2+13^2.$$ Running through the various possiblities gives these solutions for $R,S,T,U,x,y$ with $x^2+y^2-291^2=-1:$\n\n\n*\n\n*6, 16, 17, 1, 86, 278 \n\n*16, 6, 11, 13, 98, 274 \n\n*16, 6, 17, 1, 266, 118 \n\n*16, 6, 13, 11, 142, 254 \n\n\nCertain families of solutions can be given. One is $x,y,z=2p,2p^2,2p^2+1.$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/65957", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "6", "answer_count": 5, "answer_id": 2}}
{"Q": "Computing the centers of Apollonian circle packings The radii of an Apollonian circle packing are computed from the initial curvatures e.g. (-10, 18, 23, 27) solving Descartes equation $2(a^2+b^2+c^2+d^2)=(a+b+c+d)^2$ and using the four matrices to generate more solutions\n$$\n \\left[\\begin{array}{cccc} -1 & 2 & 2 & 2 \\\\\\\\ 0 & 1 & 0 & 0 \\\\\\\\ 0 & 0 & 1 & 0 \\\\\\\\ 0 & 0 & 0 & 1 \\end{array}\\right] \\hspace{0.25 in} \n\\left[\\begin{array}{cccc}  1 & 0 & 0 & 0 \\\\\\\\ 2 & -1 & 2 & 2 \\\\\\\\ 0 & 0 & 1 & 0 \\\\\\\\ 0 & 0 & 0 & 1 \\end{array}\\right] \\hspace{0.25in}\n\\left[\\begin{array}{cccc}   1 & 0 & 0 & 0 \\\\\\\\ 0 &  1 & 0 & 0\\\\\\\\ 2 & 2 & -1 & 2 \\\\\\\\ 0 & 0 & 0 & 1 \\end{array}\\right]\n\\hspace{0.25in}\n\\left[\\begin{array}{cccc}   1 & 0 & 0 & 0 \\\\\\\\ 0 &  1 & 0 & 0\\\\\\\\  0 & 0 &  1 & 0 \\\\\\\\  2 & 2 &  2&-1  \\end{array}\\right]\n$$\nHow to compute the centers of circles in the Apollonian circle packing?\nThe formulas probably simplify if you use complex numbers.\nAlso in what sense it is the circle packing the limit set of a Kleinian group?\n\n", "A": "$$2(a^2+b^2+c^2+d^2)=(a+b+c+d)^2$$\n$$a=4k(k+s)$$\n$$b=4s(k+s)$$\n$$c=p^2+k^2+s^2+2pk+2ps-2ks$$\n$$d=p^2+k^2+s^2-2pk-2ps-2ks$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/88353", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "12", "answer_count": 5, "answer_id": 4}}
{"Q": "The relationship between the dilogarithm and the golden ratio Among the values for which the dilogarithm and its argument can both be given in closed form are the following four equations:\n$Li_2( \\frac{3 - \\sqrt{5}}{2}) = \\frac{\\pi^2}{15} - log^2( \\frac{1 +\\sqrt{5}}{2} )$ (1)\n$Li_2( \\frac{-1 + \\sqrt{5}}{2}) = \\frac{\\pi^2}{10} - log^2( \\frac{1 +\\sqrt{5}}{2} )$ (2)\n$Li_2( \\frac{1 - \\sqrt{5}}{2}) = -\\frac{\\pi^2}{15} - log^2( \\frac{1 +\\sqrt{5}}{2} )$ (3)\n$Li_2( \\frac{-1 - \\sqrt{5}}{2}) = -\\frac{\\pi^2}{10} - log^2( \\frac{1 +\\sqrt{5}}{2} )$ (4)\n(from Zagier's The Remarkable Dilogarithm)\nwhere the argument of the logarithm on the right hand side is the golden ratio $\\phi$. The above equations all have this (loosely speaking) kind of duality, and almost-symmetry that gets broken by the fact that $Li_2(\\phi)$ fails to make an appearance. Can anyone explain what is the significance of the fact that  $\\phi$ appears on the right, but not on the left? Immediately one can see that the arguments on the lefthand side of (2)-(4) are related to $\\phi$ as roots of a polynomial, but what other meaning does this structure have?\n", "A": "Wikipedia says $$Li_2\\left({1+\\sqrt5\\over2}\\right)={\\pi^2\\over10}-\\log^2{\\sqrt5-1\\over2}$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/144322", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "6", "answer_count": 4, "answer_id": 2}}
{"Q": "$\\zeta(0)$ and the cotangent function In preparing some practice problems for my complex analysis students, I stumbled across the following. It is not hard to show, using Liouville's theorem, that\n$$\\pi\\cot(\\pi z)=\\frac{1}{z}+\\sum_{n=1}^\\infty\\left(\\frac{1}{z+n}+\\frac{1}{z-n}\\right),$$\nwhich implies that\n$$-\\frac{\\pi z}{2}\\cot(\\pi z)=-\\frac{1}{2}+\\sum_{k=1}^\\infty\\zeta(2k)z^{2k},\\qquad 0<|z|<1.$$\nThis formula predicts correctly that $\\zeta(0)=-\\frac{1}{2}$, and allows to calculate $\\zeta(2k)$ as a rational multiple of $\\pi^{2k}$ as well (in terms of Bernoulli numbers).\nIs there some simple explanation why the above prediction $\\zeta(0)=-\\frac{1}{2}$ is valid? Perhaps there is a not so simple but still transparent explanation via Eisenstein series.\nAdded. Just to clarify what I mean by \"simple explanation\". The second identity above follows directly from the first identity, i.e. from basic principles of complex analysis:\n$$-\\frac{\\pi z}{2}\\cot(\\pi z)=-\\frac{1}{2}+\\sum_{n=1}^\\infty\\frac{z^2}{n^2-z^2}=-\\frac{1}{2}+\\sum_{n=1}^\\infty\\sum_{k=1}^\\infty\\left(\\frac{z^2}{n^2}\\right)^k\n=-\\frac{1}{2}+\\sum_{k=1}^\\infty\\zeta(2k)z^{2k}.$$\nI would like to see a similar argument, perhaps somewhat more elaborate, that explains why the constant term here happens to be $\\zeta(0)$, which seems natural in the light of the other terms.\n", "A": "Here is an explanation based on the Euler-Maclaurin summation formula.\n(Or rather, since we'll only ever need two terms of the Euler-Maclaurin summation, it's really more or less just \"the trapezoid rule\".)\nI think it's a good explanation because it sticks to the general structure of the argument outlined in the question, and its \"18th-century-friendly\" spirit.\nFirst, let's review how to apply Euler-Maclaurin to $\\zeta$.\nWe have\n$$\n    \\begin{align}\n        \\zeta(s) &=\n      \\sum_{n=1}^N \\frac{1}{n^s}\n   + \\sum_{n=N+1}^{\\infty} \\frac{1}{n^s} \\\\\n        &=\n      \\sum_{n=1}^N \\frac{1}{n^s}\n   + \\int_N^{\\infty} \\frac{1}{x^s} \\, dx\n   - \\frac12 \\frac{1}{N^s}\n   + \\mathrm{Error} \\\\\n        &=\n      \\sum_{n=1}^N \\frac{1}{n^s}\n   + \\frac{1}{s-1} \\frac{1}{N^{s-1}}\n   - \\frac12 \\frac{1}{N^s}\n   + \\mathrm{Error}\n   \\tag{1}. \\\\\n    \\end{align}\n$$\nWe can say more about the error term later - for now, all we need to know is that $\\mathrm{Error} = O ( \\frac{1}{N^{\\operatorname{Re}(s)+1}} )$ as $N \\to \\infty$, for each $s$.\nThe key thing to note is that, even though the computation initially required $\\operatorname{Re}(s)>1$ in order to be valid, in fact the \"equation\"\n$$\n    \\zeta(s) =\n     \\sum_{n=1}^N \\frac{1}{n^s}\n  + \\frac{1}{s-1} \\frac{1}{N^{s-1}}\n  - \\frac12 \\frac{1}{N^s}\n  + O \\left( \\frac{1}{N^{\\operatorname{Re}(s)+1}} \\right)\n  \\tag{2}\n$$\nhas a unique constant solution $\\zeta(s)$, for each $s$ with $\\operatorname{Re}(s) > -1$ and $s \\ne 1$.\nThis is one way to define $\\zeta(s)$ for all such $s$.\nIn particular, we can plug in $0$ and immediately find that $\\zeta(0) = -\\frac12$.\nWhat about the function $f(z) = -\\frac{\\pi z}{2} \\cot(\\pi z)$? We can also apply Euler-Maclaurin to $f$ in the same way:\n$$\n    \\begin{align}\n        f(z) &=\n      -\\frac12\n   + \\sum_{n=1}^N \\frac{z^2}{n^2-z^2}\n   + \\sum_{n=N+1}^{\\infty} \\frac{z^2}{n^2-z^2} \\\\\n        &=\n      -\\frac12\n   + \\sum_{n=1}^N \\frac{z^2}{n^2-z^2}\n   + \\int_N^{\\infty} \\frac{z^2}{x^2-z^2} \\, dx\n   - \\frac12 \\frac{z^2}{N^2-z^2}\n   + O \\left( \\frac{1}{N^3} \\right)\n   \\tag{3} \\\\\n    \\end{align}\n$$\nas $N \\to \\infty$, for each $z$.\nThe right-hand side of (3), without the error term, is what we'll call $f_N(z)$; we can simplify it to\n$$\n    f_N(z) =\n     \\sum_{n=1}^N \\frac{z^2}{n^2-z^2}\n  + z \\cdot \\frac12 \\left(\n      \\log\\left(1+\\frac{z}{N}\\right)\n      - \\log\\left(1-\\frac{z}{N}\\right)\n  \\right)\n  - \\frac12 \\frac{N^2}{N^2-z^2}\n  \\tag{4}.\n$$\nI should emphasize that (4) is just a somewhat more elaborate variant of $-\\frac12 + \\sum_{n=1}^{\\infty} \\frac{z^2}{n^2-z^2}$, much like how (2) is just a somewhat more elaborate variant of $\\sum_{n=1}^{\\infty} \\frac{1}{n^s}$.\nNow when we expand (4) into power series, we recognize the expression from (2) as the coefficients, and we recognize that we can make the sum run from $k=0$ to $\\infty$, not just $k=1$ to $\\infty$:\n$$\n    \\begin{align}\n  f_N(z) &=\n   \\sum_{n=1}^N \\sum_{k=1}^{\\infty} \\frac{z^{2k}}{n^{2k}}\n   + \\sum_{k=1}^{\\infty} \\frac{1}{2k-1} \\frac{1}{N^{2k-1}} z^{2k}\n   - \\frac12 \\sum_{k=0}^{\\infty} \\frac{z^{2k}}{N^{2k}} \\\\\n  &=\n      \\sum_{k=0}^{\\infty} \\left(\n    \\sum_{n=1}^N \\frac{1}{n^{2k}}\n    + \\frac{1}{2k-1} \\frac{1}{N^{2k-1}}\n    - \\frac12 \\frac{1}{N^{2k}}\n   \\right) z^{2k}.\n   \\tag{5} \\\\\n \\end{align}\n$$\nThis is exactly what we want: take the limit as $N \\to \\infty$ to conclude that $f(z) = \\sum_{k=0}^{\\infty} \\zeta(2k) z^{2k}$.\n(To be rigorous in the final step, we'd need to be more precise about the error term in (1). The actual bound we get from Euler-Maclaurin is\n$\n    \\lvert \\mathrm{Error} \\rvert\n    \\le \\mathrm{constant} \\cdot \\int_N^{\\infty} \\left\\lvert \\frac{s(s+1)}{x^{s+2}} \\right\\rvert \\, dx \n$\nfor all $N$ and all $s$ such that $\\operatorname{Re}(s) > -1$ and $s \\ne 1$.\nThis lets us control the size of the difference $\\sum_{k=0}^{\\infty} \\zeta(2k) z^{2k} - f_N(z)$.)\nThis proves that all the even-power coefficients of the power series of $-\\frac{\\pi z}{2} \\cot(\\pi z)$ are the corresponding values of $\\zeta$, including $\\zeta(0)$ as the constant term.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/188371", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "37", "answer_count": 2, "answer_id": 0}}
{"Q": "Determinant of a matrix filled with elements of the Thue\u2013Morse sequence Let $n$ be a positive integer. Suppose we fill a square matrix $n\\times n$ row-by-row with the first $n^2$ elements of the Thue\u2013Morse sequence (with indexes from $0$ to $n^2-1$). Let $\\mathcal D_n$ be the determinant of this matrix. For example,\n$$\\small\\mathcal D_7=\\left| \n\\begin{array}{}\n t_0 & t_1 & t_2 & t_3 & t_4 & t_5 & t_6 \\\\\n t_7 & t_8 & t_9 & t_{10} & t_{11} & t_{12} & t_{13} \\\\\n t_{14} & t_{15} & t_{16} & t_{17} & t_{18} & t_{19} & t_{20} \\\\\n t_{21} & t_{22} & t_{23} & t_{24} & t_{25} & t_{26} & t_{27} \\\\\n t_{28} & t_{29} & t_{30} & t_{31} & t_{32} & t_{33} & t_{34} \\\\\n t_{35} & t_{36} & t_{37} & t_{38} & t_{39} & t_{40} & t_{41} \\\\\n t_{42} & t_{43} & t_{44} & t_{45} & t_{46} & t_{47} & t_{48} \\\\\n\\end{array}\n\\right|=\\left| \n\\begin{array}{}\n 0 & 1 & 1 & 0 & 1 & 0 & 0 \\\\\n 1 & 1 & 0 & 0 & 1 & 0 & 1 \\\\\n 1 & 0 & 1 & 0 & 0 & 1 & 0 \\\\\n 1 & 1 & 0 & 0 & 1 & 1 & 0 \\\\\n 1 & 0 & 0 & 1 & 1 & 0 & 0 \\\\\n 1 & 0 & 1 & 1 & 0 & 0 & 1 \\\\\n 1 & 0 & 1 & 0 & 0 & 1 & 0 \\\\\n\\end{array}\n\\right|=0.$$\nQuestion: For which $n$ does $\\mathcal D_n\\ne0$ hold?\nUsing a brute-force computer search I found only $5$ cases: $\\mathcal D_2 = -1,\\,$ $\\mathcal D_{11} = 9,\\,$ $\\mathcal D_{13} = -9,\\,$ $\\mathcal D_{19} = 270,\\,$ $\\mathcal D_{23} = -900,$ and no other cases for $n\\le1940$. Are there any other cases except these five?\n", "A": "not an answer just the result of a computation. The following plot shows for each $n$ the minimal number $k$ such that the first $k$ rows are linearly dependent. The question is to find all $n$ such that $k=n+1$.\n\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/314742", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "14", "answer_count": 1, "answer_id": 0}}
{"Q": "How to prove the determinant of a Hilbert-like matrix with parameter is non-zero Consider some positive non-integer $\\beta$ and a non-negative integer $p$. Does anyone have any idea how to show that the determinant of the following matrix is non-zero?\n$$\n\\begin{pmatrix}\n\\frac{1}{\\beta + 1} & \\frac{1}{2} & \\frac{1}{3} & \\dots & \\frac{1}{p+1}\\\\\n\\frac{1}{\\beta + 2} & \\frac{1}{3} & \\frac{1}{4} & \\dots & \\frac{1}{p+2}\\\\\n\\frac{1}{\\beta + 3} & \\frac{1}{4} & \\frac{1}{5} & \\dots & \\frac{1}{p+3}\\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{1}{\\beta + p + 1} & \\frac{1}{p+2} & \\frac{1}{p+3} & \\dots & \\frac{1}{2p+1}\n\\end{pmatrix}.\n$$\n", "A": "Rows linearly dependent means for some $c_1$, $\\ldots$, $c_{p+1}$ the non-zero rational function \n$\\sum_{k=1}^{p+1}  \\frac{c_k}{x+k}$ has $p+1$ roots $\\beta$, $1$, $2$, $\\ldots$, $p$, not possible, since its numerator has degree at most $p$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/358175", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "16", "answer_count": 2, "answer_id": 1}}
{"Q": "Norms in quadratic fields This should be well-known, but I can't find a reference (or a proof, or a counter-example...). Let $d$ be a positive square-free integer. Suppose that there is no element in the ring of integers of $\\mathbb{Q}(\\sqrt{d})$ with norm $-1$. Then I believe that no element of $\\mathbb{Q}(\\sqrt{d})$ has norm $-1\\ $\n(in fancy terms, the homomorphism $H^2(G,\\mathscr{O}^*)\\rightarrow H^2(G,\\mathbb{Q}(\\sqrt{d})^*)$, with $G:=\\operatorname{Gal}(\\mathbb{Q}(\\sqrt{d})/\\mathbb{Q})=$ $\\mathbb{Z}/2 $, is injective). Is that correct? If yes, I'd appreciate a proof or a reference.\n", "A": "Dirichlet's version of Gauss composition is in the book by Cox, (page 49 in first)  with a small typo corrected in the second edition.\nFor our purpose, duplication, it has a better look to equate $a=a'$ from the start, with $\\gcd(a,b) = 1$ sufficing,\n$$ \\left( ax^2 +bxy+ acy^2 \\right)  \\left( aw^2 +bwz+ acz^2 \\right) = c X^2 + b XY + a^2 Y^2 $$\nwhere\n$$  X = axz + ayw+byz \\; \\; , \\; \\; \\;  Y = xw - c yz  $$\nso that the square of $\\langle a,b,ac \\rangle$   is $\\langle c,b,a^2 \\rangle.$\nToday's question concerns $c=-1$\n$$ \\left( ax^2 +bxy -ay^2 \\right)  \\left( aw^2 +bwz -az^2 \\right) = - X^2 + b XY + a^2 Y^2 $$\nwhere\n$$  X = axz + ayw+byz \\; \\; , \\; \\; \\;  Y = xw + yz  $$\nso that  $$\\langle a,b,-a \\rangle^2 =   \\langle -1,b,a^2 \\rangle.$$\nWe also see Stanley's fact that the discriminant is the sum of two squares,  $b^2 + 4 a^2$ the way I wrote things.\nBy the Gauss theorem on duplication, $  \\langle -1,b,a^2 \\rangle$ is in the principal genus\nFurthermore, we now know that  the principal form is $SL_z \\mathbb Z$ equivalent to\n$$  \\langle 1,b,-a^2 \\rangle  $$\nThe principal form may not integrally represent $-1$ but does so rationally.\nAs to being in the same genus, we can use Siegel's definition of rational equivalence without essential denominator.\n$$\n\\left(\n\\begin{array}{rr}\n 0  & 1 \\\\\n -a^2 & -b \\\\\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{rr}\n 1 & \\frac{b}{2} \\\\\n \\frac{b}{2} & -a^2  \\\\\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{rr}\n 0 & -a^2 \\\\\n 1 & -b \\\\\n\\end{array}\n\\right) = \\; a^2 \\; \n\\left(\n\\begin{array}{rr}\n -1 & \\frac{b}{2} \\\\\n \\frac{b}{2} & a^2  \\\\\n\\end{array}\n\\right)\n$$\n$$\n\\left(\n\\begin{array}{rr}\n b  & 1 \\\\\n -a^2 & 0 \\\\\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{rr}\n -1 & \\frac{b}{2} \\\\\n \\frac{b}{2} & a^2  \\\\\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{rr}\n b & -a^2 \\\\\n 1 & 0 \\\\\n\\end{array}\n\\right) = \\; a^2 \\; \n\\left(\n\\begin{array}{rr}\n 1 & \\frac{b}{2} \\\\\n \\frac{b}{2} & -a^2  \\\\\n\\end{array}\n\\right)\n$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/369846", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "14", "answer_count": 3, "answer_id": 0}}
{"Q": "How the solve the equation $\\frac{(a+b\\ln(x))^2}{x}=c$ I need to solve the equation\n$$\\frac{(a+b\\ln(x))^2}{x}=c$$\nwhere $a$, $b$, and $c$ are given. It is known that $a$ and $b$ are fixed and satisfy some condition such that the left hand side is decreasing. So $x$ is uniquely determined by $c$ when $c$ is chosen in certain range.\nA related problem is\n$$\\frac{(a+b\\ln(x))}{x}=c$$\nfor which the solution is\n$$x=-\\frac{bW(-\\frac{ce^{-a/b}}{b})}{c}$$\nwhere $W(z)$ is the product log function.\nAny hint about how to solve the first equation?\n", "A": "Step-by-step solution with Lambert W.  The goal is to get something\nof the form $\\color{red}{ue^u = v}$ then re-write it as $\\color{blue}{u=W(v)}$.\n$$\n\\frac{(a+b\\ln(x))^2}{x}=c\n\\\\\n\\frac{(a+b\\ln(x))}{\\sqrt{x}}=\\pm\\sqrt{c}\n\\\\\n(a+b\\ln(x))e^{-\\ln(x)/2}=\\pm\\sqrt{c}\n\\\\\n(a+b\\ln(x))\\exp\\left(-\\frac{a}{2b}-\\frac{\\ln(x)}{2}\\right)\n=\\pm\\sqrt{c}\\exp\\left(\\frac{-a}{2b}\\right)\n\\\\\n(a+b\\ln(x))\\exp\\left(-\\frac{a+b\\ln(x)}{2b}\\right)\n=\\pm\\sqrt{c}\\exp\\left(\\frac{-a}{2b}\\right)\n\\\\\n\\color{red}{-\\frac{a+b\\ln(x)}{2b}\\exp\\left(-\\frac{a+b\\ln(x)}{2b}\\right)\n=\\mp\\frac{\\sqrt{c}}{2b}\\exp\\left(\\frac{-a}{2b}\\right)}\n\\\\\n\\color{blue}{-\\frac{a+b\\ln(x)}{2b} = \nW\\left(\\mp\\frac{\\sqrt{c}}{2b}\\exp\\left(\\frac{-a}{2b}\\right)\\right)}\n\\\\\n\\ln(x) =\n\\frac{-a-2bW\\left(\\mp\\frac{\\sqrt{c}}{2b}\\exp\\left(\\frac{-a}{2b}\\right)\\right)}{b}\n\\\\\nx =\n\\exp\\left(-\\frac{a}{b}-2\nW\\left(\\mp\\frac{\\sqrt{c}}{2b}\\exp\\left(\\frac{-a}{2b}\\right)\\right)\\right)\n$$\n\nThe other example mentioned...\n$$\n\\frac{a+b\\ln(t)}{t}=c\n\\\\\n(a+b\\ln(t))e^{-\\ln(t)} = c\n\\\\\n(a+b\\ln(t))\\exp\\left(-\\frac{a}{b}-\\ln(t)\\right) \n= c \\exp\\left(-\\frac{a}{b}\\right)\n\\\\\n(a+b\\ln(t))\\exp\\left(-\\frac{a+b\\ln(t)}{b}\\right) \n= c \\exp\\left(-\\frac{a}{b}\\right)\n\\\\\n\\color{red}{-\\frac{a+b\\ln(t)}{b}\\exp\\left(-\\frac{a+b\\ln(t)}{b}\\right) \n= -\\frac{c}{b} \\exp\\left(-\\frac{a}{b}\\right)}\n\\\\\n\\color{blue}{-\\frac{a+b\\ln(t)}{b} = W\\left(-\\frac{c}{b} \\exp\\left(-\\frac{a}{b}\\right)\\right)}\n\\\\\n\\ln(t) = -\\frac{a+bW\\left(-\\frac{c}{b} \\exp\\left(-\\frac{a}{b}\\right)\\right)}{b}\n\\\\\nt = \\exp\\left(-\\frac{a+bW\\left(-\\frac{c}{b} \\exp\\left(-\\frac{a}{b}\\right)\\right)}{b}\\right)\n$$\nWe may question the other solution given in the OP.  In fact, this solution\nis equal to that solution:\nClaim\n$$\n\\exp\\left(-\\frac{a+bW\\left(-\\frac{c}{b} \\exp\\left(-\\frac{a}{b}\\right)\\right)}{b}\\right)\n=\n-\\frac{b}{c}W\\left(-\\frac{c}{b} \\exp\\left(-\\frac{a}{b}\\right)\\right)\n\\tag1$$\nWhy?\n$$\n\\text{Let}\\quad Q = W\\left(-\\frac{c}{b} \\exp\\left(-\\frac{a}{b}\\right)\\right).\n\\\\\n\\text{Then}\\quad Qe^Q = -\\frac{c}{b}\\exp\\left(-\\frac{a}{b}\\right)\n\\\\\n-\\frac{b}{c}Q = \\exp\\left(-\\frac{a}{b}\\right)e^{-Q}\n\\\\\n-\\frac{b}{c}Q = \\exp\\left(-\\frac{a+bQ}{b}\\right)\n\\\\\n\\text{which is $(1)$.}\n$$\n\nChallenge:\nSimplity the first solution in the same way:\n$$\nx = \\left[\\frac{2b}{\\sqrt{c}}W\\left(\\mp\\frac{\\sqrt{c}}{2b}\\exp\\left(-\\frac{a}{2b}\\right)\\right)\\right]^2\n$$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/410729", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "5", "answer_count": 1, "answer_id": 0}}
{"Q": "Infinite series for $1/\\pi$. Is it known? Indirect method (associated with a certain problem of electrostatics) indicates that  $$\\sum\\limits_{j=1}^\\infty \\frac{(2j-3)!!\\,(2j-1)!!}{(2j-2)!!\\,(2j+2)!!}=\\frac{2}{3\\pi}.$$ Is this result known?\n", "A": "Using the standard power series for the complete elliptic integral of the second kind $$E(k) = \\frac{\\pi}{2} \\sum_{j=0}^\\infty \\left(\\frac{(2j)!}{2^{2j}(j!)^2}\\right)^2 \\frac{k^{2j}}{1-2j},$$\nwe find\n\\begin{align*}\n\\sum\\limits_{j=1}^\\infty \\frac{(2j-3)!!\\,(2j-1)!!}{(2j-2)!!\\,(2j+2)!!} k^{2j}&=\\sum_{j=1}^\\infty\\frac{-j}{j+1} \\left(\\frac{(2j)!}{2^{2j}(j!)^2}\\right)^2 \\frac{k^{2j}}{1-2j} \\\\\n&= -\\frac{1}{k^2} \\int_0^k\\mathrm{d}k\\,k^2 \\frac{\\mathrm{d}}{\\mathrm{d}k}\\left(\\frac{2}{\\pi}E(k)\\right)\\\\\n&= \\frac{2}{3}\\frac{k^2-1}{k^2}\\frac{2}{\\pi}K(k) - \\frac{k^2-2}{3k^2}\\frac{2}{\\pi}E(k).\n\\end{align*}\nIn the limit $k\\to 1$ only the second term survives with $E(1)=1$ and therefore\n\\begin{align*}\n\\sum\\limits_{j=1}^\\infty \\frac{(2j-3)!!\\,(2j-1)!!}{(2j-2)!!\\,(2j+2)!!} &=\\frac{2}{3\\pi}.\n\\end{align*}\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/418193", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "7", "answer_count": 1, "answer_id": 0}}
{"Q": "Some Log integrals related to Gamma value Two years ago I evaluated some integrals related to $\\Gamma(1/4)$.\nFirst example:\n$$(1)\\hspace{.2cm}\\int_{0}^{1}\\frac{\\sqrt{x}\\log{(1+\\sqrt{1+x})}}{\\sqrt{1-x^2}} dx=\\pi-\\frac{\\sqrt {2}\\pi^{5/2}+4\\sqrt{2}\\pi^{3/2}}{2\\Gamma{(1/4)^{2}}}.$$\nThe proof I have is based on the following formula concerning the elliptic integral of first kind (integrating both sides with carefully).\n$$i \\cdot K(\\sqrt{\\frac{2k}{1+k}})=K(\\sqrt{\\frac{1-k}{1+k}})-K(\\sqrt{\\frac{1+k}{1-k}})\\cdot\\sqrt{\\frac{1+k}{1-k}}$$\nfor $0<k<1$.\n\\begin{align}\n(2)\\hspace{.2cm}\\int_{0}^{1}\\frac{\\sqrt{2x-1}-2x  \\arctan{(\\sqrt{2x-1})}}{\\sqrt{x(1-x)}(2x-1)^{3/2}}dx=\\frac{\\sqrt{2}\\pi^{5/2}}{\\Gamma{(1/4)}^2}-\\frac{\\sqrt{2\\pi}\\Gamma{(1/4)}^2}{8}.\n\\end{align}\n\\begin{align}\n(3)\\hspace{.2cm}\\int_{0}^{\\pi/2}\\frac{\\sin{x}\\log{(\\tan{(x/2))}+x}}{\\sqrt{\\sin{x}}(\\sin{x}+1)}dx=\\pi-\\frac{\\sqrt{2\\pi}\\Gamma{(1/4)}^{2}}{16}-\\frac{\\sqrt{2}\\pi^{5/2}}{2\\Gamma{(1/4)}^{2}}.\n\\end{align}\nCould you find a solution to (2) and (3) employing only Beta function or other method?\nI've tried with Mathematica, Mapple, etc and seems that this evaluations are not so well known.\nQuestion is an improvement of (1) that has been proved in an elementary approach.\n", "A": "I also played around with this integral. My solution is a bit shorter than the OPs: First use the trick by @Claude and define\n$$\\tag{1}\nI(a)=\\int_0^1 \\mathrm dx \\sqrt\\frac{x}{1-x^2}\\log(a+\\sqrt{1+x}),\n$$\nsuch that\n$$\\tag{2}\nI(1) = I(0) + \\int_0^1 \\mathrm da \\, I'(a).\n$$\nPartial fraction decomposition of $I'(a)$ gives\n\\begin{align}\nI'(a) &= \\int_0^1 \\mathrm dx \\frac{\\sqrt\\frac{x}{1-x^2}}{a+\\sqrt{1+x}} \n\\,\\frac{a-\\sqrt{1+x}}{a-\\sqrt{1+x}}\\tag{3a}\\\\\n&=\\int_0^1 \\mathrm dx \\frac{\\sqrt\\frac{x}{1-x}}{1+x-a^2}\n+ \\int_0^1 \\mathrm dx \\frac{a\\sqrt\\frac{x}{1-x^2}}{a^2-x-1}\\tag{3b}.\n\\end{align}\nNow we exchange the integration order in the second term only and also move $I(0)$ into the second term, to get the result\n\\begin{align}\nI(1) &= \n\\int_0^1 \\mathrm da \\int_0^1 \\mathrm dx \\frac{\\sqrt\\frac{x}{1-x}}{1+x-a^2} \n&+&\n\\int_0^1 \\mathrm dx \\int_0^1 \\mathrm da \\frac{a\\sqrt\\frac{x}{1-x^2}}{a^2-x-1}+I(0) \\tag{4a}\\\\\n&= \\int_0^1 \\mathrm da \\, \\pi\\left(1-\\sqrt{\\tfrac{1-a^2}{2-a^2}}\\right)\n&+&\n\\int_0^1 \\mathrm dx \\sqrt{\\tfrac{x}{1-x^2}} \\log\\sqrt x\\tag{4b}\\\\\n&= \\pi-\\pi^{3/2}\\frac{\\Gamma\\left(\\tfrac{3}{4}\\right)}{\\Gamma\\left(\\tfrac{1}{4}\\right)} \n&+&\\,\\,\n\\frac{(\\pi-4)\\sqrt\\pi \\,\\Gamma\\left(\\tfrac{3}{4}\\right) }{2\\Gamma\\left(\\tfrac{1}{4}\\right)}\\tag{4c}\\\\\n&=\\pi-\\frac{(\\pi+4)\\sqrt\\pi \\,\\Gamma\\left(\\tfrac{3}{4}\\right) }{2\\Gamma\\left(\\tfrac{1}{4}\\right)}.\\tag{4d}\n\\end{align}\nNote that in (4c) the Beta function integral as motivated by @Carlo was used.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/437979", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "3", "answer_count": 3, "answer_id": 1}}
