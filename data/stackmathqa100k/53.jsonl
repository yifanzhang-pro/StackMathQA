{"Q": "Integration of the product of pdf & cdf of normal distribution  Denote the pdf of normal distribution as $\\phi(x)$ and cdf as $\\Phi(x)$. Does anyone know how to calculate $\\int \\phi(x) \\Phi(\\frac{x -b}{a}) dx$? Notice that when $a = 1$ and $b = 0$ the answer is $1/2\\Phi(x)^2$. Thank you!\n", "A": "We have $\\phi(x)=\\frac 1{\\sqrt{2\\pi}}\\exp\\left(-\\frac{\u2020^2}2\\right)$ and $\\Phi(x)=\\int_{-\\infty}^x\\phi(t)dt$. We try to compute\n$$ I(a,b):=\\int\\phi(x)\\Phi\\left(\\frac{x-b}a\\right)dx.$$\nUsing the dominated convergence theorem, we are allowed to take the derivative with respect to $b$ inside the integral. We have \n$$\\partial_bI(a,b)=\\int\\phi(x)\\left(-\\frac 1a\\right)\\phi\\left(\\frac{x-b}a\\right)dx$$\nand \n\\begin{align}\n2\\pi\\phi(x)\\phi\\left(\\frac{x-b}a\\right)&=\\exp\\left(-\\frac 12\\left(x^2+\\frac{x^2}{a^2}-2\\frac{bx}{a^2}+\\frac{b^2}{a^2}\\right)\\right)\\\\\\\n&=\\exp\\left(-\\frac 12\\frac{a^2+1}{a^2}\\left(x^2-2\\frac b{a^2+1}x+\\frac{b^2}{a^2+1}\\right)\\right)\\\\\\\n&=\\exp\\left(-\\frac 12\\frac{a^2+1}{a^2}\\left(x-\\frac b{a^2+1}\\right)^2-\\frac 12\\frac{a^2+1}{a^2}\\left(\\frac{b^2}{a^2+1}-\\frac{b^2}{(a^2+1)^2}\\right)\\right)\\\\\\\n&=\\exp\\left(-\\frac 12\\frac{a^2+1}{a^2}\\left(x-\\frac b{a^2+1}\\right)^2\\right)\\exp\\left(-\\frac{b^2}{2a^2}\\frac{a^2+1-1}{a^2+1}\\right)\\\\\\\n&=\\exp\\left(-\\frac 12\\frac{a^2+1}{a^2}\\left(x-\\frac b{a^2+1}\\right)^2\\right)\\exp\\left(-\\frac{b^2}{2(a^2+1)}\\right).\n\\end{align}\nIntegrating with respect to $x$, we get that \n$$\\partial_b I(a,b)=-\\frac 1{\\sqrt{a^2+1}}\\phi\\left(\\frac b{\\sqrt{a^2+1}}\\right).$$\nSince $\\lim_{b\\to +\\infty}I(a,b)=0$, we have \n\\begin{align}I(a,b)&=\\int_b^{+\\infty}\\frac 1{\\sqrt{a^2+1}}\\phi\\left(\\frac s{\\sqrt{a^2+1}}\\right)ds\\\\\\\n&=\\int_{b/\\sqrt{a^2+1}}^{+\\infty}\\phi(t)dt = 1 - \\Phi(b/\\sqrt{a^2+1}).\n\\end{align}\nThis can be expressed with the traditional erf function. \n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/101469", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "7", "answer_count": 3, "answer_id": 0}}
{"Q": "Logarithm of the hypergeometric function For $F(x)={}_2F_1 (a,b;c;x)$, with $c=a+b$, $a>0$, $b>0$, it has been proved in [1] that $\\log F(x)$ is convex on $(0,1)$.\nI numerically checked that with a variety of $a,\\ b$ values, $\\log F(x)$ is not only convex, but also has a Taylor series in x consisting of strictly positive coefficients. Can this be proved?\n[1] Generalized convexity and inequalities, Anderson, Vamanamurthy, Vuorinen, Journal of Mathematical Analysis and Applications, Volume 335, Issue 2,\nhttp://www.sciencedirect.com/science/article/pii/S0022247X07001825#\n", "A": "Here's a sketch of a proof of a stronger statement: the coefficients of the Taylor series for $\\log{}_2F_1(a,b;a+b+c;x)$ are rational functions of $a$, $b$, and $c$ with positive coefficients.\nTo see this we first note that \n$$\\begin{aligned}\n\\frac{d\\ }{dx} \\log {}_2F_1(a,b;a+b+c;x) &= \n\\frac{\\displaystyle\n\\frac{d\\ }{dx}\\,{}_2F_1(a,b;a+b+c;x)}{{}_2F_1(a,b;a+b+c;x)}\\\\[3pt]\n &=\\frac{ab}{a+b+c}\\frac{{}_2F_1(a+1,b+1;a+b+c+1;x)}{{}_2F_1(a,b;a+b+c;x)}.\n\\end{aligned}\n$$\nThen \n$$\n\\begin{gathered}\n\\frac{{}_2F_1(a+1,b+1;a+b+c+1;x)}{{}_2F_1(a,b;a+b+c;x)}\n  = \\frac{{}_2F_1(a+1,b+1;a+b+c+1;x)}{{}_2F_1(a,b+1;a+b+c;x)} \\\\\n \\hfill\\times\n  \\frac{{}_2F_1(a,b+1;a+b+c;x)}{{}_2F_1(a,b;a+b+c;x)}.\\quad\n\\end{gathered}\n$$\nWe have continued fractions for the two quotients on the right.\nLet $S(x; a_1, a_2, a_3, \\dots)$ denote the continued fraction\n$$\\cfrac{1}{1-\\cfrac{a_1x}\n{1-\\cfrac{a_2x}\n{1-\\cfrac{a_3x}\n{1-\\ddots}\n}}}\n$$\nThen\n$$\\begin{gathered}\\frac{{}_2F_1(a+1,b+1;a+b+c+1;x)}{{}_2F_1(a,b+1;a+b+c;x)}\n = S \\left( x;{\\frac { \\left( b+1 \\right)  \\left( b+c \\right) }{ \\left( a\n+b+c+1 \\right)  \\left( a+b+c \\right) }},\n\\right.\\hfill\\\\\n\\left.\n{\\frac { \\left( a+1 \\right) \n \\left( a+c \\right) }{ \\left( a+b+c+2 \\right)  \\left( a+b+c+1 \\right) \n}}, \n{\\frac { \\left( b+2 \\right)  \\left( b+c+1 \\right) }{ \\left( a+b+c+3\n \\right)  \\left( a+b+c+2 \\right) }},\n \\right.\\\\\n\\hfill\n\\left.\n {\\frac { \\left( a+2 \\right) \n \\left( a+c+1 \\right) }{ \\left( a+b+c+4 \\right)  \\left( a+b+c+3\n \\right) }},\\dots \\right) \n \\end{gathered}\n$$\nand \n$$\\begin{gathered}\n\\frac{{}_2F_1(a,b+1;a+b+c;x)}{{}_2F_1(a,b;a+b+c;x)}\n=S \\left( x,{\\frac {a}{a+b+c}},\n{\\frac { \\left( b+1 \\right)  \\left( b+c\n \\right) }{ \\left( a+b+c+1 \\right)  \\left( a+b+c \\right) }},\n \\right.\\hfill\\\\\n \\left.\n {\\frac {\n \\left( a+1 \\right)  \\left( a+c \\right) }{ \\left( a+b+c+2 \\right) \n \\left( a+b+c+1 \\right) }},\n {\\frac { \\left( b+2 \\right)  \\left( b+c+1\n \\right) }{ \\left( a+b+c+3 \\right)  \\left( a+b+c+2 \\right) }},\n  \\right.\\\\\n \\hfill\n \\left.\n {\\frac {\n \\left( a+2 \\right)  \\left( a+c+1 \\right) }{ \\left( a+b+c+4 \\right) \n \\left( a+b+c+3 \\right) }}, \\dots\\right) \n\\end{gathered}\n$$\nThe first of these continued fractions is Gauss's well-known continued fraction, and the second can easily be derived from the first. It follows from these formulas that the coefficients of the Taylor series for $\\log{}_2F_1(a,b;a+b+c;x)$ are rational functions of $a$, $b$, and $c$ with positive coefficients.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/143350", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "7", "answer_count": 2, "answer_id": 0}}
{"Q": "How many solutions to $2^a + 3^b = 2^c + 3^d$? A few weeks ago, I asked on math.stackexchange.com how many quadruples of non-negative integers $(a,b,c,d)$  satisfy the following equation:\n$$2^a + 3^b = 2^c + 3^d \\quad (a \\neq c)$$\nI found 5 quadruples:  $5 = 2^2 + 3^0 = 2^1 + 3^1$, $11 = 2^3 + 3^1 = 2^1 + 3^2$, $17 = 2^4 + 3^0 = 2^3 + 3^2$, $35 = 2^5 + 3^1 = 2^3 + 3^3$, $259 = 2^8 + 3^1 = 2^4 + 3^5$\nI didn't get an answer, but only a link to an OEIS sequence (no more quadruples below $10^{4000}$), so I'm asking the same question here. \n\nIs there a way to prove that they are [not] infinite?\n\nAnd, more generally, are there known tuples for which the following equation:\n$$p_{i_1}^{a_1} + p_{i_2}^{a_2} + ... + p_{i_n}^{a_n}=p_{i_1}^{b_1} + p_{i_2}^{b_2} + ... + p_{i_n}^{b_n}$$\nholds for infinitely many  (or holds only for finitely many) $a_i,b_i$?\n", "A": "The answer is yes, there are finitely many for positive $a, b, c, d$, and you've found all of them.\nSee Theorem 7 of R. Scott, R. Styer, On the generalized Pillai equation $\\pm a^x \\pm b^y = c$, Journal of Number Theory, 118 (2006), 236\u2013265.  I quote:\n\nTheorem 7. Let $a$ be prime, $a>b$, $b = 2$ or $b = 3$, $a$ not a large base-$b$ Wieferich prime, $1 \\le x_1 \\le x_2$, $1 \\le y_1 \\le y_2$, and $(x_1, y_1) \\neq (x_2, y_2)$.  If there is a solution $(a, x_1, y_1, x_2, y_2)$ to the equation $$\\left|a^{x_1} - b^{y_1}\\right| = \\left|a^{x_2} - b^{y_2}\\right|$$ then it is one of\n$$\\begin{align*}\n3-2&=3^2-2^3,\\\\ \n2^3-3&=2^5-3^3,\\\\\n2^4-3&=2^8-3^5,\\\\\n\\cdots&=\\cdots\n\\end{align*}$$\nwhere the omitted cases are irrelevant.  The three listed equations are your decompositions of $\\fbox{11}$, $\\fbox{35}$, and $\\fbox{259}$.\n\nNow we show that the answer is yes for non-negative $a, b, c, d$, and you've also found all of them.\nThe only solutions to your equation not covered by the above result correspond to solutions of $$1 - 2^x + 2^y = 3^z, $$ where we may assume $0 < x < y$.\nIf $z$ is odd, then the RHS is 3 modulo 4 and so we must have $x = 1$.  Hence $3^z - 2^y = 3 - 2$ and so by the above we have the only solution as $(x, y, z) = (1,2,1)$.  This is your decomposition of $\\fbox{5}$.\nIf $z$ is even, then the RHS is a perfect square.  Working modulo 3 we see that we must have $x$ odd and $y$ even.  Write $z' = z/2, y' = y/2, x' = x-1$, and note that $x' > 0$ is even.\nIf $x' < y'$ then we have $(2^{y'}-1)^2 = 1 - 2^{y'} + 2^y < 1 - 2^x + 2^y < 2^y = (2^{y'})^2$, and so the LHS cannot be a perfect square.  Hence $x' \\ge y'$.\nIf we have $x' = y'$, then we have $3^{z'} = 2^{y'} - 1$; this gives the solution $(x,y,z) = (3,4,2)$, corresponding to your decomposition of $\\fbox{17}$.\n\nWe claim that there are no other solutions.\nAny other solution must have $x' > y'$.  We rearrange and write $$\\left(2^{x'} - 1 + 3^{z'}\\right)\\left(2^{x'} - 1 - 3^{z'}\\right) = 2^{2x'} - 2^{2y'}.$$  Note that we must have $2^{x'}-1 > 3^{z'}$ so that the signs on each side match.\nThe RHS is divisible by $2^{2y'}$.  As $x < y$ we have $2y' \\ge x' + 2$.\nWe have $\\gcd(2^{x'} - 1 + 3^{z'}, 2^{x'} - 1 - 3^{z'}) = \\gcd(2^{x'} - 1 - 3^{z'},2\\cdot3^{z'})$, which is divisible by 2 but not by 4.  Hence one of $2^{x'} - 1 + 3^{z'}$ and $2^{x'} - 1 - 3^{z'}$ is divisible by $2^{2y' - 1} \\ge 2^{x' + 1}$.  But $$2^{x' + 1} = 2^{x'} + 2^{x'} > 2^{x'} - 1 + 3^{z'} > 2^{x'} - 1 - 3^{z'},$$ and so neither can be divisible by $2^{2y' - 1}$.  Hence there are no more solutions.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/164624", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "11", "answer_count": 6, "answer_id": 4}}
{"Q": "How do we show this matrix has full rank? \nI met with the following difficulty reading the paper Li, Rong Xiu \"The properties of a matrix order column\" (1988):\nDefine the matrix $A=(a_{jk})_{n\\times n}$, where \n  $$a_{jk}=\\begin{cases}\nj+k\\cdot i&j<k\\\\\nk+j\\cdot i&j>k\\\\\n2(j+k\\cdot i)& j=k\n\\end{cases}$$\n  and  $i^2=-1$.\nThe author says it is easy to show that $rank(A)=n$. I have proved for $n\\le 5$, but I couldn't prove for general $n$.\n\nFollowing is an attempt to solve this problem:\nlet\n$$A=P+iQ$$\nwhere\n$$P=\\begin{bmatrix}\n2&1&1&\\cdots&1\\\\\n1&4&2&\\cdots& 2\\\\\n1&2&6&\\cdots& 3\\\\\n\\cdots&\\cdots&\\cdots&\\cdots&\\cdots\\\\\n1&2&3&\\cdots& 2n\n\\end{bmatrix},Q=\\begin{bmatrix} \n2&2&3&\\cdots& n\\\\\n2&4&3&\\cdots &n\\\\\n3&3&6&\\cdots& n\\\\\n\\cdots&\\cdots&\\cdots&\\cdots&\\cdots\\\\\nn&n&n&\\cdots& 2n\\end{bmatrix}$$\nand define\n$$J=\\begin{bmatrix}\n1&0&\\cdots &0\\\\\n-1&1&\\cdots& 0\\\\\n\\cdots&\\cdots&\\cdots&\\cdots\\\\\n0&\\cdots&-1&1\n\\end{bmatrix}$$\nthen we have\n$$JPJ^T=J^TQJ=\\begin{bmatrix}\n2&-2&0&0&\\cdots&0\\\\\n-2&4&-3&\\ddots&0&0\\\\\n0&-3&6&-4\\ddots&0\\\\\n\\cdots&\\ddots&\\ddots&\\ddots&\\ddots&\\cdots\\\\\n0&0&\\cdots&-(n-2)&2(n-1)&-(n-1)\\\\\n0&0&0&\\cdots&-(n-1)&2n\n\\end{bmatrix}$$\nand $$A^HA=(P-iQ)(P+iQ)=P^2+Q^2+i(PQ-QP)=\\binom{P}{Q}^T\\cdot\\begin{bmatrix}\nI& iI\\\\\n-iI & I\n \\end{bmatrix} \\binom{P}{Q}$$\n", "A": "OK, let me try again, maybe I'll get it right this time. I'll show that $P$ is positive definite. This will imply the claim because if $(P+iQ)(x+iy)=0$ with $x,y\\in\\mathbb R^n$, then $Px=Qy$, $Py=-Qx$, and by taking scalar products with $x$ and $y$, respectively, we see that $\\langle x, Px \\rangle = -\\langle y, Py\\rangle$, which implies that $x=y=0$. Here I use that $Q$ is symmetric.\nLet me now show that $P>0$. Following math110's suggestion, we can simplify my original calculation as follows: Let\n$\nB=B_n = P -\\textrm{diag}(1,2,\\ldots , n)$. For example, for $n=5$, this is the matrix\n$$ B_ 5= \\begin{pmatrix} 1 & 1 & 1  & 1 & 1\\\\\n1 & 2 & 2  & 2 & 2\\\\\n1 & 2 & 3 & 3 & 3\\\\\n1 & 2 & 3 & 4 & 4\\\\\n1 & 2 & 3 & 4 & 5\n\\end{pmatrix} .\n$$\nI can now (in general) subtract the $(n-1)$st row from the last row, then the $(n-2)$nd row from the $(n-1)$st row etc. This confirms that $\\det B_n=1$. Moreover, the upper left $k\\times k$ submatrices of $B_n$ are of the same type; they equal $B_k$.\nThis shows that $B>0$, by Sylvester's criterion, and thus $P>0$ as well.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/191796", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "12", "answer_count": 3, "answer_id": 1}}
{"Q": "Angle subtended by the shortest segment that bisects the area of a convex polygon Let $C$ be a convex polygon in the plane and let $s$ be the shortest line segment (I believe this is called a \"chord\") that divides the area of $C$ in half. What is the smallest angle that $s$ could make where it touches the boundary of $C$?  This picture shows an example, I I called the angle $\\theta$ (and the area of the region is $A$):\n\nNumerical simulations suggest that $\\theta\\geq\\pi/3$ but I haven't been able to prove this.\n", "A": "I'll prove that for any triangle below, $\\displaystyle \\theta  \\geqq \\pi /3\\ $\n\nAssuming $\\displaystyle X'Y' =z$ be the line segment that bisects area $\\displaystyle A$ of triangle $\\displaystyle XYZ$ .\nLet $\\displaystyle \\angle Z=\\alpha $ , $\\displaystyle Y'Z=x$ and $\\displaystyle X'Z=y$\nBy Heron's formula, $\\displaystyle \\frac{A}{2} =\\frac{1}{4}\\sqrt{( x+y+z)( x+y-z)( x-y+z)( -x+y+z)} =\\frac{1}{4}\\sqrt{( 2xy)^{2} -\\left( x^{2} +y^{2} -z^{2}\\right)^{2}}$ ,\nso we get $\\displaystyle z=\\sqrt{x^{2} +y^{2} -2\\sqrt{( xy)^{2} -A^{2}}} \\geqq \\sqrt{2xy-2\\sqrt{( xy)^{2} -A^{2}}}$ .\nOn the other hand, $\\displaystyle \\frac{A}{2} =\\frac{1}{2} xy\\sin \\alpha $, so $\\displaystyle xy=\\frac{A}{\\sin \\alpha }$,\nand we get $ $$\\displaystyle z\\geqq \\sqrt{2A\\left(\\frac{1}{\\sin \\alpha } -\\frac{1}{\\tan \\alpha }\\right)} =\\sqrt{2A\\tan\\frac{\\alpha }{2}}$\nWhen $\\displaystyle x=y$ and $\\displaystyle \\alpha $ be the smallest angle of triangle $\\displaystyle XYZ$, $\\displaystyle z$ get the minimum value.\nand then $\\displaystyle \\theta =\\frac{\\pi -\\alpha }{2}$, so $\\displaystyle  \\theta \\geqq \\pi /3\\ $.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/201181", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "8", "answer_count": 2, "answer_id": 1}}
{"Q": "Curious inequality Set \n$$\ng(x)=\\sum_{k=0}^{\\infty}\\frac{1}{x^{2k+1}+1}  \\quad \\text{for}  \\quad  x>1. \n$$\nIs it true that \n$$\n\\frac{x^{2}+1}{x(x^{2}-1)}+\\frac{g'(x)}{g(x)}>0 \\quad \\text{for}\\quad x>1? \n$$\nThe answer seems to be positive. I spent several hours in proving this statement but I did not come up with anything reasonable. Maybe somebody else has (or will have) any bright idea?  \nMotivation? Nothing important, I was just playing around this question:\nA problem of potential theory arising in biology\n", "A": "The inequality is equivalent to \n$$S := (x^2+1)g(x) + x(x^2-1)g'(x) > 0.$$ \nThe left hand side here can be expanded to\n$$S = \\sum_{k\\geq 0} \\frac{(x^2+1)(x^{2k+1}+1) - (2k+1)x^{2k+1}(x^2-1)}{(x^{2k+1}+1)^2} $$\n$$= \\sum_{k\\geq 0} \\frac{(x^2+1) - (2k+1)(x^2-1)}{x^{2k+1}+1} + \\sum_{k\\geq 0}\\frac{(2k+1)(x^2-1)}{(x^{2k+1}+1)^2}.$$\nNow, the first sum here simplifies to\n$$\\sum_{k\\geq 0} \\frac{(x^2+1) - (2k+1)(x^2-1)}{x^{2k+1}+1} = \\sum_{k\\geq 0} \\frac{(2k+2)-2k x^2}{x^{2k+1}+1}$$\n$$=\\sum_{k\\geq 1} \\left( \\frac{2k}{x^{2k-1}+1} - \\frac{2k x^2}{x^{2k+1}+1}\\right)=(1-x^2)\\sum_{k\\geq 1} \\frac{2k}{(x^{2k-1}+1)(x^{2k+1}+1)}.$$\nHence\n$$\\frac{S}{x^2-1} = \\sum_{k\\geq 0}\\frac{2k+1}{(x^{2k+1}+1)^2} - \\sum_{k\\geq 1} \\frac{2k}{(x^{2k-1}+1)(x^{2k+1}+1)}$$\n$$\\geq \\sum_{k\\geq 0}\\frac{2k+1}{(x^{2k+1}+1)^2} - \\sum_{k\\geq 1} \\frac{2k}{(x^{2k}+1)^2} = \\sum_{k\\geq 1} \\frac{(-1)^{k-1}k}{(x^{k}+1)^2}.$$\nHere we used AM-GM inequality $x^{2k-1}+x^{2k+1}\\geq 2x^{2k}$ and thus \n$$(x^{2k-1}+1)(x^{2k+1}+1)=x^{4k}+x^{2k+1}+x^{2k-1}+1\\geq (x^{2k}+1)^2.$$\nSo it remains to prove that for $x>1$,\n$$\\sum_{k\\geq 1} \\frac{(-1)^{k-1}k}{(x^{k}+1)^2} > 0.\\qquad(\\star)$$\nUPDATE #1. Substituting $x=e^{2t}$, we have\n$$\\sum_{k\\geq 1} \\frac{(-1)^{k-1}k}{(x^{k}+1)^2} = \\sum_{k\\geq 1} \\frac{(-1)^{k-1}ke^{-2tk}}{4 \\cosh(tk)^2} = \\frac{1}{4}\\sum_{k\\geq 1} (-1)^{k-1}ke^{-2tk}(1-\\tanh(tk)^2)$$\n$$ = \\frac{e^{2t}}{4(e^{2t}+1)^2} - \\frac{1}{4}\\sum_{k\\geq 1} (-1)^{k-1}ke^{-2tk} \\tanh(tk)^2.$$\nUPDATE #2. The proof of $(\\star)$ is given by Iosif Pinelis.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/217711", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "24", "answer_count": 3, "answer_id": 2}}
{"Q": "Are the following identities well known? $$\nx \\cdot y = \\frac{1}{2 \\cdot 2 !} \\left( (x + y)^2 - (x - y)^2 \\right)\n$$\n$$\n\\begin{eqnarray}\nx \\cdot y \\cdot z &=& \\frac{1}{2^2 \\cdot 3 !} ((x + y + z)^3 - (x + y - z)^3 \\nonumber \\\\\n&-& (x - y + z)^3 + (x - y - z)^3 ), \n\\end{eqnarray}\n$$\n$$\n\\begin{eqnarray}\nx \\cdot y \\cdot z \\cdot w &=& \\frac{1}{2^3 \\cdot 4 !} ( (x + y + z + w)^4 \\nonumber \\\\\n&-& (x + y + z - w)^4 - (x + y - z + w)^4 \\nonumber \\\\\n&+& (x + y - z - w)^4 - (x - y + z + w)^4 \\nonumber \\\\\n&+& (x - y + z - w)^4 + (x - y - z + w)^4 \\nonumber \\\\\n&-& (x - y - z - w)^4 ). \n\\end{eqnarray}\n$$\nThe identity that rewrites a product of $n$ variables $( n \\ge 2$, $n \\in \\boldsymbol{\\mathbb{Z}_+})$ as additions of $n$ th power functions is as given below:\n$$\n\\begin{eqnarray}\n& &x_0 \\cdots x_1 \\cdot x_{n-1} = \\frac{1}{2^{n - 1} \\cdot n !} \\cdot \\sum_{j = 0}^{2^{ n - 1} -1} ( - 1 )^{\\sum_{m = 1}^{n - 1} \\sigma_m(j)} \\times ( x_0 + (-1)^{\\sigma_1(j)} x_1 + \\cdots + (- 1)^{\\sigma_{n - 1}(j)} x_{n - 1})^n, \\\\\n& &\\sigma_m(j) = r(\\left\\lfloor \\frac{j}{2^{m - 1}}\\right\\rfloor, 2), m (\\ge 1), j (\\ge 0) \\in \\mathbb{Z}_+, \\; \\left\\lfloor x \\right\\rfloor = \\max \\{ n \\in \\mathbb{Z}_+ ; n \\le x, x \\in \\mathbb{R} \\}\n\\end{eqnarray}\n$$\nwhere $r(\\alpha, \\beta)$,  $\\alpha, \\beta (\\ge 1) \\in \\mathbb{Z}_+$ means the remainder of the division of $\\alpha$ by $\\beta$ such that $r(\\alpha, \\beta)$ $=$ $\\alpha - \\beta \\left\\lfloor \\frac{\\alpha}{\\beta}\\right\\rfloor$\n", "A": "Although not the exactly the same due to $2^{n-1}$ instead of $2^n$ terms, the OP's formula seems to be essentially the well-known polarization formula for homogeneous polynomials, which is stated as following:\n\nAny polynomial $f$, homogeneous of degree $n$ can be written as $f(x)=H(x,\\ldots,x)$ for a specific multilinear form $H$. One has the following polarization formula for $H$ (see also this MO post):\n  \\begin{equation*}\n H(x_1,\\ldots,x_n) = \\frac{1}{2^n n!}\\sum_{s \\in \\{\\pm 1\\}^n}s_1\\ldots s_n f\\Bigl(\\sum\\nolimits_{j=1}^n s_jx_j\\Bigr)\n\\end{equation*}\n\nIn your case, $f=x^n$, so $H(x_1,\\ldots,x_n) = x_1\\cdots x_n$ (please note off by 1 indexing).\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/220447", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "19", "answer_count": 1, "answer_id": 0}}
{"Q": "Why is this not a perfect square? Let $x, y$ and $z$ be positive integers with $x<y$. It appears that the integer\n$$(y^2z^3-x)(y^2z^3+3x)$$\nis never a perfect square. Why? A proof? I'm not sure if it is easy.\n", "A": "Rewrite your expression as $(y^2z^3+x)^2-4x^2$. This is clearly less than $(y^2z^3+x)^2$. On the other hand, it is larger than $(y^2z^3+x-2)^2=(y^2z^3+x)^2-4(y^2z^3+x)+4$, since $4(y^2z^3+x)-4\\geq 4y^2+4x-4\\geq 4y^2>4x^2$. So if this expression is a square, it must be $(y^2z^3+x-1)^2=(y^2z^3+x)^2-2(y^2z^3+x)+1$, so $4x^2=2(y^2z^3+x)-1$. LHS is even, while RHS is odd, so this can't be.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/250163", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "Algorithm to decide whether two constructible numbers are equal? The set of constructible numbers \nhttps://en.wikipedia.org/wiki/Constructible_number\nis the smallest field extension of $\\mathbb{Q}$ that is closed under square root and complex conjugation. I am looking for an algorithm that decides if two constructible numbers are equal (or, what is the same, if a constructible number is zero). \nAs equality of rational numbers is trivial, this algorithm probably needs to reduce the complexity of the involved number in several steps.\nDoes such an algorithm exist? If yes, what does it look like?\n", "A": "Although this can be done using the complicated algorithms for general algebraic numbers, there\u2019s a much simpler recursive algorithm for constructible numbers that I implemented in the Haskell constructible library.\nA constructible field extension is either $\\mathbb Q$ or $F{\\left[\\sqrt r\\right]}$ for some simpler constructible field extension $F$ and $r \u2208 F$ with $\\sqrt r \u2209 F$.  We represent an element of $F{\\left[\\sqrt r\\right]}$ as $a + b\\sqrt r$ with $a, b \u2208 F$.  We have these obvious rules for $a, b, c, d \u2208 F$:\n$$\\begin{gather*}\n(a + b\\sqrt r) + (c + d\\sqrt r) = (a + c) + (b + d)\\sqrt r, \\\\\n-(a + b\\sqrt r) = -a + (-b)\\sqrt r, \\\\\n(a + b\\sqrt r)(c + d\\sqrt r) = (ac + bdr) + (ad + bc)\\sqrt r, \\\\\n\\frac{a + b\\sqrt r}{c + d\\sqrt r} = \\frac{ac - bdr}{c^2 - d^2 r} + \\frac{bc - ad}{c^2 - d^2 r}\\sqrt r, \\\\\na + b\\sqrt r = c + d\\sqrt r \\iff a = c \u2227 b = d.\n\\end{gather*}$$\nTo compute the square root of $a + b\\sqrt r \u2208 F{\\left[\\sqrt r\\right]}$:\n\n*\n\n*If $\\sqrt{a^2 - b^2 r} \u2208 F$ and $\\sqrt{\\frac{a + \\sqrt{a^2 - b^2 r}}{2}} \u2208 F$, then\n$$\\sqrt{a + b\\sqrt r} = \\sqrt{\\frac{a + \\sqrt{a^2 - b^2 r}}{2}} + \\frac{b}{2\\sqrt{\\frac{a + \\sqrt{a^2 - b^2 r}}{2}}}\\sqrt r \u2208 F{\\left[\\sqrt r\\right]}.$$\n\n*If $\\sqrt{a^2 - b^2 r} \u2208 F$ and $\\sqrt{\\frac{a + \\sqrt{a^2 - b^2 r}}{2r}} \u2208 F$, then\n$$\\sqrt{a + b\\sqrt r} = \\frac{b}{2\\sqrt{\\frac{a + \\sqrt{a^2 - b^2 r}}{2r}}} + \\sqrt{\\frac{a + \\sqrt{a^2 - b^2 r}}{2r}}\\sqrt r \u2208 F{\\left[\\sqrt r\\right]}.$$\n\n*Otherwise, $\\sqrt{a + b\\sqrt r} \u2209 F{\\left[\\sqrt r\\right]}$, so we represent it as\n$$0 + 1\\sqrt{a + b\\sqrt r} \u2208 F{\\left[\\sqrt r\\right]}\\left[\\sqrt{a + b\\sqrt r}\\right].$$\nIn order to compute with numbers represented in different field extensions, we need to rewrite them in a common field extension first.  To rewrite $a + b\\sqrt r \u2208 F{\\left[\\sqrt r\\right]}$ and $c \u2208 G$ in a common field extension, first rewrite $a, b, r \u2208 F$ and $c \u2208 G$ in a common field extension $H$.  If $\\sqrt r \u2208 H$, then we have $a + b\\sqrt r, c \u2208 H$; otherwise we have $a + b\\sqrt r, c + 0\\sqrt r \u2208 H{\\left[\\sqrt r\\right]}$.\nI implemented the constructible real numbers and built the constructible complex numbers generically on top of those, to enable ordering relations and to avoid having to think too hard about branch cuts.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/264827", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "6", "answer_count": 1, "answer_id": 0}}
{"Q": "Existence of generalized inverse-like operator Does there exist an operator, $\\star$, such that for all full rank matrices $B$ and all $A$ of appropriate dimensions:\n$$\nB(B^\\intercal AB)^\\star B^\\intercal = A^\\star,\n$$\nand such that $A^\\star=0$ if and only if $A=0$?\nEdit: Also, $\\star : \\operatorname{M}(m,n,\\mathbb R) \\to \\operatorname{M}(n,m,\\mathbb R)$.\nEdit: If possible, we would also like $\\operatorname{rank}(A^\\star)=\\operatorname{rank}(A)$.\n", "A": "No. We suppose it is defined for $2\\times 2$ matrices and we get a contradiction. Unless you drop the requirement on $\\operatorname{rank} A^\\star$ in which case $A^\\star=0$ trivially works.\nLet $A=\\begin{pmatrix} 1 & 0 \\\\ 0 & 0\\end{pmatrix}$ and let $B=\\begin{pmatrix} a & b\\\\ c & d\\end{pmatrix}$ with arbitrary $a,b,c,d\\in\\mathbb R$ satisfying $ad-bc\\neq 0$.\nThe key observation is that $B^T A B = \\begin{pmatrix} a^2 & ab \\\\ ab & b^2\\end{pmatrix}$ does not depend on $c,d$. \nTherefore $(B^T A B)^\\star=B^{-1}A^\\star (B^T)^{-1}$ should be independent of $c,d$ as well.\nLet $A^\\star =\\begin{pmatrix} x & y\\\\ z & w\\end{pmatrix}$ for some $x,y,z,w\\in\\mathbb R$.\nThen we compute $$B^{-1}A^\\star (B^T)^{-1}=\\frac 1 {(\\operatorname{det} B)^2}\\begin{pmatrix} x d^2 - (y+z) cd + w c^2 & -x bd +(yad + zbc) -wac\\\\ -x bd +(ybc + zad) -wac & x b^2 - (y+z) ab + w a^2 \\end{pmatrix}$$. \nIn case $B=\\begin{pmatrix} 1 & 0\\\\ t & 1\\end{pmatrix}$ we get that $B^{-1}A^\\star (B^T)^{-1}=\\begin{pmatrix} x - (y+z)t + w t^2& \\dots\\\\ \\dots & \\dots\\end{pmatrix}$ is independent of $t$. So $y+z=0$ and $w=0$.\nNow, in case $B=\\begin{pmatrix} 0 & -1\\\\ 1 & t\\end{pmatrix}$ we get $B^{-1}A^\\star (B^T)^{-1}=\\begin{pmatrix} x t^2 + 0 & \\dots\\\\ \\dots & \\dots\\end{pmatrix}$ from which $x=0$.\nThis is already a contradiction, because $A^\\star=\\begin{pmatrix} 0 & y \\\\ -y & 0\\end{pmatrix}$ has either rank 0 or 2. But in case $B=\\begin{pmatrix} 1 & 0\\\\ 0 & t\\end{pmatrix}$ we get that $B^{-1}A^\\star (B^T)^{-1}=\\frac 1 {t^2}\\begin{pmatrix} 0 & yt  \\\\ -yt & 0\\end{pmatrix}$ is independent of $t$, so $y=0$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/270049", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "5", "answer_count": 1, "answer_id": 0}}
{"Q": "Matrix rescaling increases lowest eigenvalue? Consider the set $\\mathbf{N}:=\\left\\{1,2,....,N \\right\\}$ and let $$\\mathbf M:=\\left\\{ M_i; M_i \\subset \\mathbf N \\text{ such that } \\left\\lvert M_i \\right\\rvert=2 \\text{ or }\\left\\lvert M_i \\right\\rvert=1 \\right\\}$$\nbe the set of all subsets of $\\mathbf{N}$ that are of cardinality $1$ or $2.$\nThe cardinality of the set $\\mathbf M$ itself is $\\binom{n}{1}+\\binom{n}{2}=:K$\nWe can then study for $y \\in (0,1)$ the $K \\times K$ matrix\n$$A_N = \\left(  \\frac{\\left\\lvert M_i \\cap M_j \\right\\rvert}{\\left\\lvert M_i \\right\\rvert\\left\\lvert M_j \\right\\rvert}y^{-\\left\\lvert M_i \\cap M_j \\right\\rvert} \\right)_{i,j}$$\nand \n$$B_N = \\left(  \\left\\lvert M_i \\cap M_j \\right\\rvert y^{-\\left\\lvert M_i \\cap M_j \\right\\rvert} \\right)_{i,j}.$$\nQuestion\nI conjecture that $\\lambda_{\\text{min}}(A_N)\\le \\lambda_{\\text{min}}(B_N)$ for any $N$ and would like to know if one can actually show this?\nAs a first step, I would like to know if one can show that $$\\lambda_{\\text{min}}(A_N)\\le C\\lambda_{\\text{min}}(B_N)$$ for some $C$ independent of $N$?\nIn fact, I am not claiming that $A_N \\le B_N$ in the sense of matrices. But it seems as if the eigenvalues of $B_N$ are shifted up when compared with $A_N.$\nNumerical evidence:\nFor $N=2$ we can explicitly write down the matrices \n$$A_2 =\\left(\n\\begin{array}{ccc}\n \\frac{1}{y} & 0 & \\frac{1}{2 y} \\\\\n 0 & \\frac{1}{y} & \\frac{1}{2 y} \\\\\n \\frac{1}{2 y} & \\frac{1}{2 y} & \\frac{1}{2 y^2} \\\\\n\\end{array}\n\\right) \\text{ and }B_2 = \\left(\n\\begin{array}{ccc}\n \\frac{1}{y} & 0 & \\frac{1}{y} \\\\\n 0 & \\frac{1}{y} & \\frac{1}{y} \\\\\n \\frac{1}{y} & \\frac{1}{y} & \\frac{2}{y^2} \\\\\n\\end{array}\n\\right)$$\nWe obtain for the lowest eigenvalue of $A_2$ (orange) and $B_2$(blue) as a function of $y$\n\nFor $N=3$ we get qualitatively the same picture, i.e. the lowest eigenvalue of $A_3$ remains below the lowest one of $B_3$:\nIn this case: \n$$A_3=\\left(\n\\begin{array}{cccccc}\n \\frac{1}{y} & 0 & 0 & \\frac{1}{2 y} & 0 & \\frac{1}{2 y} \\\\\n 0 & \\frac{1}{y} & 0 & \\frac{1}{2 y} & \\frac{1}{2 y} & 0 \\\\\n 0 & 0 & \\frac{1}{y} & 0 & \\frac{1}{2 y} & \\frac{1}{2 y} \\\\\n \\frac{1}{2 y} & \\frac{1}{2 y} & 0 & \\frac{1}{2 y^2} & \\frac{1}{4 y} & \\frac{1}{4 y} \\\\\n 0 & \\frac{1}{2 y} & \\frac{1}{2 y} & \\frac{1}{4 y} & \\frac{1}{2 y^2} & \\frac{1}{4 y} \\\\\n \\frac{1}{2 y} & 0 & \\frac{1}{2 y} & \\frac{1}{4 y} & \\frac{1}{4 y} & \\frac{1}{2 y^2} \\\\\n\\end{array}\n\\right)\\text{ and } B_3=\\left(\n\\begin{array}{cccccc}\n \\frac{1}{y} & 0 & 0 & \\frac{1}{y} & 0 & \\frac{1}{y} \\\\\n 0 & \\frac{1}{y} & 0 & \\frac{1}{y} & \\frac{1}{y} & 0 \\\\\n 0 & 0 & \\frac{1}{y} & 0 & \\frac{1}{y} & \\frac{1}{y} \\\\\n \\frac{1}{y} & \\frac{1}{y} & 0 & \\frac{2}{y^2} & \\frac{1}{y} & \\frac{1}{y} \\\\\n 0 & \\frac{1}{y} & \\frac{1}{y} & \\frac{1}{y} & \\frac{2}{y^2} & \\frac{1}{y} \\\\\n \\frac{1}{y} & 0 & \\frac{1}{y} & \\frac{1}{y} & \\frac{1}{y} & \\frac{2}{y^2} \\\\\n\\end{array}\n\\right)$$\n\n", "A": "The matrices are of the form\n$$\nA=\\begin{pmatrix} 1 & C \\\\ C^* & D \\end{pmatrix}, \\quad\\quad\nB= \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} A \\begin{pmatrix} 1 & 0\\\\ 0&2\\end{pmatrix} ,\n$$\nwith the blocks corresponding to the sizes of the sets $M_j$ involved.\nLet $v=(x,y)^t$ be a normalized eigenvector for the minimum eigenvalue $\\lambda $ of $B$. Then\n$$\n(x,2y)A\\begin{pmatrix} x \\\\ 2y \\end{pmatrix} = \\lambda\n$$\nalso, but this modified vector has larger norm.\nSo the desired inequality $\\lambda_j(A)\\le\\lambda_j(B)$ (for all eigenvalues, not just the first one) will follow if we can show that $B\\ge 0$. This is true for $y=1$ because in this case we can interpret\n$$\n|M_j\\cap M_k|=\\sum_n \\chi_j(n)\\chi_k(n)\n$$\nas the scalar product in $\\ell^2$ of the characteristic functions, and this makes\n$v^*Bv$ equal to $\\|f\\|_2^2\\ge 0$, with $f=\\sum v_j\\chi_j$.\nFor general $y>0$, we have $B(y)=(1/y)B(1) + D$, for a diagonal matrix $D$ with non-negative entries.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/313470", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "8", "answer_count": 2, "answer_id": 0}}
{"Q": "How can I simplify this sum any further? Recently I was playing around with some numbers and I stumbled across the following formal power series:\n$$\\sum_{k=0}^\\infty\\frac{x^{ak}}{(ak)!}\\biggl(\\sum_{l=0}^k\\binom{ak}{al}\\biggr)$$\nI was able to \"simplify\" the above expression for $a=1$:\n$$\\sum_{k=0}^\\infty\\frac{x^k}{k!}\\cdot2^k=e^{2x}$$\nI also managed to simplify the expression for $a=2$ with the identity $\\sum_{i=0}^\\infty\\frac{x^{2k}}{(2k)!}=\\cosh(x)$:\n$$\\sum_{k=0}^\\infty\\frac{x^{2k}}{(2k)!}\\biggl(\\sum_{l=0}^k\\binom{2k}{2l}\\biggr)=\\mathbf[\\cdots\\mathbf]=\\frac{1}{4}\\cdot(e^{2x}+e^{-2x})+\\frac{1}{2}=\\frac{1}{2}\\cdot(\\cosh(2x)+1)$$\nHowever, I couldn't come up with a general method for all $a\\in\\Bbb{N}$. I would be very thankful if someone could either guide me towards simplifying this expression or post his solution here. \n", "A": "You might be able to use the fact that\n$$\\sum_{k=0}^\\infty b_{ak}=\\sum_{k=0}^\\infty \\left(\\frac{1}{a}\\sum_{j=0}^{a-1} \\exp\\left(2\\pi ijk/a\\right)\\right)b_k.$$\nFor example, when $a=1$, taking $b_k = \\frac{x^k}{k!}\\sum_{\\ell \\ge 0} \\binom{k}{\\ell}$ yields\n$$\\sum_{k=0}^\\infty b_{k}=\\sum_{k=0}^\\infty \\frac{x^k}{k!}\\sum_{\\ell \\ge 0} \\binom{k}{\\ell}=\\sum_{k=0}^\\infty \\frac{x^k}{k!}2^k=\\exp(2x),$$\nas you already obtained.\nFor $a=2$, first note that\n\\begin{align}\n\\sum_{\\ell \\ge 0}\\binom{k}{2 \\ell} &= \\sum_{\\ell\\ge 0} \\left(\\frac{1}{2}\\sum_{j=0}^1 \\exp\\left(2\\pi ij\\ell/2\\right)\\right)\\binom{k}{\\ell}\\\\\n&= \\sum_{\\ell\\ge 0} \\frac{1+(-1)^\\ell}{2}\\binom{k}{\\ell}\\\\\n&= \\frac{1}{2}\\sum_{\\ell\\ge 0} \\binom{k}{\\ell}+ \\frac{1}{2}\\sum_{\\ell\\ge 0} (-1)^\\ell\\binom{k}{\\ell}\\\\\n&= \\frac{2^k+0^k}{2}.\n\\end{align}\nNow taking $b_k = \\frac{x^k}{k!}\\sum_{\\ell \\ge 0}\\binom{k}{2 \\ell}$ yields\n\\begin{align}\\sum_{k=0}^\\infty b_{2k}&=\\sum_{k=0}^\\infty \\left( \\frac{1}{2}\\sum_{j=0}^1 \\exp\\left(\\pi ijk\\right)\\right)\\frac{x^k}{k!}\\sum_{\\ell \\ge 0}\\binom{k}{2 \\ell}\\\\\n&=\\frac{1}{2}\\sum_{k=0}^\\infty \\left(1+(-1)^k\\right)\\frac{x^k}{k!}\\left(2^{k-1}+\\frac{1}{2}[k=0]\\right)\\\\\n&=\\frac{1}{4}\\sum_{k=0}^\\infty \\frac{x^k}{k!}2^k+\\frac{1}{4}\\sum_{k=0}^\\infty (-1)^k\\frac{x^k}{k!}2^k+\\frac{1}{2}\\\\\n&=\\frac{\\exp(2x)+\\exp(-2x)}{4} +\\frac{1}{2}\\\\\n&=\\cosh^2(x),\n\\end{align}\nagain matching your result.\nFor $a=3$, first note that\n\\begin{align}\n\\sum_{\\ell \\ge 0}\\binom{k}{3 \\ell} &= \\sum_{\\ell\\ge 0} \\left(\\frac{1}{3}\\sum_{j=0}^2 \\exp\\left(2\\pi ij\\ell/3\\right)\\right)\\binom{k}{\\ell}\\\\\n&= \\sum_{\\ell\\ge 0} \\frac{1+\\exp(2\\pi i\\ell/3)+\\exp(4\\pi i\\ell/3)}{3}\\binom{k}{\\ell}\\\\\n&= \\frac{1}{3}\\sum_{\\ell\\ge 0} \\binom{k}{\\ell}+ \\frac{1}{3}\\sum_{\\ell\\ge 0} \\exp(2\\pi i/3)^\\ell\\binom{k}{\\ell}+ \\frac{1}{3}\\sum_{\\ell\\ge 0} \\exp(4\\pi i/3)^\\ell\\binom{k}{\\ell}\\\\\n&= \\frac{2^k+(1+\\exp(2\\pi i/3))^k+(1+\\exp(4\\pi i/3))^k}{3}\\\\\n&= \\frac{2^k+\\exp(\\pi i/3)^k+\\exp(-\\pi i/3)^k}{3}.\n\\end{align}\nNow taking $b_k = \\frac{x^k}{k!}\\sum_{\\ell \\ge 0}\\binom{k}{3 \\ell}$ yields\n\\begin{align}\\sum_{k=0}^\\infty b_{3k}&=\\sum_{k=0}^\\infty \\left( \\frac{1}{3}\\sum_{j=0}^2 \\exp\\left(2\\pi ijk/3\\right)\\right)\\frac{x^k}{k!}\\sum_{\\ell \\ge 0}\\binom{k}{3 \\ell}\\\\\n&=\\frac{1}{3}\\sum_{k=0}^\\infty \\left(1+\\exp(2\\pi ik/3)+\\exp(4\\pi ik/3)\\right)\\frac{x^k}{k!}\\frac{2^k+\\exp(\\pi i/3)^k+\\exp(-\\pi i/3)^k}{3}\\\\\n&=\\frac{1}{9}\\sum_{k=0}^\\infty (1+\\exp(2\\pi i/3)^k+\\exp(4\\pi i/3)^k)(2^k+\\exp(\\pi i/3)^k+\\exp(-\\pi i/3)^k)\\frac{x^k}{k!}.\n\\end{align}\nNow expand the product of trinomials to obtain 9 sums that reduce to $\\exp(cx)$ for various constants $c$.\nAlternatively, note that:\n$$\\sum_{k=0}^\\infty \\frac{x^{ak}}{(ak)!}\\sum_{\\ell \\ge 0}\\binom{ak}{a\\ell} = \\left(\\sum_{k=0}^\\infty \\frac{x^{ak}}{(ak)!}\\right)^2,$$\nso you might as well just compute\n\\begin{align}\n\\sum_{k=0}^\\infty \\frac{x^{ak}}{(ak)!}\n&= \\sum_{k=0}^\\infty \\left( \\frac{1}{a}\\sum_{j=0}^{a-1} \\exp\\left(2\\pi ijk/a\\right)\\right)\\frac{x^k}{k!} \\\\\n&= \\frac{1}{a}\\sum_{j=0}^{a-1} \\sum_{k=0}^\\infty \\frac{(\\exp(2\\pi ij/a)x)^k}{k!} \\\\\n&= \\frac{1}{a}\\sum_{j=0}^{a-1} \\exp(\\exp(2\\pi ij/a)x),\n\\end{align}\nand then square the result.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/346198", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "11", "answer_count": 3, "answer_id": 2}}
{"Q": "Can an even perfect number be a sum of two cubes? A similar question was asked before in https://math.stackexchange.com/questions/2727090/even-perfect-number-that-is-also-a-sum-of-two-cubes, but no conclusions were drawn.\nOn the Wikipedia article of perfect numbers there are two related results concerning whether an even perfect number can be a sum of two cubes. Gallardo's result in 2010 (which can be found here) claims that 28 is the only perfect number that can be a sum of two cubes. This part is copied from the question on MSE, which is summarized from the paper:\n\nLet $N$ be an even perfect number. Assume that $N=x^3+a^3=(x+a)(x^2-xa+a^2)$. Note that $x$ and $a$ have the same parity. Consider the case $x+a<x^2-xa+a^2$. By the Euclid\u2013Euler theorem, it follows that $N=2^{p-1}(2^p-1)$, where $2^p-1$ is a Mersenne prime. Thus, $x+a=2^{p-1}$ and $x^2-xa+a^2=2^p-1$.\n\nHowever, nowhere in the proof was it proven that both $x,a$ are odd, or that $x+a$ and $x^2-xa+a^2$ are coprime. If $x,a$ are even, the second equation cannot hold. So, is this result true? If the subsequent analysis is correct, this still shows that a perfect number cannot be expressed as two odd cubes. Or are there similar results concerning whether a perfect number can be expressed as a sum of two perfect powers?\nRemark: the title of this paper is On a remark of Makowski about perfect numbers. The remark of Makowski, also referenced in the Wikipedia article, concerns the case $a=1$, so $x$ is also odd, and there is no issue of non-comprimality. For those interested, Makowski deduced that $x+1=2^{p-1}$ and $x^2-x+1 = 2^p-1$ from the fact that the latter factor must be odd. From these equations, $x=3$ follows immediately, hence $28$ is the only perfect number that is one more than a cube. @Mindlack's answer here generalizes the result to $N = x^m + 1$. Both proofs are elementary.\n", "A": "Here is a proof that 28 is the only even perfect number that is the sum of two positive cubes. The proof in Gallardo's article must be adapted in the case $x,a$ are even.\nWrite $N=2^{p-1}(2^p-1) = x^3+y^3 = (x+y)(x^2-xy+y^2)$. The gcd $d$ of $x$ and $y$ must be a power of 2, because $d^3$ divides $N$. Writing $x=2^h u$, $y=2^h v$ gives $2^{p-1-3h}(2^p-1) = u^3+v^3$. We are going to show that the only solution of the equation $2^k(2^p-1) = u^3+v^3$ with $k<p$ and $(u,v)=1$ has no solution for $p \\geq 5$. First we must have $k \\geq 1$ because $2^p-1$ is prime, and $u,v$ must be odd. Moreover $u+v=2^k$ and $u^2-uv+v^2=2^p-1$. Then\n\\begin{equation*}\n2^p-1=u^2-uv+v^2=u^2-u(2^k-u)+(2^k-u)^2 = 2^{2k}-3uv.\n\\end{equation*}\nWe deduce the bounds $p \\leq 2k$ and\n\\begin{equation*}\n2^p-1 \\geq 2^{2k}-3 \\cdot (2^{k-1})^2 \\geq 2^{2k-2},\n\\end{equation*}\nwhich implies $p \\geq 2k-2$. Putting these bounds together, we get $p=2k-1$. So $u,v$ are solutions to the system of equations\n\\begin{equation*}\n\\begin{cases} & u+v = 2^k \\\\ & uv = (2^{2k-1}+1)/3\n\\end{cases}\n\\end{equation*}\nThe discriminant $\\Delta$ of the polynomial $(X-u)(X-v)$ must be a perfect square. We have $\\Delta=4 \\cdot (2^{2k-2}-1)/3$, hence $2^{2k-2}-1$ is 3 times an odd square. In particular $2^{2k-2} - 1 \\equiv 3 \\bmod{8}$, which is possible only for $k=2$ and $p=3$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/375879", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 1, "answer_id": 0}}
{"Q": "A special congruence For any $a, b\\in\\mathbb{N}$ with $a+2b\\not\\equiv 0\\pmod 3$, we define $\\delta(a, b)$ as follows:\n\\begin{align*}\n\\delta(a, b)={\\left\\{\\begin{array}{rl}\n1,\\ \\ \\ \\ &{\\rm if} \\ a+2b\\equiv 1\\pmod 3,\\\\\n0,\\ \\ \\ \\ &{\\rm if} \\ a+2b\\equiv 2\\pmod 3.\n\\end{array}\\right.}\n\\end{align*}\nFurthermore, for any $m, n\\in\\mathbb{N}$, we let\n$$s(m, n)=\\sum\\limits_{a=0}^m\\sum\\limits_{b=0\\atop a+2b\\not\\equiv 0\\pmod 3}^n\n(-1)^{m+n-a-b}2^{\\delta(a, b)}\\binom{m}{a}\\binom{n}{b}.$$\nI want to know how to prove that $s(m, n)\\equiv 0\\mod 3^k$, where $k=[(m+n)/2]$.\n", "A": "We can rewrite the sum as\n$$\\sum_{a=0}^{m} (-1)^a \\binom{m}{a}\\sum_{\\substack{b=0 \\\\ 3 \\nmid a+2b}} (-1)^b 2^{\\delta(a,b)} \\binom{n}{b}$$\n\n*\n\n*Now, when, $a=3k+1$, then we have $b=3k$ or $3k-1$.\n\nThen for, $b=3k$, $\\delta(a,b)=1$ and for $b=3k-1$ and $\\delta(a,b)=0$.\n\n\n*Similarly, when $a=3k-1$, $b=3k, \\delta(a,b)=0$ and $b=3k+1 ,\\delta(a,b)=1$\n\n\n*When, $a=3k$, $b=3k+1 ,\\delta(a,b)=0$ and $b=3k-1 ,\\delta(a,b)=1$\n[$\\omega$ is the cube root of unity]\nThen, $$\\sum_{\\substack{b=0 \\\\b=3k}}^{n} (-1)^b \\binom{n}{b}=\\frac{1}{3}[(1-\\omega)^n+(1-\\omega^2)^n]=A_n$$\nSimilarly, $$\\sum_{\\substack{b=0 \\\\b=3k-1}}^{n} (-1)^b \\binom{n}{b}=\\frac{1}{3}[\\omega(1-\\omega)^n+\\omega^2(1-\\omega^2)^n]=C_n$$\nAnd, $$\\sum_{\\substack{b=0 \\\\b=3k+1}}^{n} (-1)^b \\binom{n}{b}=\\frac{1}{3}[\\omega^2(1-\\omega)^n+\\omega(1-\\omega^2)^n]=B_n$$\nThen, $$\\sum_{a=0}^{m} (-1)^a \\binom{m}{a}\\sum_{\\substack{b=0 \\\\ 3 \\nmid a+2b}}^{n} (-1)^b 2^{\\delta(a,b)} \\binom{n}{b} =2(A_nB_m+B_nC_m+C_nA_m)+(A_mB_n+B_mC_n+C_mA_n)$$\n$=-[(1-\\omega)^{m+1}(1-\\omega^2)^n+(1-\\omega^2)^{m+1}(1-\\omega)^n$.\n$=-(1-\\omega)^{m+n}[(1+\\omega)^{m+1}+(1+\\omega)^n]$\nFrom Wolfram Alpha we get\n$-(1-\\omega)^{m+n}[(1+\\omega)^{m+1}+(1+\\omega)^n] \\\\ =-2.3^{\\frac{m+n+1}{2}}[\\cos(\\frac{\\pi (m+1-n)}{6})]$\nThis is divisible by $3^{\\lfloor \\frac{m+n}{2} \\rfloor}$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/380193", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "Is there a nonzero solution to this infinite system of congruences? Is there a triple of nonzero even integers $(a,b,c)$ that satisfies the following infinite system of congruences?\n$$\na+b+c\\equiv 0 \\pmod{4} \\\\\na+3b+3c\\equiv 0 \\pmod{8} \\\\\n3a+5b+9c\\equiv 0 \\pmod{16} \\\\\n9a+15b+19c\\equiv 0 \\pmod{32} \\\\\n\\vdots \\\\\ns_na + t_nb + s_{n+1}c \\equiv 0 \\pmod{2^{n+1}} \\\\\n\\vdots\n$$\nwhere $(s_n)$ and $(t_n)$ are weighted tribonacci sequences defined by\n$$\ns_1=s_2=1, \\\\\ns_3=3, \\\\\ns_n = s_{n-1} +2s_{n-2} + 4s_{n-3} \\text{ for } n>3,\n$$\nand\n$$\nt_1=1, \\\\\nt_2=3, \\\\\nt_3=5, \\\\\nt_n = t_{n-1} +2t_{n-2} + 4t_{n-3} \\text{ for } n>3.\n$$\nI think there are no nonzero solutions, but I haven't been able to prove this. Computationally, I found there are no nonzero solutions for integers $a$, $b$, and $c$ up to $1000$.\nNote the $s_n$ and $t_n$ are always odd, and that the ratios $\\frac{s_n}{s_{n-1}}$ and $\\frac{t_n}{t_{n-1}}$ approach $2.4675...$.\n", "A": "Let $u_n = a s_n + b t_n + c s_{n+1}$. The stronger claim is true: for large enough values of $n$,\nthe number $u_n$ will be exactly divisible\nby a fixed power of $2$ that doesn't depend on $n$.\nLet $u_n = a s_n + b t_n + c s_{n+1}$ then (by induction)\n$$u_{n} = u_{n-1} + 2 u_{n-2} + 4 u_{n-3}.$$\nThe polynomial $x^3 - x^2 - 2 x - 4$  is irreducible and has three roots $\\alpha_1$, $\\alpha_2$, and $\\alpha_3$ in $\\overline{\\mathbf{Q}}$.\nBy the general theory of recurrence relations,\n$$u_n = A_1 \\alpha^n_1 + A_2 \\alpha^n_2 + A_3 \\alpha^n_3$$\nfor constants $A_1$, $A_2$, $A_3$. Since $u_n \\in \\mathbf{Q}$, we may additionally deduce that $A_i$ lie in $\\mathbf{Q}(\\alpha_1,\\alpha_2,\\alpha_3)$.\nThat is because we can solve for $A_i$ using the equation\n$$\\left( \\begin{matrix} \\alpha_1 & \\alpha_2 & \\alpha_3 \\\\ \\alpha^2_1 & \\alpha^2_2 & \\alpha^2_3 \\\\ \\alpha^3_1 & \\alpha^3_2 & \\alpha^3_3 \\end{matrix} \\right)\n\\left( \\begin{matrix} A_1 \\\\ A_2 \\\\ A_3 \\end{matrix} \\right) = \\left( \\begin{matrix} u_1 \\\\ u_2 \\\\ u_3 \\end{matrix} \\right)$$\nand the matrix on the left is invertible (Vandermonde). In fact we deduce the stronger claim that\nany Galois automorphism sending $\\alpha_i$ to $\\alpha_j$ sends $A_i$ to $A_j$.\n(Simply consider the action of the Galois group on both sides of this equation,\nnoting that the $A_i$ are determined uniquely from this equation.) In particular, if one of the $A_i = 0$,\nthen all of the $A_i = 0$.\nBut now fix an embedding of $\\overline{\\mathbf{Q}}$ into $\\overline{\\mathbf{Q}}_2$. From the Newton Polygon,\nwe see that there is one root (call it $\\alpha_1$) of valuation $0$, and the other two roots have valuation $1$. Hence\n$$\\|A_1 \\alpha^n_1 \\|_2 = \\|A_1\\|_2,  \\quad \\|A_2 \\alpha^n_2 \\|_2 = \\|A_2\\|_2 \\cdot 2^{-n},  \\quad  \\|A_3 \\alpha^n_3 \\|_2 = \\|A_3\\|_2  \\cdot 2^{-n}.$$\nIn particular,  if $A_1 \\ne 0$, then (by the ultrametric inequality) $\\| u_n \\|_2 = \\|A_1\\|$ for $n$ large enough. Hence we deduce that either the $2$-adic valuation\nof $u_n$ is eventually  constant (as claimed) or that $A_1 = 0$ and so $A_i = 0$ for all $i$, which implies that $u_n = 0$ for all $n$. But  if $u_1 = u_2 = u_3 = 0$,\nthen\n$$\\left( \\begin{matrix} 1 &1 & 1 \\\\ 1 &3 & 3 \\\\ 3 & 5 & 9 \\end{matrix} \\right)\n\\left( \\begin{matrix} a \\\\ b \\\\ c \\end{matrix} \\right) = \\left( \\begin{matrix} 0 \\\\ 0 \\\\ 0 \\end{matrix} \\right)$$\nThe matrix on the left is invertible which implies that $a=b=c=0$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/381057", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "7", "answer_count": 2, "answer_id": 0}}
{"Q": "Why $\\lim_{n\\rightarrow \\infty}\\frac{F(n,n)}{F(n-1,n-1)} =\\frac{9}{8}$? $$F(m,n)= \\begin{cases}\n1, & \\text{if $m n=0$ }; \\\\\n \\frac{1}{2} F(m ,n-1) + \\frac{1}{3} F(m-1,n )+ \\frac{1}{4} F(m-1,n-1), & \\text{ if $m n>0$. }%\n\\end{cases}$$\nPlease a proof of:\n$$\\lim_{n\\rightarrow \\infty}\\frac{F(n,n)}{F(n-1,n-1)} =\\lim_{n\\rightarrow \\infty}\\frac{F(n,n-1)}{F(n-1,n-1)}=\\frac{9}{8}$$\n$$\\lim_{n\\rightarrow \\infty}\\frac{F(n-1,n)}{F(n-1,n-1)}=1$$\n", "A": "We will compute the generating function, and use the method described in section 2 of this paper.\nLet $F_{m,n}=F(m,n)$. Consider the generating function\n$$G(x,y)=\\sum_{m=0}^\\infty\\sum_{n=0}^\\infty F_{m,n}x^my^n.$$\nThen the recurrence gives\n\\begin{align*}\n&G(x,y)=\\sum_{m=0}^\\infty F_{m,0}x^m+\\sum_{n=1}^\\infty F_{0,n}y^n+\\sum_{m=1}^\\infty\\sum_{n=1}^\\infty F_{m,n}x^my^n\\\\\n&=\\frac{1}{1-x}+\\frac{y}{1-y}+\\sum_{m=1}^\\infty\\sum_{n=1}^\\infty\\left(\\frac{1}{2}F_{m,n-1}+\\frac{1}{3}F_{m-1,n}+\\frac{1}{4}F_{m-1,n-1}\\right)x^my^n\\\\\n&=\\frac{1-xy}{(1-x)(1-y)}+\\frac{y}{2}\\sum_{m=1}^\\infty\\sum_{n=0}^\\infty F_{m,n}x^my^n+\\frac{x}{3}\\sum_{m=0}^\\infty\\sum_{n=1}^\\infty F_{m,n}x^my^n+\\frac{xy}{4}G(x,y)\\\\\n&=\\frac{1-xy}{(1-x)(1-y)}+\\frac{y}{2}\\left(G(x,y)-\\frac{1}{1-y}\\right)+\\frac{x}{3}\\left(G(x,y)-\\frac{1}{1-x}\\right)+\\frac{xy}{4}G(x,y)\\\\\n&=\\frac{1-xy-\\frac{y}{2}(1-x)-\\frac{x}{3}(1-y)}{(1-x)(1-y)}+\\left(\\frac{x}{3}+\\frac{y}{2}+\\frac{xy}{4}\\right)G(x,y)\\\\\n&=\\frac{1-\\frac{x}{3}-\\frac{y}{2}-\\frac{xy}{6}}{(1-x)(1-y)}+\\left(\\frac{x}{3}+\\frac{y}{2}+\\frac{xy}{4}\\right)G(x,y).\n\\end{align*}\nSolving for $G(x,y)$ gives\n$$G(x,y)=\\frac{1-\\frac{x}{3}-\\frac{y}{2}-\\frac{xy}{6}}{(1-x)(1-y)\\left(1-\\frac{x}{3}-\\frac{y}{2}-\\frac{xy}{4}\\right)}.$$\nLet $R(x,y)$ denote this rational function.\nWe have shown that $G(x,y)$ converges to $R(x,y)$ in some neighborhood of the origin.\nThen for fixed small $x$, the Laurent series $G(x/y,y)$ will converge to $R(x/y,y)$ in some annulus around $y=0$.\nFurthermore, $H(x)=\\sum_{m=0}^\\infty F_{m,m}x^m$ is the constant term of $G(x/y,y)$, and can be found via residue calculus as\n\\begin{align*}\nH(x)&=\\frac{1}{2\\pi i}\\int_\\gamma\\frac{1}{y}G(x/y,y)\\,dy\\\\\n&=\\frac{1}{2\\pi i}\\int_\\gamma\\frac{1}{y}R(x/y,y)\\,dy\\\\\n&=\\sum_k\\mathrm{Res}\\left[\\frac{1}{y}R(x/y,y),y=z_k\\right]\n\\end{align*}\nwhere $\\gamma$ is a counterclockwise contour in the annulus, and where $z_k$ are the singularities of $R(x/y,y)$ lying inside of $\\gamma$.\nWe can compute\n\\begin{align*}\n\\frac{1}{y}R(x/y,y)&=\\frac{y-\\frac{x}{3}-\\frac{y^2}{2}-\\frac{xy}{6}}{(y-x)(1-y)\\left(y-\\frac{x}{3}-\\frac{y^2}{2}-\\frac{xy}{4}\\right)}.\n\\end{align*}\nThis rational function has poles at the following points:\n\n*\n\n*$y=1$. This pole does not lie inside of $\\gamma$.\n\n\n*$y=x$. This pole lies inside of $\\gamma$, and has residue $\\frac{8}{8-9x}$.\n\n\n*$y=(1-\\frac{x}{4})+\\sqrt{(\\frac{x}{4}-1)^2-\\frac{2}{3}x}$. This pole does not lie inside of $\\gamma$.\n\n\n*$y=(1-\\frac{x}{4})-\\sqrt{(\\frac{x}{4}-1)^2-\\frac{2}{3}x}$. This pole lies inside of $\\gamma$, and has residue\n$$\\frac{\\frac{x}{12}\\left((1-\\frac{x}{4})-\\sqrt{(\\frac{x}{4}-1)^2-\\frac{2}{3}x}\\right)}{\\left((1-\\frac{5x}{4})-\\sqrt{(\\frac{x}{4}-1)^2-\\frac{2}{3}x}\\right)\\left(\\frac{x}{4}+\\sqrt{(\\frac{x}{4}-1)^2-\\frac{2}{3}x}\\right)\\left(\\sqrt{(\\frac{x}{4}-1)^2-\\frac{2}{3}x}\\right)}$$\nwhich Wolfram Alpha can simplify to\n$$\\frac{x\\left(13\\sqrt3\\,x-12\\sqrt3+\\sqrt{3x^2-56x+48}\\right)}{(7x-6)(9x-8)\\sqrt{3x^2-56x+48}}.$$\nPutting this all together gives\n$$H(x)=\\frac{8}{8-9x}+\\frac{x\\left(13\\sqrt3\\,x-12\\sqrt3+\\sqrt{3x^2-56x+48}\\right)}{(7x-6)(9x-8)\\sqrt{3x^2-56x+48}}.$$\nThe second summand is actually holomorphic at $x=6/7$ and $x=8/9$.\nThen the singularity of $H(x)$ closest to the origin is $x=8/9$, and we obtain the asymptotic\n$$F_{m,m}\\sim\\left(\\frac{9}{8}\\right)^m$$\nwhich proves the first limit.\nThe remaining limits can be solved in a similar way, by first determining the asymptotics of $F(m,m-1)$ and $F(m-1,m)$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/390924", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "Improper integral $\\int_0^\\infty\\frac{x^{2n+1}}{(1+x^2)^2(2+x^2)^N}dx,\\ \\ \\ n\\le N$ How can I evaluate this integral?\n$$\\int_0^\\infty\\frac{x^{2n+1}}{(1+x^2)^2(2+x^2)^N}dx,\\ \\ \\ n\\le N$$\nMaybe there is a recurrence relation for the integral?\n", "A": "One approach is to consider the sum\n$$ J = \\sum_{n,m=0}^\\infty s^nt^mI_{n,n+m} = \\int_{x=0}^\\infty F\\,dx, $$\nwhere\n$$ F = \\sum_{n,m=0}^\\infty s^nt^m \\frac{x^{2n+1}}{(1+x^2)^2(2+x^2)^{n+m}} = \n \\frac{x(2+x^2)^2}{(1+x^2)^2(2+x^2-sx^2)(2+x^2-t)}\n$$\nThis works out as\n$$\n J = \\frac{2s^2\\ln(1-s)}{(1+s)^2(st-2s-t)} + \n  \\frac{t^2\\ln(1-t/2)}{2(1-t)^2(st-2s-t)} + \n  \\frac{(2s-t-3st)\\ln(2)}{2(1+s)^2(1-t)^2} + \n  \\frac{1}{2(1+s)(1-t)} \n$$\nIn principle you could expand this as a power series and extract $I_{n,n+m}$ as the coefficient of $s^nt^m$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/393753", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "7", "answer_count": 4, "answer_id": 1}}
{"Q": "General formulas for derivative of $f_n(x)=\\dfrac{ax^n+bx^{n-1}+cx^{n-2}+\\cdots}{a'x^n+b'x^{n-1}+c'x^{n-2}+\\cdots},\\quad a'\\neq0$ For the function $f_1(x)=\\dfrac{ax+b}{a'x+b'},\\quad a'\\neq0$ , we have $$f_1'(x)=\\dfrac{\\begin{vmatrix}{a} && {b} \\\\ {a'} && {b'}\\end{vmatrix}}{(a'x+b')^2}$$\nFor $f_2(x)=\\dfrac{ax^2+bx+c}{a'x^2+b'x+c'},\\quad a'\\neq0$, we have\n$$f_2'(x)=\\dfrac{{ \\begin{vmatrix}{a} && {b} \\\\ {a'} && {b'}\\end{vmatrix} }x^2+2{ \\begin{vmatrix}{a} && {c} \\\\ {a'} && {c'}\\end{vmatrix} }x+{ \\begin{vmatrix}{b} && {c} \\\\ {b'} && {c'}\\end{vmatrix} }}{(a'x^2+b'x+c')^2}$$\nCan we generalize the formula containing determinants to find $f_n'(x)$?\n", "A": "You can easily extend this, but for $n\\geq 3$ you will end up with more than one term per monomial:\nFor two functions $f$, $g$ rewrite the quotient rule using a determinant\n$$\\frac{d}{dx} \\frac{f}{g} = \\frac{\\frac{df}{dx}g-f \\frac{dg}{dx}}{g^2} = \\frac{\\begin{vmatrix} \\frac{df}{dx} & f \\\\ \\frac{dg}{dx} & g \\end{vmatrix}}{g^2}$$\nNow assume that $f(x) := a_nx^n+\\dots + a_0$, $g(x) :=b_n x^n+ \\dots + b_0$ are polyonomials. Then $\\frac{df}{dx}$ and $\\frac{dg}{dx}$ can be calculated explicitly and you can use the multilinearity of the determinant to split it by monomials:\n$$\\frac{d}{dx} \\frac{f}{g} = \\frac{\\begin{vmatrix} \\sum_{k=0}^n a_k k x^{k-1} & \\sum_{j=0}^n a_j x^j \\\\ \\sum_{k=0}^n b_k k x^{k-1} & \\sum_{j=0}^n b_j x^j \\end{vmatrix}}{g^2} = \\frac{\\sum_{k=0}^n \\sum_{j=0}^n k\\begin{vmatrix} a_k   & a_j \\\\  b_k   & b_j  \\end{vmatrix} x^{k+j-1} }{g^2}$$\nNow in the last sum for $k=j$ the determinant vanishes and if $k\\neq j$ the same determinant occurs again with flipped sign if their roles are reversed. So you can only count the cases $j<k$ and get\n$$\\frac{d}{dx} \\frac{f}{g} = \\frac{\\sum_{k=0}^n \\sum_{j=0}^{k-1} (k-j)\\begin{vmatrix} a_k   & a_j \\\\  b_k   & b_j  \\end{vmatrix} x^{k+j-1} }{g^2} $$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/396250", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "5", "answer_count": 2, "answer_id": 0}}
{"Q": "Integrality of a sequence formed by sums Consider the following sequence defined as a sum\n$$a_n=\\sum_{k=0}^{n-1}\\frac{3^{3n-3k-1}\\,(7k+8)\\,(3k+1)!}{2^{2n-2k}\\,k!\\,(2k+3)!}.$$\n\nQUESTION. For $n\\geq1$, is the sequence of rational numbers $a_n$ always integral?\n\n", "A": "Here is another proof, inspired by Tewodros Amdeberhan's. We represent the sum as a constant term in a power series.\nTo represent $(7k+8) \\frac{(3k+1)!}{k!\\,(2k+3)!}$ as a constant term, we need to express it as a linear combination of binomial coefficients. To do this we express $7k+8$ as a linear combination of $(2k+2)(2k+3)$, $k(2k+3)$, and $k(k-1)$ since each of these polynomials yields a binomial coefficient when multiplied by $\\frac{(3k+1)!}{k!\\,(2k+3)!}$. We find that\n$$(7k+8) \\frac{(3k+1)!}{k!\\,(2k+3)!}=\\frac13 \\left[4\\binom{3k+1}{k} -7\\binom{3k+1}{k-2} -2\\binom{3k+1}{k-2}\\right].$$\nUsing $\\binom{n}{j} =\\text{CT}\\, (1+x)^n/x^j$, where CT denotes the constant term in $x$, we have\n$$\n\\begin{aligned}\n(7k+8) \\frac{(3k+1)!}{k!\\,(2k+3)!} &= \\text{CT}\\, \\frac13\\left( 4\\frac{(1+x)^{3k+1}}{x^k}\n   -7\\frac{(1+x)^{3k+1}}{x^{k-1}}-2\\frac{(1+x)^{3k+1}}{x^{k-2}}\\right)\\\\\n   &=\\text{CT}\\,\\frac{(1-2x)(x+4)(1+x)^{3k+1}}{3x^k}.\n \\end{aligned}\n$$\nMultiplying by $3^{3n-3k-1}/2^{2n-2k}$, summing on $k$ from 0 to $n-1$, and simplifying gives\n$$\na_n = 3\\,\\text{CT}\\, \\frac{(1+x)^{3n+1}}{x^{n-1}(1-2x)} -3\\left(\\frac{27}{4}\\right)^n\\!\\text{CT}\\,\\frac{x(1+x)}{1-2x}.\n$$\nThe second constant term is 0, so $a_n = 3\\,[x^{n-1}]\\, (1+x)^{3n+1}/(1-2x)$, which is clearly an integer.\nIn fact this gives the formula\n$$a_n = 3 \\sum_{k=0}^{n-1}2^{n-k-1}\\binom{3n+1}{k}.$$\nTewodros's formula can also be derived in the same way; if we represent his sum as a constant term and simplify we also get\n$3\\,[x^{n-1}]\\, (1+x)^{3n+1}/(1-2x)$.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/398037", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "14", "answer_count": 4, "answer_id": 3}}
{"Q": "How to find the asymptotics of a linear two-dimensional recurrence relation Let $d$ be a positive number.\nThere is a two dimensional recurrence relation as follow:\n$$R(n,m) = R(n-1,m-1) + R(n,m-d)$$\nwhere\n$R(0,m) = 1$ and $R(n,0) = R(n,1) = \\cdots = R(n, d-1) = 1$ for all $n,m>0$.\nHow to analyze the asymptotics of $R(n, kn)$ for fixed $k$?\nIt is easy to see that\n$$R(n, kn) = O\\left( c_{k,d}^{n} \\cdot (n+k+d)^{O(1)} \\right)$$\nIs there a way (or an algorithm) to find $c_{k,d}$ given $k$ and $d$?\nPS: I have calcuated the bivariate generating function of $R(\\cdot, \\cdot)$:\n\\begin{align}\nf(x,y) \n&= \\frac{1 - xy - y^{d} + xy^{d}}{(1 - x)(1 - y)(1 - xy - y^{d})} \\\\\n&= \\frac{1}{(1 - x)(1 - y)} + \\frac{xy^{d}}{(1 - x)(1 - y)(1 - xy - y^{d})} \\\\\n\\end{align}\n", "A": "This is to complement Blanco's answer by showing that\n\\begin{equation*}\n    R(n,kn)=\\exp\\{(C_{k,d}+o(1))\\,n\\} \\tag{0}\\label{0}\n\\end{equation*}\n(as $n\\to\\infty$), where $k\\ge1$ and $d\\ge1$ (are fixed),\n\\begin{equation*}\n    C_{k,d}:=\\frac k{1+y_{k,d}\\,d}\\,\\big(\\ln(1+y_{k,d})+y_{k,d}\\,\\ln(1+1/y_{k,d})\\big),\n\\end{equation*}\n\\begin{equation*}\n    y_{k,d}:=\\max\\Big(x_d,\\frac{k-1}d\\Big), \n\\end{equation*}\nand $x_d$ is the unique positive root of the equation\n\\begin{equation*}\n    x_d(1+x_d)^{d-1}=1. \\tag{0.5}\\label{0.5}\n\\end{equation*}\nIn view of Blanco's answer, it is enough to show that\n\\begin{equation*}\n    B(n):=B(n,kn)=\\exp\\{(C_{k,d}+o(1))\\,n\\}, \\tag{1}\\label{1}\n\\end{equation*}\nwhere\n\\begin{equation*}\n    B(n):=\\max\\{c_{a,b}\\colon (a,b)\\in E_{n,k,d}\\},\n\\end{equation*}\n\\begin{equation*}\n    E_{n,k,d}:=\\{(a,b)\\colon 0\\le a\\le n-1,b\\ge0,bd+a\\le kn-d,\\ a,b \\text{ are integers}\\},\n\\end{equation*}\n\\begin{equation*}\n    c_{a,b}:=\\binom{a+b}b=\\binom{a+b}a. \n\\end{equation*}\nNote that $c_{a,b}$ is increasing in $a$ and in $b$.\nNote also that $c_{a,b}=(a+b)^{O(1)}=n^{O(1)}$ for $(a,b)\\in E_{n,k,d}$ if $a=O(1)$ or $b=O(1)$.\nSo, it remains to consider the case when $a\\to\\infty$ and $b\\to\\infty$. Then, by Stirling's formula,\n\\begin{equation*}\n\\begin{aligned}\n    \\ln c_{a,b}\\sim a\\ln(1+b/a)+b\\ln(1+a/b). \n\\end{aligned}\n\\tag{2}\\label{2}\n\\end{equation*}\nAlso,\n\\begin{equation*}\n\\begin{aligned}\n    \\frac{c_{a+d,b-1}}{c_{a,b}}&=b\\frac{(a+d+1)\\cdots(a+d+b-1)}{(a+1)\\cdots(a+b)} \\\\ \n    &= b\\frac{(a+b+1)\\cdots(a+b+d-1)}{(a+1)\\cdots(a+d)} \\\\ \n    &\\sim b\\frac{(a+b)^{d-1}}{a^d} =\\frac ba\\Big(1+\\frac ba\\Big)^{d-1}. \n\\end{aligned}\n\\end{equation*}\nSo, for a fixed value of $bd+a$, the maximum of $c_{a,b}$ occurs when $b/a\\to x_d$ (recall \\eqref{0.5}).\nLet now $(a,b)\\in E_{n,k,d}$ be a maximizer of $c_{a,b}$ (such that $a\\to\\infty$ and $b\\to\\infty$). Then, since $c_{a,b}$ is increasing in $a$ and in $b$, we have\n\\begin{equation*}\n    bd+a\\sim kn. \n\\end{equation*}\nThe conditions $b/a\\to x_d$ and $bd+a\\sim kn$ imply\n\\begin{equation*}\na\\sim k\\frac1{1+x_d\\,d}\\,n, \\tag{3}\\label{3}\n\\end{equation*}\nand the latter condition is compatible with condition $a\\le n-1$ only if\n\\begin{equation*}\n    k\\frac1{1+x_d\\,d}\\le1. \\tag{4}\\label{4} \n\\end{equation*}\nIf this is the case, then\n\\begin{equation*}\nb\\sim k\\frac{x_d}{1+x_d\\,d}\\,n, \n\\end{equation*}\nso that, by \\eqref{2},\n\\begin{equation*}\n\\begin{aligned}\n    \\frac{\\ln c_{a,b}}n\\to \\frac k{1+x_d\\,d}\\,(\\ln(1+x_d)+x_d\\,\\ln(1+1/x_d)). \n\\end{aligned}\n\\tag{5}\\label{5}\n\\end{equation*}\nAlso, \\eqref{4} implies $x_d\\ge(k-1)/d$, so that $y_{k,d}=x_d$.\nSo, we have proved \\eqref{1}, and thus \\eqref{0} -- in the case when condition (3) is compatible with condition $a\\le n-1$.\nOtherwise, we have $a=n-1\\sim n$ and still $bd+a\\sim kn$, whence $b\\sim(k-1)n/d$. So, by \\eqref{2}, here\n\\begin{equation*}\n\\begin{aligned}\n    \\frac{\\ln c_{a,b}}n\\to \\ln\\Big(1+\\frac{k-1}d\\Big)+\\frac{k-1}d\\,\\ln\\Big(1+\\frac d{k-1}\\Big). \n\\end{aligned}\n\\tag{6}\\label{6}\n\\end{equation*}\nAlso, in this \"incompatibility\" case, we have $k\\frac1{1+x_d\\,d}\\ge1$ -- cf. \\eqref{4}. So, here $x_d\\le(k-1)/d$ and hence $y_{k,d}=\\frac{k-1}d$.\nSo, we have proved \\eqref{1}, and thus \\eqref{0} -- in the case when condition (3) is incompatible with condition $a\\le n-1$.\nThus, in either case, \\eqref{0} is proved. $\\quad\\Box$\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/416269", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "8", "answer_count": 4, "answer_id": 1}}
{"Q": "Is equation $xy(x+y)=7z^2+1$ solvable in integers? Do there exist integers $x,y,z$ such that\n$$\nxy(x+y)=7z^2 + 1 ?\n$$\nThe motivation is simple. Together with Aubrey de Grey, we developed a computer program that incorporates all standard methods we know (Hasse principle, quadratic reciprocity, Vieta jumping, search for large solutions, etc.) to try to decide the solvability of Diophantine equations, and this equation is one of the nicest (if not the nicest) cubic equation that our program cannot solve.\n", "A": "There is no solution.\nIt is clear that at least one of $x$ and $y$ is positive and that neither is divisible by 7. We can assume that $a := x > 0$. The equation implies that there are integers $X$, $Y$ such that\n$$ X^2 - 7 a Y^2 = a (4 + a^3) $$\n(with $X = a (a + 2y)$ and $Y = 2z$).\nFirst consider the case that $a$ is odd. Then $4 + a^3$ is also odd (and positive), so we can consider the Jacobi symbol\n$$ \\left(\\frac{7a}{4+a^3}\\right) \\,. $$\nOne of the two numbers involved is ${} \\equiv 1 \\bmod 4$, so\nby quadratic reciprocity,\n$$ \\left(\\frac{7a}{4+a^3}\\right)\n    = \\left(\\frac{4+a^3}{7}\\right) \\left(\\frac{4+a^3}{a}\\right)\n    = \\left(\\frac{4+a^3}{7}\\right) $$\n($4 + a^3$ is a square mod $a$). Since $7 \\nmid a$, we have\n$4 + a^3 \\equiv 3$ or $5 \\bmod 7$, both of which are nonsquares\n$\\bmod 7$, so the symbol is $-1$. This implies that there is\nan odd prime $p$ having odd exponent in $4 + a^3$ and such that\n$7a$ is a quadratic nonresidue $\\bmod p$. This gives a\ncontradiction (note that $p \\nmid a$).\nNow consider the case $a = 2b$ even; write $b = 2^{v_2(b)} b'$.\nThen we have that $4 + a^3 = 4 (1 + 2 b^3)$ and\n$$ \\left(\\frac{7a}{1 + 2b^3}\\right)\n   = \\left(\\frac{14b}{1 + 2b^3}\\right)\n   = \\left(\\frac{2}{1 + 2b^3}\\right)^{1+v_2(b)}\n     \\left(\\frac{7b'}{1 + 2b^3}\\right) \\,. $$\nIf $b$ is odd, then this is\n$$ \\left(\\frac{2}{1 + 2b^3}\\right)\n   (-\\left(\\frac{-1}{b}\\right))\n   \\left(\\frac{1 + 2b^3}{7}\\right)\n   \\left(\\frac{1 + 2b^3}{b}\\right) \\,, $$\nwhich is always $-1$ (the product of the first two factors is $1$;\nthen conclude similarly as above). We obtain again a contradiction.\nFinally, if $b$ is even, then\n$$ \\left(\\frac{2}{1 + 2b^3}\\right)^{1+v_2(b)}\n   \\left(\\frac{7b'}{1 + 2b^3}\\right)\n   = \\left(\\frac{1 + 2b^3}{7}\\right)\n   \\left(\\frac{1 + 2b^3}{b'}\\right) = -1$$\nagain (the first symbol is $1$, and quadratic reciprocity holds\nwith the positive sign), and the result is the same.\n\nHere is an alternative proof using the product formula for\nthe quadratic Hilbert symbol.\nIf $(a,y,z)$ is a solution (with $a > 0$), then for all\nplaces $v$ of $\\mathbb Q$, we must have\n$(7a, a(4+a^3))_v = 1$.\nWe can rewrite the symbol as follows.\n$$ (7a, a(4+a^3))_v\n    = (-7, a (4 + a^3))_v (-a, a)_v (-a, 4+a^3)_v \n    = (-7, a(4 + a^3))_v $$\n(the last two symbols in the middle expression are $+1$).\nSo it follows that\n$$ (-7, a)_v = (-7, 4 + a^3)_v \\,.$$\nWhen $v = \\infty$, the symbols are $+1$, since $a > 0$.\nWhen $v = 2$, the symbols are $+1$, since $-7$ is a\n$2$-adic square.\nWhen $v = p \\ne 7$ is an odd prime, one of the symbols is\n$+1$ (and therefore both are), since $a$ and $4 + a^3$\nhave no common odd prime factors.\nFinally, when $v = 7$, the symbol on the right is\n$$ (-7, 4 + a^3)_7 = \\left(\\frac{4 + a^3}{7}\\right) = -1 $$\nas in the first proof.\nPutting these together, we obtain a contradiction to the\nproduct formula for the Hilbert symbol.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/420896", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "31", "answer_count": 2, "answer_id": 0}}
{"Q": "Division problem Are there infinitely many pairs of positive integers $(a,b)$ such that $2(6a+1)$ divides $6b^2+6ab+b-6a^2-2a-3$? That is, if there are infinitely many different $a$ and for which at least one value of $b$ can be found for a given $a$. Some $a$ values are $0,2,3,7,11,17....$\nI think that the answer is yes but I have no idea how to show this.\nIf the answer is yes, are there any polynomial parametric solutions?\n", "A": "If $6a+1$ is a prime and a quadratic residue modulo $17$ (which is true for infinitely many values of $a$), then there are infinitely many positive integers $b$ with the required property.\nFirst observe that $b$ is good if and only if $$f(a,b):=6b^2+6ab+b-6a^2-2a-3$$ is even and divisible by $6a+1$. Hence $b$ must be odd: $b=2c+1$. Now we need to find infinitely many positive integers $c$ such that $f(a,2c+1)$ is divisible by $6a+1$. The identity\n$$6f(a,2c+1) + (6a-5-12c)(6a + 1)=(12c+6)^2-17$$\nshows that $c$ is good if and only if $(12c+6)^2-17$ is divisible by $6a+1$. So we need to guarantee that the congruence\n$$(12c+6)^2\\equiv 17\\pmod{6a+1}$$\nhas a solution. This is equivalent to $17$ being a quadratic residue modulo $6a+1$. By quadratic reciprocity, this is equivalent to $6a+1$ being a quadratic residue modulo $17$, and we are done.\n", "meta": {"language": "en", "url": "https://mathoverflow.net/questions/436310", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 1, "answer_id": 0}}
