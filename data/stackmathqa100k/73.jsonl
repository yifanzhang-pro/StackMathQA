{"Q": "Find probability from uniform distribution Let $X$, $Y$ be two independent random variables from $U(0,1)$. Then find $P[Y>(X-1/2)^2]$.\nI initially  tried drawing the figure but that seemed complicated. I then took expectation on both sides and got $P[E(Y)>V(X)]$. Am I right?\n", "A": "This ends up being the area above the curve\n\\begin{equation}\nY=(X\u2212\\frac{1}{2})^2\n\\end{equation}\n\nThis can be found by integration\n\\begin{equation}\nP[Y>(X\u2212\\frac{1}{2})^2] = \\int_{0}^{1}\\int_{(X\u2212\\frac{1}{2})^2}^{1} 1\\times1 \\,dydx\n\\end{equation}\n\\begin{equation}\n= \\int_{0}^{1}{1-(X\u2212\\frac{1}{2})^2} \\,dx\n\\end{equation}\n\\begin{equation}\n=  \\Big[X-\\frac{1}{3}\\times(X\u2212\\frac{1}{2})^3\\Big]_0^1  \n\\end{equation}\n\\begin{equation}\n=  \\Big(1-\\frac{1}{3}\\times(1\u2212\\frac{1}{2})^3\\Big) - \\Big(0-\\frac{1}{3}\\times(0\u2212\\frac{1}{2})^3\\Big)\n\\end{equation}\n\\begin{equation}\n=  \\frac{23}{24}-\\frac{1}{24}\n\\end{equation}\n\\begin{equation}\n=  \\frac{22}{24}\n\\end{equation}\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/275108", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "Finding vectors that direct the discriminatory factorial axis \nLet be a set $E$ of $100$ individuals for who the quantitative variables $x_1$ and $x_2$ have been observed. This set is partitioned into $C_1$ and $C_2$ which contains $40$ and $60$ individuals respectively. Each individuals have a weight of $1/100$. We write $g_1$ and $g_2$ the gravity center of $C_1$ and $C_2$ and $V$ the total variance matrix, that is to say the matrix of variable $x_1$ and $x_2$ which have been observed for each of the $100$ individuals. We assume that :\n$$g_1=\\begin{pmatrix}6\\\\1\n\\end{pmatrix}, g_2=\\begin{pmatrix}1\\\\-4\n\\end{pmatrix}$$ \nI'm looking for the vector that direct the only discriminatory  factorial axis of the following matrix :\n$$V=\n\\begin{pmatrix}\n5 & 0\\\\\n0 & 2\n\\end{pmatrix}$$\n\nI have the following eigenvectors and values :\n\n\n*\n\n*$\\begin{pmatrix}1\\\\0\\end{pmatrix}$ for $5$\n\n*$\\begin{pmatrix}0\\\\1\\end{pmatrix}$ for $2$\n\n\nNormalizing the vector I get :\n\n\n*\n\n*$v_1=\\frac{1}{\\sqrt{5}}\\begin{pmatrix}1\\\\0\\end{pmatrix}$\n\n*$v_2=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}0\\\\1\\end{pmatrix}$\n\n", "A": "Here is the formula to apply :\n\\begin{align}\n\\frac{g_2-g_1}{||g_2-g_1||}&=\n\\frac{\\begin{pmatrix}1\\\\-4\\end{pmatrix}-\\begin{pmatrix}6\\\\1\\end{pmatrix}}{||\\begin{pmatrix}1\\\\-4\\end{pmatrix}-\\begin{pmatrix}6\\\\1\\end{pmatrix}||}\\\\\n&=\\frac{-5\\begin{pmatrix}1\\\\1\\end{pmatrix}}{||-5\\begin{pmatrix}1\\\\1\\end{pmatrix}||}\\\\\n&=-\\frac{1}{2}\\begin{pmatrix}1\\\\1\\end{pmatrix}\n\\end{align}\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/277328", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "Let A and B be independent. Show that $A^c$ and $B^c$ c are independent - better solution? My solution seems too long winded. This should take less writing, no? Here it is.\n$B^c$ means complement of $B$ (i.e. $P(B) = 1 - P(B^c)$\nIf $A$ and $B$ are independent events:\n$$\nP(A \\cap B) = P(A)P(B)\n$$\nSo I do:\n$$\nP(A^c \\cap B^c) = P(A^c | B^c)P(B^c) = (1 - P(A|B^c))P(B^c) = (1 - \\frac{P(A\\cap B^c)}{P(B^c)})P(B^c) = (1 - \\frac{P(B^c|A)P(A)}{P(B^c)})P(B^c)\n$$\nNow, I can use the result that since $A$ and $B$ are independent $P(B^c|A) = 1 - P(B|A) = 1 - P(B) = P(B^c)$. Then:\n$$\n(1 - \\frac{P(B^c|A)P(A)}{P(B^c)})P(B^c) = (1 - \\frac{P(B^c)P(A)}{P(B^c)})P(B^c) = (1 - P(A))P(B^c) = P(A^c)P(B^c)\n$$\nTherefore, since $P((A^c \\cap B^c) = P(A^c)P(B^c)$ then $A^c$ and $B^c$ are independent.\n", "A": "Here is another way:\n$$\\begin{align} P(A^c\\cap B^c) &=1-P(A\\cup B)=1-P(A)-P(B)+P(A\\cap B)\\\\  &= 1-P(A)-P(B)+P(A)P(B) \\\\ &=1-P(A)-P(B)(1-P(A))=(1-P(A))(1-P(B)) \\\\ &= P(A^c)P(B^c)\\end{align}$$\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/394726", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "$X_{1},X_{2},X_{3}\\overset{i.i.d.}{\\sim}N(0,1)$, find m.g.f. of $Y=X_{1}X_{2}+X_{1}X_{3}+X_{2}X_{3}$ I tried this\n$X_{1}X_{2}+X_{1}X_{3}+X_{2}X_{3}=X_{1}(X_{2}+X_{3})+\\frac{1}{4}(X_{2}+X_{3})^{2}-\\frac{1}{4}(X_{2}-X_{3})^{2}$\n$U=X_{2}+X_{3}\\sim N(0,2)$\n$\\psi_{X_{1}(X_{2}+X_{3})}(t)=\\psi_{X_{1}U}(t)=\\frac{1}{\\sqrt{2}\\cdot 2\\pi}\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}e^{x_{1}ut}e^{-\\frac{1}{2}(x_{1}^{2}+\\frac{u^{2}}{2})}\\, dx_{1}\\, du$\n$=\\frac{1}{\\sqrt{2}\\cdot 2\\pi}\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}e^{-\\frac{1}{4}(2(x_{1}-ut)^{2}-2u^{2}t^{2}+u^{2})}\\, dx_{1}\\, du$\n$V=(x_{1}-ut)\\qquad dv=dx_{1}\\\\\n        =\\frac{1}{\\sqrt{2}\\cdot 2\\pi}\\int_{-\\infty}^{\\infty}e^{-\\frac{1}{4}(1-2t^{2})u^{2}}\\int_{-\\infty}^{\\infty}e^{-\\frac{1}{2}v^{2}}\\, dv\\, du\\\\$\n$=\\frac{1}{\\sqrt{\\pi}\\cdot 2}\\int_{-\\infty}^{\\infty}e^{-\\frac{1}{4}(1-2t^{2})u^{2}}\\, du$\n$ w=\\sqrt{\\frac{1-2t^{2}}{2}}u,\\qquad \\sqrt{\\frac{2}{1-2t^{2}}}\\, dw=du\\\\\n    \\psi_{XU}(t)=\\frac{1}{\\sqrt{1-2t^{2}}}\\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}w^{2}}\\, dw=\\frac{1}{\\sqrt{1-2t^{2}}}$\n$Z=X_{2}-X_{3}\\sim N(0,2)$\n$\\psi_{\\frac{1}{4}(X_{1}+X_{2})^{2}}(t)=\\frac{1}{\\sqrt{4\\pi}}\\int_{-\\infty}^{\\infty}e^{\\frac{1}{4}z^{2}t}e^{-\\frac{1}{4}z^{2}}\\, dz$\n$=\\frac{1}{\\sqrt{4\\pi}}\\int_{-\\infty}^{\\infty}e^{-\\frac{1}{4}(z^{2}-z^{2}t)}\\, dz=\\frac{1}{\\sqrt{4\\pi}}\\int_{-\\infty}^{\\infty}e^{-\\frac{1}{4}(1-t)z^{2}}\\, dz\\\\$\n$v=\\sqrt{1-t}z,\\quad \\frac{1}{\\sqrt{1-t}}\\, dv=dz\\\\\n        \\psi_{\\frac{1}{4}(X_{1}+X_{2})^{2}}(t)=\\frac{1}{\\sqrt{1-t}}\\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{4\\pi}}e^{-\\frac{1}{4}z^{2}}\\,dz=\\frac{1}{\\sqrt{1-t}}$\n$\\psi_{\\frac{1}{4}(X_{1}+X_{2})^{2}-\\frac{1}{4}(X_{2}-X_{3})^{2}}(t)=\\frac{1}{\\sqrt{1-t}}\\cdot \\frac{1}{\\sqrt{1-(-t)}}=\\frac{1}{\\sqrt{(1-t)(1+t)}}=\\frac{1}{\\sqrt{1-t^{2}}}$\n$\\psi_{X_{1}(X_{2}+X_{3})+\\frac{1}{4}(X_{2}+X_{3})^{2}-\\frac{1}{4}(X_{2}-X_{3})^{2}}(t)=\\frac{1}{\\sqrt{1-2t^{2}}}\\cdot \\frac{1}{\\sqrt{1-t^{2}}}=\\frac{1}{\\sqrt{1-2t^{2}}\\sqrt{1-t^{2}}}$\nBut I have learned that this is incorrect. What mistakes did I make?\n", "A": "In your first line you write the expression as the sum of three quadratic forms. You then multiply the three mgfs. But, this is only possible if the variables (quadratic forms) are independent. Quadratic forms are independent if and only if the product of their matrices is the zero matrix. This is not true of the first and second quadratic forms. However, it is true of the first and third and it is true of the second and third. That is why you could multiply two of the mgfs and get a correct result for those.\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/478495", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 2, "answer_id": 0}}
{"Q": "Conditional Multivariate Gaussian Identity I'm trying to verify the form of a multivariate Gaussian provided in a paper I'm reading. It should be pretty elementary.\nLet $Y=X+\\varepsilon$ where $X\\sim N(0,C)$ and $\\varepsilon\\sim N(0,\\sigma^2\\mathbf{I})$. The authors then claim that\n$$\nX|Y,C,\\sigma^2 \\sim N(\\mu,\\Sigma),\n$$\nwhere\n$$\n\\mu := C(C+\\sigma^2\\mathbf I)^{-1}Y\\\\\n\\Sigma:=\\sigma^2C(C+\\sigma^2\\mathbf I)^{-1}.\n$$\nMy first thought was to consider the joint distribution\n$$\n\\begin{pmatrix}\nX\\\\\nY\n\\end{pmatrix}\\sim N\\Big(\\begin{pmatrix}\n0\\\\\n0\n\\end{pmatrix},\\begin{pmatrix}\nC & C\\\\\nC^\\top & \\sigma^2\\mathbf I+C\n\\end{pmatrix}\\Big)\n$$\nand apply the conditional Gaussian identities. Unfortunately this approach gives me the right $\\mu$, but I can't see how their form of $\\Sigma$ comes about. Any thoughts?\n", "A": "This is a correct representation of the conditional variance.\nSince\n$$\\begin{pmatrix}\nX\\\\\n\\epsilon\n\\end{pmatrix}\\sim N\\Big(\\begin{pmatrix}\n0\\\\\n0\n\\end{pmatrix},\\begin{pmatrix}\nC & \\mathbf O\\\\\n\\mathbf O & \\sigma^2\\mathbf I\n\\end{pmatrix}\\Big)$$\nand\n$$\\begin{pmatrix}\nX\\\\\nY\n\\end{pmatrix} =  \\begin{pmatrix}\n\\mathbf 1^\\text{T} &\\mathbf 0^\\text{T} \\\\\n\\mathbf 1^\\text{T} &\\mathbf 1^\\text{T}\n\\end{pmatrix}\\begin{pmatrix}\nX\\\\\n\\epsilon\n\\end{pmatrix}$$\nthe distribution of $\\begin{pmatrix}\nX\\\\\nY\n\\end{pmatrix}$ is\n$$\\begin{pmatrix}\nX\\\\\nY\n\\end{pmatrix}\\sim N\\Big(\\begin{pmatrix}\n0\\\\\n0\n\\end{pmatrix},\\underbrace{\\begin{pmatrix}\n\\mathbf 1^\\text{T} &\\mathbf 0^\\text{T} \\\\\n\\mathbf 1^\\text{T} &\\mathbf 1^\\text{T}\n\\end{pmatrix}\\begin{pmatrix}\nC & \\mathbf O\\\\\n\\mathbf O & \\sigma^2\\mathbf I\n\\end{pmatrix}\\begin{pmatrix}\n\\mathbf 1 &\\mathbf 1 \\\\\n\\mathbf 0 &\\mathbf 1\n\\end{pmatrix}}_{\\begin{pmatrix}\nC & C\\\\\nC & \\sigma^2\\mathbf I\n\\end{pmatrix}\n}\\Big)$$\nindeed. With\n$$\\mathbb E[X|Y] = 0 + C (C+\\sigma^2\\mathbf I)^{-1}\nY $$\nand\n$$\\text{var}(X|Y) = C - C (C+\\sigma^2I)^{-1} C\n$$\nApplying the Woodbury matrix inversion lemma\n$$(A+B)^{-1}=A^{-1}-A^{-1}(B^{-1}+A^{-1})^{-1}A^{-1}$$\none gets that\n\\begin{align*} C - C (C+\\sigma^2I)^{-1} C &= C - C (C^{-1}-\nC^{-1}(C^{-1}+\\sigma^{-2}\\mathbf I)^{-1}C^{-1})C\\\\ &= C - C\n+(C^{-1}+\\sigma^{-2}\\mathbf I)^{-1}\\\\ &= \n(C^{-1}\\mathbf I+\\sigma^{-2}C^{-1}C)^{-1}\\\\ &= \\sigma^2 C (\\sigma^2\\mathbf I+C)^{-1}\n\\end{align*}\nThe apparent lack of symmetry in the expression may sound suspicious but actually$$C (\\sigma^2\\mathbf I+C)^{-1} = (\\sigma^2\\mathbf I+C)^{-1} C$$\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/481518", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 1, "answer_id": 0}}
{"Q": "Discrete probability distribution involving curtailed Riemann zeta values $\\renewcommand{\\Re}{\\operatorname{Re}}$ $\\renewcommand{\\Var}{\\operatorname{Var}}$We define the discrete random variable $X$ as having the probability mass function $$f_{X}(k) = \\Pr(X=k) = \\zeta(k)-1, $$ for $k \\geq 2 $.\nHere, $\\zeta(\\cdot)$ is the Riemann zeta function, defined as $$\\zeta(s) = \\sum_{n=1}^{\\infty} n^{-s} $$ for $\\Re(s) >1 $.\nNow, $X$ is indeed a discrete RV, as we have $$\\sum_{k=2}^{\\infty} p_k = \\sum_{k=2}^{\\infty} (\\zeta(k)-1) = 1,$$ (which we can find, for example, here) and it is clear that for all $k$ it holds that $$0 \\leq p_k \\leq 1 .$$\nFurthermore, we can find the first and second moments of $X$. The mean amounts to $$E[X] = \\sum_{k=2}^{\\infty} k \\big(\\zeta(k)-1\\big) = 1+\\frac{\\pi^{2}}{6} .$$\nMoreover, we have $$E[X^{2}] = \\sum_{k=2}^{\\infty} k^{2} \\big( \\zeta(k)-1 \\big) = 1 + \\frac{\\pi^{2}}{2} + 2 \\zeta(3), $$ so we obtain \\begin{align*} \\Var(X) &= E[X^2] - E[X]^{2} \\\\ \n&= \\frac{\\pi^2}{6} +2 \\zeta(3) - \\frac{\\pi^4}{36} \\\\ \n&=  \\zeta(2) + 2 \\zeta(3) - \\frac{5}{2} \\zeta(4). \\end{align*}\nQuestion: does this discrete random variable involving curtailed Riemann zeta values come up in the literature on probability theory and/or statistics? Does it have any applications?\nNote: please note that this RV differs from the Zeta distribution.\n", "A": "To illustrate Whuber's comment\n$$\\begin{array}{c|ccccccccc}\n& Y = 2 & Y =3& Y=4 & Y=5\\\\\n\\hline\n X =2  & \\frac{1}{2^2} & \\frac{1}{3^2} & \\frac{1}{4^2} &\\frac{1}{5^2} & \\dots\\\\\n X =3  & \\frac{1}{2^3} & \\frac{1}{3^3} & \\frac{1}{4^3} & \\frac{1}{5^3} & \\dots\\\\\n X =4  & \\frac{1}{2^4}  &\\frac{1}{3^4} &\\frac{1}{4^4} & \\frac{1}{5^4} &\\dots\\\\\n\\vdots& \\\\\\text{etc.}&\n\\end{array}$$\nAnd those terms can be seen as the product of a product $P(X=x|Y=y)P(Y=y)$ with a shifted geometric distribution $$P(X=x|Y=y) =   \n\\left(\\frac{1}{y}\\right)^{x} y(y-1)$$ and some sort of variant of a Zipf distribution $$P(Y=y) =   \n \\frac{1}{y(y-1)}$$\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/604631", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 1, "answer_id": 0}}
