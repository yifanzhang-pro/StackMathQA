{"Q": "Prove that $(A^{-1} + B^{-1})^{-1}=A(A+B)^{-1}B$ I have this equality \n$$(A^{-1} + B^{-1})^{-1}=A(A+B)^{-1}B$$ where  $A$ and $B$ are square symmetric matrices.\nI have done many test of R and Matlab that show that this holds, however I do not know how to prove it.\n", "A": "Note that\n$$ \\mathbf{A} \\left(\\mathbf{A} + \\mathbf{B} \\right)^{-1} \\mathbf{B}$$\nis the inverse of \n$$\\left(\\mathbf{A}^{-1} + \\mathbf{B}^{-1} \\right) $$\nif and only if \n$$ \\mathbf{A} \\left(\\mathbf{A} + \\mathbf{B} \\right)^{-1} \\mathbf{B} \\left(\\mathbf{A}^{-1} + \\mathbf{B}^{-1} \\right) = \\mathbf{I} $$\nand \n$$ \\left(\\mathbf{A}^{-1} + \\mathbf{B}^{-1} \\right) \\mathbf{A} \\left(\\mathbf{A} + \\mathbf{B} \\right)^{-1} \\mathbf{B} = \\mathbf{I} $$\nso that the left and right inverses coincide. Let's prove the first statement. We can see that \n$$\\begin{align} \\mathbf{A} \\left(\\mathbf{A} + \\mathbf{B} \\right)^{-1} \\mathbf{B} \\left(\\mathbf{A}^{-1} + \\mathbf{B}^{-1} \\right) & = \\mathbf{A} \\left(\\mathbf{A} + \\mathbf{B} \\right)^{-1} \\left(\\mathbf{B} \\mathbf{A}^{-1} + \\mathbf{I} \\right) \\\\ &=  \\mathbf{A} \\left(\\mathbf{A} + \\mathbf{B} \\right)^{-1} \\left( \\mathbf{A} + \\mathbf{B} \\right) \\mathbf{A}^{-1} \\\\ & = \\mathbf{I} \\end{align} $$\nas desired. A similar trick will prove the second statement as well. Thus $ \\mathbf{A} \\left(\\mathbf{A} + \\mathbf{B} \\right)^{-1} \\mathbf{B}$ is indeed the inverse of $\\left(\\mathbf{A}^{-1} + \\mathbf{B}^{-1} \\right) $.\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/197067", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "8", "answer_count": 2, "answer_id": 0}}
{"Q": "sample all pairs without repeats Assuming I have a very large number of $K$ colored balls and we know the fraction of each color. If we randomly sample all pairs so that all pairs have two balls of different colors then what is the fraction of pairs with a given color combinations?\nFor example if there are 3 colors with fractions, $f_{blue}=0.5$, $f_{red}=0.25$ and $f_{green}=0.25$ then if you sample all pairs of balls such that each pairs consists of two different colors. Then I would expect that $50\\%$ of pairs will be $(blue/red)$, $50\\%$ will be $(blue/green)$ and $0\\%$ $(red/green)$ (if 50% is blue then there must be a blue in each pair). This scenario is easy since there is only one way to sample all unordered pairs. \nIf more than $50\\%$ of balls have the same color there will be no solution and if $50\\%$ of balls are a certain color there is only one way to sample all balls (unordered) as above. \nIf the fraction of 3 colors are then same $f_{blue}=1/3$, $f_{red}=1/3$ and $f_{green}=1/3$ then by symmetry I would expect the fraction of pairs to be  $1/3$ $(blue/red)$, $1/3$ $(blue/green)$ and $1/3$ $(red/green)$ if they where randomly sampled. \nIs there a general way to calculate the expected fraction of colored pairs given you know the fraction of each of the $K$ colors?\nEdit/update\n Ertxiem gave the solution in the case of K=3 where you do not use the assumption of randomly drawing all pairs (pairs of different colors without replacement). \nHere is what I have tried so far. \nLet $f=(f_1,f_2,\\ldots,f_K)$ be the fraction of each colored ball assuming K colors. \nFor the case of K=3 then we can calculate the fraction of pairs of ball by solving the following \n$Ax=f$ where $A=    \\left( \\begin{array}{ccc}\n0.5 & 0.5 & 0 \\\\\n0.5 & 0 & 0.5 \\\\\n0 & 0.5 &0.5\n  \\end{array}\n\\right)\n$, $f=  \\left( \\begin{array}{c}\nf_1\\\\\nf_2 \\\\\nf_3 \n  \\end{array}\n\\right)$, $x= \\left( \\begin{array}{c}\n\\pi_{12}\\\\\n\\pi_{13} \\\\\n\\pi_{23} \n  \\end{array}\\right)$ where $\\pi_{ij}$is the probability of a pair of color $i$ and $j$. \nThis gives the solution for $K=3$. \nFor $K>3$ we cannot use the same approach because there will be multiple solutions for example for $K=4$. Solving $Ax=f$ where $A=    \\left( \\begin{array}{cccccc}\n0.5 & 0.5 & 0.5 & 0 & 0 & 0  \\\\\n0.5 & 0 & 0  &0.5 &0.5 &0 \\\\\n0 & 0.5 &0  & 0.5 & 0 & 0.5 \\\\\n0 & 0 &0.5  & 0& 0.5& 0.5\n  \\end{array}\n\\right)\n$, $f=  \\left( \\begin{array}{c}\nf_1\\\\\nf_2 \\\\\nf_3 \\\\\nf_4 \n  \\end{array}\n\\right)$ and  $x= \\left( \\begin{array}{c}\n\\pi_{12}\\\\\n\\pi_{13} \\\\\n\\pi_{14} \\\\ \n\\pi_{23} \\\\\n\\pi_{24} \\\\\n\\pi_{34}\\end{array}\\right)$ gives multiple multiple solutions. Is there a way to solve it by assuming the color combinations are independent given that they are different?  \nupdate with example and simulations\nFor the $K=4$ case then I have tried to solve $Ax=f$ for $x$ using Moore-Penrose generalized inverse (pseudoinverse using least squared solution) however, this does not give the same results as simulations (rejection sampling using $5e7$ balls).  For the case of $f=(3/8,1/8,2/8,2/8)$ I get the following results\n$$\\begin{array}{c|c|c}\n\\hat{\\pi} & pseudo inverse & simulations\\\\\n\\pi_{12} & 4/24 & 31/236\\\\\n\\pi_{13} & 7/24 &  73/236\\\\\n\\pi_{14} & 7/24 &  73/236\\\\ \n\\pi_{23} & 1/24 &  14/236\\\\\n\\pi_{24} & 1/24 &  14/236\\\\\n\\pi_{34} & 4/24 &  31/236\n  \\end{array}$$. \nSo I am still not able to find a analytical solution (for K>3). \n", "A": "Suppose you have $K$ colours of balls with respective numbers $n_1,...,n_K$, with a total of $n = \\sum n_i$ balls.  Let $\\mathscr{S}$ denote the set of all pairs of distinct balls and let $\\mathscr{C}$ denote the set of all pairs of distinct balls of the same colour.  Since $\\mathscr{C} \\subset \\mathscr{S}$ the number of ways you can sample two balls of different colours is:\n$$\\begin{equation} \\begin{aligned}\n|\\mathscr{S} - \\mathscr{C}| = |\\mathscr{S}| - |\\mathscr{C}| \n&= {n \\choose 2} - \\sum_{k=1}^K {n_k \\choose 2} \\\\[6pt]\n&= \\frac{n(n-1)}{2} - \\sum_{k=1}^K \\frac{n_k (n_k-1)}{2} \\\\[6pt]\n&= \\frac{1}{2} \\Big[ n(n-1) - \\sum_{k=1}^K n_k (n_k-1) \\Big] \\\\[6pt]\n&= \\frac{1}{2} \\Big[ (n-1) \\sum_{k=1}^K n_k - \\sum_{k=1}^K n_k (n_k-1) \\Big] \\\\[6pt]\n&= \\frac{1}{2} \\sum_{k=1}^K n (n-n_k). \\\\[6pt]\n\\end{aligned} \\end{equation}$$\nLet $\\mathscr{M}_{a,b}$ denote the set of all pairs of distinct balls with colours $a \\neq b$.  The number of ways you can sample two balls with a given (different) colour combination is:\n$$|\\mathscr{M}_{a,b}| = \\frac{n_a n_b}{2}$$\nHence, the fraction of sample-pairs of different colours that are of the specified colour pair $a \\neq b$ is:\n$$P_n(a,b) = \\frac{|\\mathscr{M}_{a,b}|}{|\\mathscr{S} - \\mathscr{C}|} = \\frac{n_a n_b}{\\sum_{k=1}^K n_k (n-n_k)}.$$\nTaking $n \\rightarrow \\infty$ and letting $p_1,...,p_K$ be the respective limiting sample proportions of the balls of each colour, you have:\n$$P_\\infty(a,b) = \\lim_{n \\rightarrow \\infty} \\frac{|\\mathscr{M}_{a,b}|}{|\\mathscr{S} - \\mathscr{C}|} = \\frac{p_a p_b}{\\sum_{k=1}^K p_k (1-p_k)}.$$\n\nApplication to your problem: In your example you have $K=3$ colours with proportions $\\mathbf{p} = (\\tfrac{1}{2}, \\tfrac{1}{4}, \\tfrac{1}{4})$ for the respective colours $\\text{Blue}, \\text{Red}, \\text{Green}$.  This gives:\n$$P_\\infty(a,b) \n= \\frac{p_a p_b}{\\tfrac{1}{2} \\cdot \\tfrac{1}{2} + \\tfrac{1}{4} \\cdot \\tfrac{3}{4} + \\tfrac{1}{4} \\cdot \\tfrac{3}{4}}\n= \\frac{p_a p_b}{5/8}\n= \\tfrac{8}{5} \\cdot p_a p_b.$$\nSo you have:\n$$\\begin{equation} \\begin{aligned}\nP_\\infty(\\text{Blue}, \\text{Red}) \n&= \\tfrac{8}{5} \\cdot \\tfrac{1}{2} \\cdot \\tfrac{1}{4} = \\tfrac{1}{5}, \\\\[6pt]\nP_\\infty(\\text{Blue}, \\text{Green}) \n&= \\tfrac{8}{5} \\cdot \\tfrac{1}{2} \\cdot \\tfrac{1}{4} = \\tfrac{1}{5}, \\\\[6pt]\nP_\\infty(\\text{Red}, \\text{Green}) \n&= \\tfrac{8}{5} \\cdot \\tfrac{1}{4} \\cdot \\tfrac{1}{4} = \\tfrac{1}{10}. \\\\[6pt]\n\\end{aligned} \\end{equation}$$\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/402971", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 2, "answer_id": 0}}
{"Q": "Correct or not? Mixed Bayes' Rule - Noisy Communication In this problem, we study a simple noisy communication channel. Suppose that  $X$  is a binary signal that takes value  $\u22121$  and  $1$  with equal probability. This signal  $X$  is sent through a noisy communication channel, and the medium of transmission adds an independent noise term. More precisely, the received signal is  $Y=X+N$ , where  $N$  is standard normal, indpendendent of  $X$ .\nThe decoder receives the value  $y$  of  $Y$, and decides whether  $X$  was  $1$  or  $\u22121$,  using the following decoding rule: it decides in favor of  $1$  if and only if\n$$P(X=1|Y=y)>2P(X=-1|Y=y)$$\nIt turns out that the decoding rule can be expressed in the form: decide in favor of  $1$  if and only if  $Y>t$, for some threshold t. Find the threshhold t .\nAs an intermediate step, find  $p_1\u225cP(X=1|Y=y).$\nI get the answer of $p_1 = {e^{-2*(y-1)/2}\\over e^{-2*(y-1)/2}+e^{-2*(y+1)/2}}$\nor is the answer, $p_1 = \\frac{1}{1 + e^{-2*y}}$\n", "A": "Both answers are correct. \nThe likelihood is defined as\n$$\np \\left(Y \\mid X=1 \\right) = \\frac{1}{\\sqrt{2\\pi}}\\, e^{\\frac{-\\left(y-1 \\right)^2}{2}}\n$$\nAssuming both $X=1$ and $X=-1$ have the same probability, $p(X=1)=\\frac{1}{2}$, the posterior is found with Bayes rule as following.\n$$\n\\begin{align}\np \\left(X=1 \\mid Y \\right) &= \\frac{p \\left(Y \\mid X=1 \\right)\\cdot p \\left(X=1 \\right)}{p\\left(Y \\right)}\\\\\n&=\\frac{p \\left(Y \\mid X=1 \\right)\\cdot \\frac{1}{2}}{\\frac{1}{2} \\cdot p\\left(Y\\mid X=1 \\right) + \\frac{1}{2} \\cdot p\\left(Y\\mid X=-1 \\right)}\\\\\n&= \\frac{\\frac{1}{\\sqrt{2\\pi}}\\, e^{\\frac{-\\left(y-1 \\right)^2}{2}} \\cdot \\frac{1}{2}}{ \\frac{1}{2} \\cdot \\frac{1}{\\sqrt{2\\pi}}\\, e^{\\frac{-\\left(y-1 \\right)^2}{2}} + \\frac{1}{2} \\cdot \\frac{1}{\\sqrt{2\\pi}}\\, e^{\\frac{-\\left(y+1 \\right)^2}{2}} } \\\\\n&= \\frac{e^{\\frac{-\\left(y-1 \\right)^2}{2}} }{ e^{\\frac{-\\left(y-1 \\right)^2}{2}} + e^{\\frac{-\\left(y+1 \\right)^2}{2}} }\n\\end{align} \n$$\nThis can be manipulated further to obtain your second answer\n$$\n\\begin{align}\np \\left(X=1 \\mid Y \\right) &= \\frac{e^{\\frac{-\\left(y-1 \\right)^2}{2}} }{ e^{\\frac{-\\left(y-1 \\right)^2}{2}} + e^{\\frac{-\\left(y+1 \\right)^2}{2}} }\\\\\n&= \\frac{1}{ 1+ e^{\\frac{-\\left(y+1 \\right)^2}{2} - \\frac{-\\left(y-1 \\right)^2}{2}} }\\\\\n&= \\frac{1}{ 1+ e^{-2y} }\n\\end{align} \n$$\nCouldn't resist but finish also the rest of the exercise. The threshold $t$ is the value of $y$ that satisfies the following\n$$\np \\left(X=1 \\mid Y =t\\right) = 2 \\cdot p \\left(X=-1 \\mid Y=t \\right)\n$$\nPlugging in the formula of the posterior distribution found above, and solving for $t$ results in \n$$\nt = \\frac{\\log_e 2}{2}\n$$\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/420744", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 1, "answer_id": 0}}
{"Q": "calculate probability using joint density function I'm stuck with this question:\nX,Y are random variables and thier joint density function is:\n$$f_X,_Y(x,y)=2 ,0<=x<=1, 0<=y<=x$$\nNow we define new random variable Z: $$Z=XY^3$$\nI need to calculate the value of $$F_Z(0.3)$$\nand i'm not so sure which bounds i should integrate with the joint function of X and Y.\n", "A": "Let $\\mathcal A_t= \\left \\{0 \\leq x \\leq 1, 0 \\leq y \\leq x : xy^3 \\leq t \\right\\}$\nThe probability $\\mathbb P(XY^3 \\leq t)$ can be seen as a double integral over $\\mathcal A_t$:\n$$\n\\mathbb P(XY^3 \\leq t) = 2 \\int_{A_t} dxdy\n$$\nThe condition $xy^3 \\leq t$ imply that $y \\leq \\left( \\frac{t}{x} \\right)^{\\frac{1}{3}}$\nand $\\left( \\frac{t}{x} \\right)^3 \\leq x \\Rightarrow x \\geq t^{\\frac{1}{4}}$.\nSo in the above integral, for a fixed $x$, if $x \\geq t^{\\frac{1}{4}}$ then integration over $y$ ranges from $0$ to $\\left( \\frac{t}{x} \\right)^{\\frac{1}{3}}$ (it is $0$ otherwise) and if $x \\leq t^{\\frac{1}{4}}$ it ranges from $0$ to $x$.\nHence we have:\n\\begin{align*}\n\\int_{A_t} dxdy  &= \\int_0^{t^{\\frac{1}{4}}} x dx + \\int_{t^{\\frac{1}{4}}}^1\\left( \\frac{t}{x} \\right)^{\\frac{1}{3}} dx \\\\\n&= \\left[ \\frac{x^2}{2} \\right]_0^{t^{\\frac{1}{4}}} + t^{\\frac{1}{3}} \\left[ \\frac{3}{2} x^{\\frac{2}{3}}\\right ]_{t^{\\frac{1}{4}}}^1 \\\\\n&= \\frac{\\sqrt{t}}{2} + \\frac{3}{2}t^{\\frac{1}{3}}\\left(1-t^{\\frac{1}{6}} \\right) \\\\\n&= \\frac{\\sqrt{t}}{2} + \\frac{3}{2}t^{\\frac{1}{3}}-\\frac{3\\sqrt{t}}{2} \\\\\n&=\\frac{3}{2}t^{\\frac{1}{3}} - \\sqrt{t}\n\\end{align*}\nMultiplying this by $2$ yields the desired probability:\n\\begin{align*}\n\\mathbb P(Z \\leq t) = 3t^{\\frac{1}{3}} - 2 \\sqrt{t}\n\\end{align*}\nFor $t=0.3$ this gives $\\mathbb P(Z \\leq t) \\approx 0.913$.\n", "meta": {"language": "en", "url": "https://stats.stackexchange.com/questions/545025", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
