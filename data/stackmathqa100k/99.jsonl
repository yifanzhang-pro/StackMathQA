{"Q": "A confusion in the Derivation of Lorentz Transformation \nMy doubt is in the equation (1) and (2). Aren't x,y and z also the radiuses?\nEDIT\nThank you guys for trying to give a wonderful explanation but I figured out the answer myself and it was just my silly interpretation. I thought the the value of ct on x axis would be equal to ct and forgot that the value is given by a perpendicular and not an arc (of the sphere). I was thinking that where the sphere touches x axis, that is the value of ct but it isn't. The value of ct for x is given by a point on the axis that lies perpendicular to the axis.\n", "A": "Think of the coordinates as a single object: $\\mathbf{x}=\\left(x,\\,y,\\,z\\right)$. \nA point $P$ located at $\\mathbf{P}=\\left(a,\\,b,\\,c\\right)$ would look like this:\n\nNow what is the distance from the origin ($\\mathbf{x}=(0,\\,0,\\,0)$) and $\\mathbf{P}$? For this we need to use the Pythagorean theorem: the square of the diagonal is equal to the sum of the squares of the sides (e.g., $d^2=x^2+y^2+z^2$). In 2 dimensions, this is done by\n\n$$a^2+b^2=c^2 \\leftrightarrow x^2+y^2=r^2$$\nBut if we wanted to find the distance from some point that isn't the origin, we use\n$$r^2=\\left(x-x_0\\right)^2+\\left(y-y_0\\right)^2$$\nwhere $x,\\,y$ are the positions of the point and $x_0,\\,y_0$ the reference position. In the subsequent discussion, $x_0=y_0=0$.\nIn 3D, we can actually do the above 2D slice twice. Solve for $r$ in the $x$-$y$ plane and then solve for $d$ in the $r$-$z$ plane (using $x=a$, $y=b$, and $z=c$):\n$$\nr^2=a^2+b^2\\to r=\\sqrt{a^2+b^2}\n$$\n$$\nd^2=r^2+c^2\\to d^2=\\left(\\sqrt{a^2+b^2}\\right)^2+c^2=a^2+b^2+c^2\n$$\nWe could also have done this in the $y$-$z$ plane first:\n$$\nr^2=b^2+c^2\\to r=\\sqrt{b^2+c^2}\n\\\\\nd^2=r^2+a^2\\to d^2=\\left(\\sqrt{b^2+c^2}\\right)^2+a^2=a^2+b^2+c^2\n$$\nso clearly the ordering of it doesn't matter, we get $d=\\sqrt{a^2+b^2+c^2}$ as the distance from the origin to the point $P$ when doing it both ways.\nNext, what happens if we let $y=b\\to y=-b$? Since we take the square of $y$, we get $y^2=\\left(-b\\right)^2=+b^2$ which doesn't change anything, our distance is still $d=\\sqrt{a^2+b^2+c^2}$. The same thing happens if we swap the other values for their negatives. That means that there are at least 8 points $P$ that have identical distances from the origin.\nLet's try using some values, just to get an idea here. Suppose we let $\\mathbf{P}=\\left(1,2,2\\right)$. The distance $d$ is then\n$$d=\\sqrt{1^2+2^2+2^2}=\\sqrt{1+4+4}=\\sqrt{9}=3$$\nIf we consider a sphere with constant radius (i.e., $d$ does not change), then if we change $x=1\\to x=0$ we must have that \n$$\\sqrt{y^2+z^2}=3$$\n Obviously $y=z=3=d$ is not a solution because \n$$\\sqrt{3^2+3^2}=\\sqrt{9+9}=\\sqrt{18}>4>d$$\nEqually as well, $x=y=z=3=d$ is not a valid solution because\n$$\\sqrt{3^2+3^2+3^2}=\\sqrt{9+9+9}=\\sqrt{27}>5>d$$\nSo clearly $x,\\,y,\\,z$ are not also the radius. Individually, the values could be the radius, but that would require the other two values being zero:\n$$\\sqrt{3^2+0^2+0^2}=\\sqrt{9+0+0}=\\sqrt{9}=3=d$$\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/94071", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 2, "answer_id": 0}}
{"Q": "How can one prove the equation for a system of lenses? Let's say we have a system of 2 lenses which are placed in a non-negligible distance $L$ from eachother. \nHow can I prove without using geometrical construction and principal planes that\n$$\\frac 1f = \\frac {1}{f_1} + \\frac {1}{f_2} -\\frac{L}{f_1 f_2} $$\ndescribes the system's focal length?\n\nFor example, with $ L \\lt \\lt f_1f_2 $ :\n$\\dfrac{1}{f_1} = \\dfrac{1}{o_1} + \\dfrac{1}{i_1}$ where $o_1$ is the object distance and $i_1$ the image distance of the first lens. \nAnd of course, $\\dfrac{1}{f_2} = \\dfrac{1}{o_2} + \\dfrac{1}{i_2}$ .\nNow you can say the image of the first lense is the object distance of the second length (with paying attention to conventions what is negative and what positive):\n$o_2 = -i_1$ \nUsing this relation one receives $\\dfrac{1}{o_1} + \\dfrac{1}{i_2} = \\dfrac{1}{f_1} + \\dfrac{1}{f_2}  = \\dfrac{1}{f}$ \n\nI already tried saying $o_2 = -i_1 + L$ but this didn't lead anywhere.\n", "A": "Use ray transfer matrices. The system matrix is given by\n$$\nS=\\begin{pmatrix}\n1 & 0 \\\\\n-\\frac{1}{f_2} & 1 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n        1 & L \\\\\n        0 & 1 \\\\\n        \\end{pmatrix}\n\\begin{pmatrix}\n        1 & 0 \\\\\n        -\\frac{1}{f_1} & 1 \\\\\n        \\end{pmatrix}\n$$\nThe back focal length $BFL$ is determined by the point where all the rays in an incoming collimated beam meet after the second lens:\n$$\n\\begin{pmatrix}\n        1 & BFL \\\\\n        0 & 1 \\\\\n        \\end{pmatrix}\nS\n\\begin{pmatrix}\n        z \\\\\n        0  \\\\\n        \\end{pmatrix}\n=\n\\begin{pmatrix}\n        0 \\\\\n        \\text{X}  \\\\\n        \\end{pmatrix}\n$$\nfor all $z$. Solve for $BFL$ and then find $f$ by adding the distance of the second lens to the origin of coordinates. The origin is not arbitrary, it is chosen to a specific point on purpose in order to give a neat symmetric expression.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/199966", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 2, "answer_id": 1}}
{"Q": "Angles in a static equilibrium I have three masses $\\left(F_\\alpha, \\, F_\\beta , \\, \\text{and}  \\,F_g \\right)$ with 2 pulleys, and a wind variable which is in static equilibrium. I have already calculated the appropriate forces for the 3 masses by multiplying it with $9.81 \\, \\frac{\\mathrm{m}}{\\mathrm{s}^{2}}$ (gravity). \n$$\n\\begin{alignat}{7}\n& F_{\\text{wind}} && ~=~ & 60 \\phantom{.0} & \\, \\mathrm{N}  \\\\[2px]\n& F_{\\alpha} && = & 313.9 & \\, \\mathrm{N} \\\\[2px]\n& F_{\\beta} && = & 619 \\phantom{.0} & \\, \\mathrm{N} \\\\[2px]\n& F_{g} && = & 882.9 & \\, \\mathrm{N} \\\\\n\\end{alignat}\n$$\nI'm required to find the angles for vector $F_\\alpha$ and $F_\\beta$ as shown in below equations (which is derived from the vector's individual components ($x$ and $y$):\n$$\n\\begin{alignat}{7}\nF_\u03b1 \\, \\cos{\\left( \u03b1 \\right)} & \\, + \\, F_\u03b2 \\, \\cos {\\left( \u03b2 \\right)} && + F_\\text{wind} & ~=~ 0  \\tag{1} \\\\[2px]\nF_\u03b1 \\, \\sin{\\left(\u03b1\\right)} & \\, + \\, F_\u03b2 \\, \\sin {\\left( \u03b2 \\right)} && - F_g & ~=~ 0  \\tag{2}\n\\end{alignat}\n$$\nReplacing these with actual values: \n- 313.9cos \u03b1 + 619cos \u03b2 + 60 = 0  \u2014 (1)\n 313.9sin \u03b1 + 619sin \u03b2 - 882.9 = 0  \u2014 (2)\n\nHow do I find the angle \u03b1 & \u03b2 from these two equations?\nEdit 2:\n\nI have re-organized the equation and square it as such:\ncos\u00b2a = (619\u00b2 cos\u00b2\u03b2 + 60\u00b2 + 2(619cos\u03b2 * 60)) / 313.9\u00b2\nsin\u00b2a = (619\u00b2 sin\u00b2\u03b2 + 882.9\u00b2 - 2(619sin\u03b2 * 882.9)) / 313.9\u00b2\n", "A": "You can eliminate the angle $\\alpha$ from the equations with the trick the other answers give you *. But then you will end up with an equation of the form\n$$ A \\cos \\beta + B \\sin \\beta + C = 0$$\nTo solve this do the following transformation\n$$ \\left. \\begin{align}\n  A & = R \\cos \\psi \\\\\n  B & = R \\sin \\psi \n\\end{align} \\right\\} \n\\begin{aligned} \n  R & = \\sqrt{A^2+B^2} \\\\\n  \\psi & = \\arctan\\left( \\frac{B}{A} \\right) \n\\end{aligned}  $$\nThe equation is now $$ \ncos\\beta\\cos\\psi + \\sin\\beta \\sin\\psi = \\cos(\\beta-\\psi) = -\\frac{C}{R} $$\nwhich is solved for\n$$ \\begin{split} \\beta & = \\arccos\\left( -\\frac{C}{R} \\right) + \\psi \\\\\n & = \\arccos\\left( -\\frac{C}{\\sqrt{A^2+B^2}} \\right) + \\arctan\\left( \\frac{B}{A} \\right)\\end{split}$$\nfootnotes:\n\n\n*\n\n*make the equations of this form \n$$\\begin{align} \n  \\cos \\alpha & = a \\cos\\beta+c_x \\\\\n  \\sin \\alpha & = -a \\sin \\beta + c_y \n\\end{align}$$\n\n*square both sides and add them for\n$$ 1 =  2 a c_x \\cos\\beta - 2 a c_y \\sin\\beta + c_x^2 + c_y^2 +a^2 $$\n$$ \\left(2 a c_x\\right) \\cos\\beta + \\left(- 2 a c_y\\right) \\sin\\beta + \\left(c_x^2 + c_y^2 +a^2-1\\right) = 0 $$\n\n*Match the $A$, $B$ and $C$ coefficients.\n\n*Once $\\beta$ is known, then divide the two equations above for $$ \\tan \\alpha = \\frac{c_y - a \\sin\\beta}{c_x + a \\cos\\beta} $$\n\n\nEdit 1\nHere is the actual solution:\n$$\\left. \\begin{align}\n  -313.9 \\cos(\\alpha) + 619 \\cos(\\beta) + 60 & = 0 \\\\\n   313.9 \\sin(\\alpha)  + 619 \\sin(\\beta) - 882.9 & = 0 \n\\end{align} \\right\\} \\begin{aligned}\n   313.9 \\cos(\\alpha) & = 619 \\cos(\\beta) + 60 \\\\\n   313.9 \\sin(\\alpha)  & = - 619 \\sin(\\beta) + 882.9\n\\end{aligned} $$\nSquare and add the two equations (on each side) to get \n$$ \\left. 98533.21 = 74280 \\cos(\\beta) - 1093030.2 \\sin(\\beta) + 1166273.41 \\right\\}\\\\ 74280 \\cos(\\beta) - 1093030.2 \\sin(\\beta) + 1067740.2 = 0 $$\n$$ \\begin{aligned} \\beta & = \\arccos\\left( -\\frac{C}{\\sqrt{A^2+B^2}} \\right) + \\arctan\\left( \\frac{B}{A} \\right) \\\\\nA & = 74280\\\\\nB & = -1093030.2 \\\\\nC & = 1067740.2\\\\\n\\beta &= 1.41284652 = 80.9501426\u00b0 \\\\ \\end{aligned} $$\nFinally, $\\alpha$ can be solved with the 2nd equation:\n$$ \\sin(\\alpha) = 2.81267919-1.97196559 \\sin(\\beta) $$\n$$ \\alpha = 1.04567064 = 59.9125144\u00b0 $$\nNow you can plug the values of $\\alpha$ and $\\beta$ into the two original equations to confirm it balances the forces.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/240532", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "2", "answer_count": 2, "answer_id": 0}}
{"Q": "Oscillation of non-uniform plank on parallel springs A plank of length $l$ and mass $m$ is placed on two parallel springs, each with spring constant $k$ and equidistant from the plank's horizontal center of gravity. When the plank is displaced from it's equilibrium position, it's expected to oscillate at this frequency:\n$$ f = \\frac{1}{2\\pi}\\sqrt{\\frac{2k}{m}} $$ \nNow, if the plank isn't of uniform density, such that at equilibrium, the force acting on spring 1 is $amg$ and that on spring 2 is $bmg$ where $a + b = 1$. At what frequency will the plank oscillate at when it's displaced from its equilibrium position?\nIs it possible to obtain an estimate of its horizontal center of gravity at equilibrium (or rather, constants $a$, $b$) by observing the oscillations, say by taking a fourier transform of the plank's oscillation waveform?\n", "A": "First you decided on the independent degrees of freedom. I choose the center of the plank and I track the translation $x$ and rotation $\\theta$ from the equilibrium conditions. \nThe displacements of each spring are:\n$$\\begin{align}\n  x_1 & = x - \\frac{\\ell}{2} \\theta \\\\\n  x_2 & = x + \\frac{\\ell}{2} \\theta\n\\end{align} $$\nEach spring force is:\n$$\\left. \\begin{align}\n  F_1 & = a m g - k x_1 \\\\\n  F_2 & = b m g - k x_2\n\\end{align} \\right\\} \n\\begin{aligned}\n  F_1 & = a m g + \\frac{\\ell}{2} k \\theta - k x \\\\\n  F_2 & = b m g - \\frac{\\ell}{2} k \\theta - k x\n\\end{aligned}$$\nThe displacement of the center of mass is $x_C = x + \\frac{\\ell}{2} (b-a) \\theta$ and hence the center of mass acceleration (needed for the equations of motion) is $ \\ddot{x}_C = \\ddot{x} + \\frac{\\ell}{2} (b-a) \\ddot{ \\theta}$. \nThe EOM are:\n$$\\begin{align}\n  m \\ddot{x}_C & = F_1 + F_2 - m g \\\\\n  I_C \\ddot{\\theta} & = a \\ell F_1 - b \\ell F_2\n\\end{align} $$\nwhere $I_C$ is the mass moment of inertia about the center of mass. The above is solved by $x(t) = X \\sin \\omega t$ and $\\theta(t) = \\Theta \\sin \\omega t$. This produces the system of equations of\n$$ \\begin{align}\n  2 k X & = m \\omega^2 \\left( X + \\Theta \\frac{\\ell}{2} (b-a) \\right) \\\\\n  k X \\ell (a-b) + k \\frac{\\ell^2}{2} \\Theta (a+b) & = I_C \\Theta \\omega^2\n\\end{align} $$\nThis has two solutions for frequency $\\omega_T$ and $\\omega_R$ for translational and rotational modes of vibration. \nThe two degrees of freedom are coupled with\n$$ -\\frac{X}{\\Theta} = \\frac{\\frac{\\ell}{2} m \\omega^2 (a-b)}{ (2k-m \\omega^2)}$$\nThe left hand side of this equation is the center of rotation position (distance) from the center of the plank. Pure translation occurs when $\\omega^2 = 2 \\frac{k}{m}$ and pure rotation when $a=b$.\n$$\\begin{align}\n  \\omega^2_T & = \\frac{k}{m} \\left(1+ \\frac{m \\ell^2 (1-2 a b)}{2 I_C} + \\sqrt{ 1 + \\left( \\frac{m \\ell^2 (1-2 a b)}{2 I_C} \\right)^2 - \\frac{2 a b m \\ell^2}{I_C} } \\right) \\\\\n  \\omega^2_R & = \\frac{k}{m} \\left(1+ \\frac{m \\ell^2 (1-2 a b)}{2 I_C} - \\sqrt{ 1 + \\left( \\frac{m \\ell^2 (1-2 a b)}{2 I_C} \\right)^2 - \\frac{2 a b m \\ell^2}{I_C} } \\right)\n\\end{align} $$\nEdit 1\nTo estimate $a$ $b$ from the resulting motion, maybe you can solve the equations of motion using the normalized frequency $n^2 = \\frac{\\omega^2}{2 k/m}$ and center of rotation location $r=-\\frac{X}{\\Theta}$.\n$$ \\begin{align}\n  a &= \\frac{2 I_C n^2}{m \\ell^2} + \\frac{ r (1-n^2) (2 r+\\ell)}{n^2 \\ell^2} \\\\\n  b &= \\frac{2 I_C n^2}{m \\ell^2} + \\frac{ r (1-n^2) (2 r-\\ell)}{n^2 \\ell^2} \n\\end{align} $$\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/242757", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
{"Q": "What is the 4-dimensional matrix representation of rotation operator? The rotation operator is $$\\exp\\left(-i\\frac{\\theta}{2}\\boldsymbol{J}\\cdot\\hat{\\boldsymbol{n}}\\right).$$ \n\n\n*\n\n*If $\\boldsymbol{\\sigma}$ is the Pauli matrix, the operator can be written as a matrix form $$\\boldsymbol{1}\\cos(\\phi/2)-i\\boldsymbol{\\sigma}\\cdot\\hat{\\boldsymbol{n}}\\sin(\\phi/2).$$ \n\n*But when $J$ is the spin-3/2 operator, $J$ is 4-dimensional. Is there a matrix representation of operator $\\exp\\left(-i\\frac{\\theta}{2}\\boldsymbol{J}\\cdot\\hat{\\boldsymbol{n}}\\right)$? I find that when $\\{J_x,J_y\\}\\neq0$ for spin-3/2, not like Pauli matrices. \n\n*What is the case when $J$ is spin-1 operator?\n", "A": "There are several ways to proceed.  \nFirst, be aware that Mathematica has a built-in function called WignerD\nand this function will give you the matrix element of a rotation matrix.  I have found that this function does not seem to use the same parametrization as Varshalovich, Dmitri\u012d Aleksandrovich, Anatolij Nikolaevi\u010d Moskalev, and Valerii Kel'manovich Khersonskii. Quantum theory of angular momentum. 1988., which in my opinion remains the bible.  It seems you need to use the negative of all the angles in WignerD  to obtain the formulas of Varshalovich.\nThere are various closed form expressions for \n\\begin{align}\nd^j_{mm'}(\\beta)&:= \\langle jm\\vert R_y(\\beta)\\vert jm'\\rangle \\, \n\\end{align}\nsuch as\n\\begin{align}\nd^j_{mm'}(\\beta)&=(-1)^{j-m'} \n\\sqrt{(j+m)!(j-m)!(j+m')!(j-m')!}\\\\\n&\\times \\sum_k (-1)^k\n\\frac{\\left(\\cos\\frac{1}{2}\\beta\\right)^{m+m'+2k}\n\\left(\\sin\\frac{1}{2}\\beta\\right)^{2j-m-m'-2k}}\n{k!(j-m-k)!(j-m'-k)!(m+m'+k)!}\\, .\n\\end{align}\nThere is also an expression in terms of Jacobi polynomials:\n\\begin{align}\nd^j_{mm'}(\\beta)&=\\xi_{mm'} \n\\sqrt{\\frac{s!(s+\\mu+\\nu)!}{(s+\\mu)!(s+\\nu)!}}\n\\left(\\sin\\textstyle\\frac{1}{2}\\beta\\right)^\\mu\n\\left(\\cos\\textstyle\\frac{1}{2}\\beta\\right)^\\nu\nP_s^{\\mu,\\nu}(\\cos\\beta)\n\\end{align}\nwith \n$$\n\\mu=\\vert m-m'\\vert\\, ,\\quad\n\\nu=\\vert m+m'\\vert\\, ,\\quad\ns=j-\\frac{1}{2}(\\mu+\\nu)\n$$\nand the phase \n$$\n\\xi_{mm'}=\\left\\{\\begin{array}{cc}\n1&\\quad \\hbox{if } m'\\ge m\\, \\\\\n(-1)^{m'-m}&\\quad \\hbox{if } m'<m\\, .\\end{array}\\right.\n$$\nFinally, there is a method based on recursion relations.  This is described in details in Wolters, G. F. \"Simple method for the explicit calculation of d-functions.\" Nuclear Physics B 18.2 (1970): 625-653. Starting with \n$$\n\\langle jm\\vert R_y(\\beta) L_x\\vert jm'\\rangle\n$$\none can obtain a recursion relation \n\\begin{align}\n&\\sqrt{(j-m')(j+m'+1)}d^j_{m,m'+1}(\\beta)\n+\\sqrt{(j+m')(j-m'+1)}d^j_{m,m'-1}(\\beta)\\\\\n&\\qquad = 2\\hbox{cosec}(\\beta)(m'\\cos\\beta-m)d^j_{mm'}(\\beta)\n\\end{align}\nThe function\n\\begin{align}\nd^j_{mj}(\\beta)&={2j \\choose j+m}^{1/2}\n\\left(\\cos\\textstyle\\frac{1}{2}\\beta\\right)^{j+m}\n\\left(\\sin\\textstyle\\frac{1}{2}\\beta\\right)^{j-m}\\, ,\\\\\n\\end{align}\ncan be used as a seed for the recursion.\nAs a matrix with elements $d^{3/2}_{mm'}(\\beta)$, the explicit results for $j=3/2$ is\n\\begin{align}\n&R_y(\\beta)=\\\\\n&{\\scriptsize\\left(\n\\begin{array}{cccc}\n \\cos ^3\\left(\\frac{\\beta }{2}\\right) & -\\sqrt{3} \\cos ^2\\left(\\frac{\\beta }{2}\\right) \\sin \\left(\\frac{\\beta }{2}\\right) & \\sqrt{3} \\cos \\left(\\frac{\\beta\n   }{2}\\right) \\sin ^2\\left(\\frac{\\beta }{2}\\right) & -\\sin ^3\\left(\\frac{\\beta }{2}\\right) \\\\\n \\sqrt{3} \\cos ^2\\left(\\frac{\\beta }{2}\\right) \\sin \\left(\\frac{\\beta }{2}\\right) & \\frac{1}{2} \\cos \\left(\\frac{\\beta }{2}\\right) (3 \\cos (\\beta )-1) &\n   -\\frac{1}{2} (3 \\cos (\\beta )+1) \\sin \\left(\\frac{\\beta }{2}\\right) & \\sqrt{3} \\cos \\left(\\frac{\\beta }{2}\\right) \\sin ^2\\left(\\frac{\\beta }{2}\\right) \\\\\n \\sqrt{3} \\cos \\left(\\frac{\\beta }{2}\\right) \\sin ^2\\left(\\frac{\\beta }{2}\\right) & \\frac{1}{2} (3 \\cos (\\beta )+1) \\sin \\left(\\frac{\\beta }{2}\\right) &\n   \\frac{1}{2} \\cos \\left(\\frac{\\beta }{2}\\right) (3 \\cos (\\beta )-1) & -\\sqrt{3} \\cos ^2\\left(\\frac{\\beta }{2}\\right) \\sin \\left(\\frac{\\beta }{2}\\right) \\\\\n \\sin ^3\\left(\\frac{\\beta }{2}\\right) & \\sqrt{3} \\cos \\left(\\frac{\\beta }{2}\\right) \\sin ^2\\left(\\frac{\\beta }{2}\\right) & \\sqrt{3} \\cos ^2\\left(\\frac{\\beta\n   }{2}\\right) \\sin \\left(\\frac{\\beta }{2}\\right) & \\cos ^3\\left(\\frac{\\beta }{2}\\right) \\\\\n\\end{array}\n\\right)}\n\\end{align}\nwith the columns and rows ordered as $3/2,1/2,-1/2,-3/2$.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/313973", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 3, "answer_id": 2}}
{"Q": "A small error in Landau & Lifschitz \"Mechanics\" (3rd ed.)? I think I found a small error in Landau & Lifschitz \"Mechanics\" (3rd ed.). In section 28 (Anharmonic oscillations), they are discussing how to solve the following anharmonic oscillator problem:\n\n$$\\ddot{x}+\\omega_0^2 x = -\\alpha x^2-\\beta x^3 \\tag{28.9}$$\n\nThey show how one can solve the anharmonic oscillator problem perturbatively by expanding the solution in powers of the initial amplitude $a$ and supposing that the fundamental frequency is also shifted, the shift being given by another power series in the amplitude. The ansatz for the lowest-order solution is the following:\n\n$$x^{(1)}=a\\cos \\omega t \\tag{28.10}$$\n\nOne can grind out the higher order equations and arrive at the equation for the 3rd order perturbation:\n\n$$\\ddot{x}^{(3)}+\\omega_0^2 x^{(3)}=-2\\alpha x^{(1)}x^{(2)}-\\beta x^{(1)3}+2\\omega_0 \\omega ^{(2)} x^{(1)}\\tag{pg. 87}$$\n\nNow, first I want to mention that in that equation we have $\\beta x^{(1)3}$ which we can write out as\n$$\\begin{align}\\beta x^{(1)3}&=\\beta a^3\\cos^3\\omega t\\\\\n&=a^3\\left(\\color{red}{\\frac{1}{4}\\beta} \\cos 3\\omega t \\color{red}{+ \\frac{3}{4}\\beta} \\cos \\omega t\\right)\n\\end{align}$$\nBut in the next line the following full expansion is given (where I highlight the error in red):\n\n$$\\begin{align}\n\\ddot{x}^{(3)}+\\omega_0^2 x^{(3)}=a^3&\\left[\\color{red}{\\frac{1}{4}\\beta}-\\frac{\\alpha^2}{6\\omega_0^2}\\right]\\cos 3\\omega t +\\\\\n&+a\\left[2\\omega_0\\omega^{(2)}+\\frac{5a^2\\alpha^2}{6\\omega_0^2}\\color{red}{- \\frac{3}{4}a^2\\beta}\\right]\\cos\\omega t \\tag{pg. 87}\\end{align}$$\n\nSo the it looks like a spurious minus sign has entered, which carries on throughout the rest of the section. \n[Question]: Is this actually a mistake? I can't find any errata for the book so I can't validate this.\n", "A": "I think there are more problems with this solution. Especially with perturbation theory. For this kind of problems one has to use Poincare-Lindstedt method [1] [2]. The small parameters in the former differential equations are $\\alpha$ and $\\beta$ so we can write down (the same can done for $\\beta$):\n$$\\ddot{x} + \\omega_0^2x = -\\alpha\\left(x^2+\\frac{\\beta}{\\alpha}x^3 \\right).$$\nHere $\\alpha$ will be our small parameter and we are looking for a solution of the form \n$$x(t) = A\\cos(\\omega t) + \\alpha x_1(t) + \\alpha^2x_2(t) + \\ldots$$\n$$\\omega = \\omega_0 + \\alpha\\omega_1 + \\alpha^2\\omega_2 + \\ldots$$\nwith initial conditions $x(0)=A$ and $\\dot{x}(0)=0$. \nFirst of all, we change variables $\\tau = \\omega t$, so that we get\n$$\\omega^2 x''+ \\omega^2_0 x = -\\alpha\\left(x^2 + \\frac{\\beta}{\\alpha}x^3 \\right),$$\nwhere $x''$ denotes second derivative over $\\tau$. We put our series formula for $x$ and $\\omega$ and extract terms in the same order of $\\alpha$:\n$$\\left[ \\omega_0^2 + 2\\omega_0\\omega_1 \\alpha + \\alpha^2 (\\omega_1^2 + 2\\omega_0\\omega_2) + \\ldots \\right] \\cdot \\left[-A\\cos\\tau + \\alpha x''_1 + \\alpha^2 x''_2 + \\ldots \\right] + \\omega_0^2 \\left[A\\cos\\tau + \\alpha x_1 + \\alpha^2 x_2 + \\ldots \\right] = -\\alpha \\left[A^2\\cos^2\\tau + 2\\alpha x_1 A\\cos\\tau + \\frac{\\beta}{\\alpha}\\left(A^3\\cos^3\\tau + 3\\alpha x_1 A^2\\cos^2\\tau \\right) + \\ldots \\right]$$\n1st order terms\n$$\\begin{align}\nx''_1 + x_1 & = \\frac{2A\\omega_1}{\\omega_0}\\cos\\tau - \\frac{A^2}{\\omega^2_0}\\cos^2\\tau - \\frac{\\beta}{\\alpha}\\frac{A^3}{\\omega_0^2}\\cos^3\\tau \\\\\n& = \\cos\\tau\\left[\\frac{2A\\omega_1}{\\omega_0}-\\frac{\\beta}{\\alpha}\\frac{3 A^3}{4\\omega_0^2}\\right] - \\frac{1}{2}\\frac{A^2}{\\omega_0^2} - \\frac{1}{2}\\frac{A^2}{\\omega_0^2}\\cos 2\\tau - \\frac{1}{2}\\frac{\\beta}{\\alpha}\\frac{A^3}{\\omega_0^2}\\cos 3\\tau,\n\\end{align}\n$$\nwith $x_1(0)=0$ and $x'_1(0)=0$. If we want to kill the resonant term (the one with $\\cos\\tau$) we need to set \n$$\\omega_1 = \\frac{\\beta}{\\alpha}\\frac{3}{8}\\frac{A^2}{\\omega_0}.$$\nThen $x_1(\\tau)$ solves to\n$$x_1(\\tau) = \\frac{A^2}{\\omega_0^2}\\left[-\\frac{1}{2} + \\left(\\frac{1}{3} - \\frac{1}{16}\\frac{\\beta}{\\alpha}A\\right)\\cos\\tau + \\frac{1}{6}\\cos 2\\tau + A\\frac{1}{16}\\frac{\\beta}{\\alpha}\\cos 3\\tau \\right].$$\n2nd order terms\n$$x_2'' + x_2 = \\frac{A}{\\omega_0^2}(\\omega_1^2 + 2\\omega_0\\omega_2)\\cos\\tau - 2\\frac{\\omega_1}{\\omega_0}x''_1 - x_1\\frac{2A}{\\omega_0^2}\\cos\\tau- x_1\\frac{\\beta}{\\alpha}\\frac{3A^2}{\\omega_0^2}\\cos^2\\tau,$$\nwith $x_2(0)=0$ and $x'_2(0)=0$. This is a real mess which I am not going to post here, but\n$$\\omega_2 = \\frac{A^2}{\\omega_0^3}\\left[\\frac{A}{4}\\frac{\\beta}{\\alpha}-\\frac{3A^2}{64}\\left(\\frac{\\beta}{\\alpha}\\right)^2-\\frac{3A^2}{64}-\\frac{5}{12}\\right]$$\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/367204", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "3", "answer_count": 1, "answer_id": 0}}
{"Q": "Covariant Maxwell equations invariant under parity transformation I tried to proof that the Maxwell equations are invariant under parity transformations. Therefore I used the covariant formulation of the Maxwell equations \n\\begin{align}\n\\partial_{\\nu}F^{\\nu\\mu} &= \\frac{4\\pi}{c}j^{\\mu}\\\\\n\\partial_{\\nu}\\tilde{F}^{\\nu\\mu} &= 0\n\\end{align}\nand the parity transformation given by \n\\begin{align}\nP = \\begin{pmatrix} 1 & 0 & 0 & 0  \\\\ 0 & -1 & 0 & 0 \\\\ 0 & 0 & -1 & 0 \\\\ 0 & 0 & 0 & -1 \\end{pmatrix}\n\\end{align}\nRegarding only the first equation $\\partial_{\\nu}F^{\\nu\\mu} = \\frac{4\\pi}{c}j^{\\mu}$ we have\n\\begin{align}\n\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\cdot \\begin{pmatrix} \\frac{1}{c}\\frac{\\partial}{\\partial \\text{t}} \\\\ \\vec{\\nabla} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{c}\\frac{\\partial}{\\partial \\text{t}} \\\\ -\\vec{\\nabla} \\end{pmatrix} \n\\end{align}\nas well as \n\\begin{align}\n\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\cdot \\begin{pmatrix} c\\rho \\\\ \\vec{j} \\end{pmatrix} = \\begin{pmatrix} c\\rho \\\\ -\\vec{j} \\end{pmatrix} \n\\end{align}\nand \n\\begin{align}\nP \\cdot F^{\\nu\\mu} &= \\begin{pmatrix} 1 & 0 & 0 & 0  \\\\ 0 & -1 & 0 & 0 \\\\ 0 & 0 & -1 & 0 \\\\ 0 & 0 & 0 & -1 \\end{pmatrix}\\begin{pmatrix} 0 & -E^1 & -E^2 & -E^3 \\\\ E^1 & 0 & -B^3 & B^2 \\\\ E^2 & B^3 & 0 & -B^1 \\\\ E^3 & -B^2 & B^1 & 0  \\end{pmatrix} = \\begin{pmatrix} 0 & -E^1 & -E^2 & -E^3 \\\\ -E^1 & 0 & B^3 & -B^2 \\\\ -E^2 & -B^3 & 0 & B^1 \\\\ -E^3 & B^2 & -B^1 & 0  \\end{pmatrix}\n\\end{align}\nBased on these calculations, is there a way to see that Maxwell equations are invariant under parity transformations and if so how do I see it? \n", "A": "As current is a vector, it is not invariant under parity. Therefore neither is Amp\u00e8re's law. \n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/459639", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 2, "answer_id": 1}}
{"Q": "Derivation of the Electromagnetic Stress-Energy Tensor in Flat Space-time I am working on deriving the electromagnetic stress energy tensor using the electromagnetic tensor in the $(-, +, +, +)$ sign convention. However, I have hit a snag and cannot figure out where I have gone wrong.\n$$ F^{\\mu \\alpha}= \n    \\begin{bmatrix}\n    0 & \\frac{E_{x}}{c} & \\frac{E_{y}}{c} & \\frac{E_{z}}{c} \\\\\n    -\\frac{E_{x}}{c} & 0 & B_{z} & -B_{y} \\\\\n    -\\frac{E_{y}}{c} & -B_{z} & 0 &  B_{x} \\\\\n    -\\frac{E_{z}}{c} & B_{y} & -B_{x} & 0 \\\\\n    \\end{bmatrix}\n$$\n$$\nF^{\\mu}_{\\alpha} = \n    \\begin{bmatrix}\n    0 & \\frac{E_{x}}{c} & \\frac{E_{y}}{c} & \\frac{E_{z}}{c} \\\\\n    \\frac{E_{x}}{c} & 0 & B_{z} & -B_{y} \\\\\n    \\frac{E_{y}}{c} & -B_{z} & 0 &  B_{x} \\\\\n    \\frac{E_{z}}{c} & B_{y} & -B_{x} & 0 \\\\\n    \\end{bmatrix}\n$$\n$$ T^{\\mu\\nu} = \\frac{1}{\\mu_0}(F^{\\mu \\alpha}F^{v}_{\\alpha} - \\frac{1}{4}\\eta^{\\mu\\nu}F_{\\alpha\\beta}F^{\\alpha \\beta})$$\nDoing matrix multiplication of the matrices $F^{\\mu \\alpha}$ and $F^{\\nu}_{\\alpha}$ from above gives\n$$\nF^{\\mu \\alpha}F^{\\nu}_{\\alpha} =\n \\begin{bmatrix}\n (\\frac{E}{c})^{2} & -B_{z}\\frac{E_{y}}{c} + B_{y}\\frac{E_{z}}{c}  & \\frac{E_{x}}{c}B_{z} - \\frac{E_{z}}{c}B_{x} & -\\frac{E_{x}}{c}B_{y} + \\frac{E_{y}}{c}B_{x} \\\\\n B_{z}\\frac{E_{y}}{c} - B_{y}\\frac{E_{z}}{c} & -B_{z}^{2} - B_{y}^{2} - (\\frac{E_{x}}{c})^{2} & -\\frac{E_{x}}{c}\\frac{E_{y}}{c} + B_{y}B_{x} & \\frac{E_{x}}{c}\\frac{E_{z}}{c} + B_{z}B_{x} \\\\\n -B_{z}\\frac{E_{x}}{c} + B_{x}\\frac{E_{z}}{c} & -\\frac{E_{y}}{c}\\frac{E_{x}}{c} + B_{x}B_{y} & -(\\frac{E_{y}}{c})^{2}-B_{z}^{2}-B_{x}^{2} & -\\frac{E_{y}}{c}\\frac{E_{z}}{c} + B_{z}B_{y} \\\\\n B_{y}\\frac{E_{x}}{c} - B_{x}\\frac{E_{y}}{c} & -\\frac{E_{z}}{c}\\frac{E_{x}}{c} + B_{x}B_{z} & -\\frac{E_{z}}{c}\\frac{E_{y}}{c} + B_{y}B_{z} & -(\\frac{E_{z}}{c})^{2}-B_{y}^{2}-B_{x}^{2} \\\\\n \\end{bmatrix}\n$$\nSubtracting the $\\frac{1}{4}\\eta^{\\mu\\nu}F_{\\alpha\\beta}F^{\\alpha\\beta}= \\frac{1}{4}\\eta^{\\mu\\nu}[2(B^{2} - (\\frac{E}{c})^{2})]$ and multiplying by $\\frac{1}{\\mu_{0}}$ gives\n$$ T^{\\mu\\nu}=\\frac{1}{\\mu_{0}}  \n   \\begin{bmatrix}\n (\\frac{E}{c})^{2} + \\frac{1}{2}(B^{2} - (\\frac{E}{c})^{2}) & -B_{z}\\frac{E_{y}}{c} + B_{y}\\frac{E_{z}}{c}  & \\frac{E_{x}}{c}B_{z} - \\frac{E_{z}}{c}B_{x} & -\\frac{E_{x}}{c}B_{y} + \\frac{E_{y}}{c}B_{x} \\\\\n B_{z}\\frac{E_{y}}{c} - B_{y}\\frac{E_{z}}{c} & -B_{z}^{2} - B_{y}^{2} - (\\frac{E_{x}}{c})^{2} - \\frac{1}{2}(B^{2} - (\\frac{E}{c})^{2}) & -\\frac{E_{x}}{c}\\frac{E_{y}}{c} + B_{y}B_{x} & \\frac{E_{x}}{c}\\frac{E_{z}}{c} + B_{z}B_{x} \\\\\n -B_{z}\\frac{E_{x}}{c} + B_{x}\\frac{E_{z}}{c} & -\\frac{E_{y}}{c}\\frac{E_{x}}{c} + B_{x}B_{y} & -(\\frac{E_{y}}{c})^{2}-B_{z}^{2}-B_{x}^{2} - \\frac{1}{2}(B^{2} - (\\frac{E}{c})^{2}) & -\\frac{E_{y}}{c}\\frac{E_{z}}{c} + B_{z}B_{y} \\\\\n B_{y}\\frac{E_{x}}{c} - B_{x}\\frac{E_{y}}{c} & -\\frac{E_{z}}{c}\\frac{E_{x}}{c} + B_{x}B_{z} & -\\frac{E_{z}}{c}\\frac{E_{y}}{c} + B_{y}B_{z} & -(\\frac{E_{z}}{c})^{2}-B_{y}^{2}-B_{x}^{2} - \\frac{1}{2}(B^{2} - (\\frac{E}{c})^{2}) \\\\\n \\end{bmatrix}\n$$\nHowever, the textbook definition of the electromagnetic stress energy tensor is:\n$$ T^{\\mu\\nu} =\n    \\begin{bmatrix}\n    \\frac{1}{2}(\\epsilon_{0} |E|^{2} + \\frac{1}{\\mu_{0}}|B|^{2}) & \\frac{S_{x}}{c} & \\frac{S_{y}}{c} & \\frac{S_{z}}{c} \\\\\n    \\frac{S_{x}}{c} & -\\sigma_{xx} & -\\sigma_{xy}  & -\\sigma_{xz} \\\\\n    \\frac{S_{y}}{c} & -\\sigma_{yx} & -\\sigma_{yy}  & -\\sigma_{yz} \\\\\n\\frac{S_{z}}{c} & -\\sigma_{zx} & -\\sigma_{zy} & -\\sigma_{zz} \\\\\n    \\end{bmatrix}\n$$\nwith $\\vec{S} = \\frac{1}{\\mu_{0}}(\\vec{E} \\times \\vec{B})$ and $\\sigma_{ij} = \\epsilon_{0} E_{i}E_{j} + \\frac{1}{\\mu_{0}}B_{i}B_{j} - \\frac{1}{2}(\\epsilon_{0} E^{2} + \\frac{1}{\\mu_{0}}B^{2})\\delta_{ij} $\nSo, I know my $T^{01} = T^{10}$, $T^{02} = T^{20}$, and $T^{03} = T^{30}$ but they do not. They are of opposite signs. What did I do incorrectly?\n", "A": "Ok...I have done a little more work and I think I have it.\nIf \n$$ F^{\\mu \\alpha}= \n    \\begin{bmatrix}\n    0 & \\frac{E_{x}}{c} & \\frac{E_{y}}{c} & \\frac{E_{z}}{c} \\\\\n    -\\frac{E_{x}}{c} & 0 & B_{z} & -B_{y} \\\\\n    -\\frac{E_{y}}{c} & -B_{z} & 0 &  B_{x} \\\\\n    -\\frac{E_{z}}{c} & B_{y} & -B_{x} & 0 \\\\\n    \\end{bmatrix}\n$$\nand\n$$ T^{mv} = \\frac{1}{\\mu_0}(F^{\\mu \\alpha}F^{\\nu}{}_{\\alpha} - \\frac{1}{4}\\eta^{\\mu\\nu}F_{\\alpha\\beta}F^{\\alpha \\beta})$$\nthen letting c = 1\n$$\nF^{\\mu \\alpha}F^{v}{}_{\\alpha} = \\eta_{\\beta\\alpha}F^{\\mu\\alpha}F^{\\nu\\beta}\n$$\nIf we let $\\mu = 0,1,2,3$, $\\nu = 0, 1, 2, 3$, and $\\alpha=\\beta$ summing over repeated indexes gives\nfor $\\mu = 0$ and $\\nu = 0$\n$$\n\\eta_{\\beta \\alpha}F^{0\\alpha}F^{0\\beta} = \\eta_{00}F^{00}F^{00}+\\eta_{11}F^{01}F^{01}+ \\eta_{22}F^{02}F^{02} + \\eta_{33}F^{03}F^{03} = E_{x}^{2} + E_{y}^{2} + E_{z}^{2}\n$$\nfor $\\mu = 1$ and $\\nu = 0$\n$$\n\\eta_{\\beta \\alpha}F^{1\\alpha}F^{0\\beta} = \\eta_{00}F^{10}F^{00}+\\eta_{11}F^{11}F^{01}+ \\eta_{22}F^{12}F^{02} + \\eta_{33}F^{13}F^{03} = B_{z}E_{y} - B_{y}E_{z}\n$$\nand so on...\nIs this correct? When looking at the indexes for the metric will $\\alpha=\\beta$ always be true when working in general relativity?\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/479331", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 2, "answer_id": 1}}
{"Q": "Current density $\\mathbf{J}$ of particle with magnetic dipole moment $\\mathbf{m}$ I'm solving some excercises on magnetostatics, and encounterded this on which i'm having some trouble. Given a particle of magnetic dipole moment $\\mathbf{m}$, show that its current density is given as $\\mathbf{J} = \\left( \\mathbf{m} \\times \\nabla \\right) \\delta \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right)$, where $\\mathbf{r}_{0}$ is the vector position of the particle.\nI started from the stationary Ampere's law, given that the magnetic field $\\mathbf{B}_{m}$ is due only by the magnetic dipole moment\n$$ \\nabla \\times \\mathbf{B}_{m} \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) = \\mu_{0} \\; \\mathbf{J} \\left( \\mathbf{r} \\right)$$\nSo that\n$$ \\boxed{\\mathbf{J} \\left( \\mathbf{r} \\right) = \\frac{1}{\\mu_{0}} \\nabla \\times \\mathbf{B}_{m} \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right)} \\; \\; \\; \\; (1)$$\nNow, it terms of the magnetic dipole moment, the corresponding magnetic field is given as\n$$ \\boxed{\\mathbf{B}_{m} \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) = \\frac{\\mu_{0}}{4\\pi} \\left[ \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) - \\frac{\\mathbf{m}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right]} \\; \\; \\; \\; (2) $$\nReplacing, then, (2) into (1)\n$$ \\mathbf{J}\\left( \\mathbf{r} \\right) = \\frac{1}{4 \\pi} \\nabla \\times \\left( \\frac{\\mu_{0}}{4\\pi} \\left[ \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) - \\frac{\\mathbf{m}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right] \\right) $$\n$$ = \\frac{1}{4 \\pi}  \\left[ \\nabla \\times \\left( \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) \\right) - \\nabla \\times \\left( \\frac{\\mathbf{m}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right) \\right] $$\n$$ = \\frac{1}{4 \\pi} \\left[ \\nabla \\left( \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\right) \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) + \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\nabla \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) \\right. $$\n$$ \\left. - \\nabla \\left( \\frac{\\mathbf{1}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right) \\times \\mathbf{m} - \\frac{\\mathbf{1}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\nabla \\times \\mathbf{m} \\right] $$\nNow, as $\\nabla \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right)=0$ and $\\nabla \\times \\mathbf{m}=0$\n$$ \\boxed{\\mathbf{J}\\left( \\mathbf{r} \\right) = \\frac{1}{4 \\pi} \\left[ \\nabla \\left( \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\right) \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) - \\nabla \\left( \\frac{\\mathbf{1}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right) \\times \\mathbf{m} \\right]} \\; \\; \\; \\; (3) $$\nNow, by components\n$$ \\left( \\nabla \\left[ \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\right] \\right)_{i} = \\partial_{i} \\left( \\frac{m_{j} (x_{j} - x^{0}_{j}) }{ [(x_{l} - x^{0}_{l})(x_{l} - x^{0}_{l})]^{5/2} } \\right)$$\n$$ = m_{j} \\left\\{ \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} \\partial_{i} (x_{j} - x^{0}_{j}) + (x_{j} - x^{0}_{j}) \\partial_{i} [(x_{l} - x^{0}_{l})(x_{l} - x^{0}_{l})]^{-5/2} \\right\\} $$\n$$ = m_{j} \\left\\{ \\frac{\\delta_{ij}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} - \\frac{5}{2}\\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {7}}2(x_{l} - x^{0}_{l})\\delta_{il}(x_{j} - x^{0}_{j}) \\right\\} $$\n$$ = m_{j} \\left\\{ \\frac{\\delta_{ij}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} - 5\\frac{(x_{i} - x^{0}_{i})(x_{j} - x^{0}_{j})}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {7}} \\right\\} $$\n$$ = \\frac{m_{i}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} - 5 \\frac{m_{j} (x_{j} - x^{0}_{j})}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {7}}(x_{i} - x^{0}_{i}) $$\n$$ \\boxed{\\left( \\nabla \\left[ \\frac{\\mathbf{m}\\cdot\\left(\\mathbf{r} - \\mathbf{r}_{0}\\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{5}} \\right] \\right)_{i} = \\left[ \\frac{\\mathbf{m}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} - 5 \\frac{\\mathbf{m} \\cdot (\\mathbf{r} - \\mathbf{r}_{0}) }{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {7}}(\\mathbf{r} - \\mathbf{r}_{0}) \\right]_{i}} \\; \\; \\; \\; (4) $$\nLikewise\n$$ \\left( \\nabla \\left[ \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right]  \\right)_{i} = \\partial_{i} [(x_{j} - x_{j}^{0})(x_{j} - x_{j}^{0})]^{-3/2} $$\n$$ = -\\frac{3}{2} \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}}2(x_{j} - x_{j}^{0})\\delta_{ij} $$\n$$ = -3 \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} (x_{i} - x_{i}^{0}) $$\n$$ \\boxed{\\left( \\nabla \\left[ \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right]  \\right)_{i} = \\left( -3 \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} (\\mathbf{r} - \\mathbf{r}_{0}) \\right)_{i}} \\; \\; \\; \\; (5) $$\nReplacing (4) and (5) into (3)\n$$ \\mathbf{J}\\left( \\mathbf{r} \\right) = \\frac{1}{4 \\pi} \\left[ \\left( \\frac{\\mathbf{m}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} - 5 \\frac{\\mathbf{m} \\cdot (\\mathbf{r} - \\mathbf{r}_{0}) }{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {7}}(\\mathbf{r} - \\mathbf{r}_{0}) \\right) \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) - \\left( -3 \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} (\\mathbf{r} - \\mathbf{r}_{0}) \\right) \\times \\mathbf{m} \\right] $$\nAnd, because $\\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) = 0$\n$$ \\mathbf{J}\\left( \\mathbf{r} \\right) = \\frac{1}{4 \\pi} \\left[ \\left( \\frac{\\mathbf{m}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} \\right) \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) + 3 \\frac{1}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} (\\mathbf{r} - \\mathbf{r}_{0}) \\times \\mathbf{m} \\right] $$\n$$ \\mathbf{J}\\left( \\mathbf{r} \\right) = \\frac{1}{4 \\pi} \\left(-2 \\left( \\frac{\\mathbf{m}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} \\right) \\times \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right)  \\right)$$\n$$ \\boxed{\\mathbf{J}\\left( \\mathbf{r} \\right) = -\\frac{1}{2 \\pi} \\mathbf{m} \\times \\frac{\\left( \\mathbf{r} - \\mathbf{r}_{0} \\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}}} $$\nHere is where i'm stuck. I'm aware of the identity\n$$ \\nabla \\cdot \\left[ \\frac{\\mathbf{r} - \\mathbf{r}_{0}}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^{3}} \\right] = 4 \\pi \\delta (\\mathbf{r} - \\mathbf{r}_{0})$$\nSo, assuming that the answer presented in the statement is true (and that my calculations were correct), then it must be true that\n$$ -\\frac{1}{2 \\pi} \\frac{\\left( \\mathbf{r} - \\mathbf{r}_{0} \\right)}{\\left| \\mathbf{r} - \\mathbf{r}_{0} \\right|^ {5}} = \\nabla \\delta \\left( \\mathbf{r} - \\mathbf{r}_{0} \\right) $$\nbut, if this is indeed true, i'm not sure how to prove this.\nThanks in advance for any help!\n", "A": "A Herculean effort. Well done. It looks correct though I had only a brief look. Griffiths (Introduction to Electrodynamics) has a quite nice section on 3d delta functions in Sec. 1.5\nThe trick with delta functions is that they only make sense inside the integral. You want to analyse $\\boldsymbol{\\nabla}.\\left(\\frac{\\mathbf{r}-\\mathbf{r}_0}{\\left|\\mathbf{r}-\\mathbf{r}_0\\right|^3}\\right)$. First, simplify it to:\n$$\\boldsymbol{\\nabla}.\\left(\\frac{\\mathbf{r}-\\mathbf{r}_0}{\\left|\\mathbf{r}-\\mathbf{r}_0\\right|^3}\\right)=\\boldsymbol{\\nabla}.\\left(\\frac{\\boldsymbol{r}}{\\left|\\boldsymbol{r}\\right|^3}\\right)\\bigg{|}_{\\boldsymbol{r}=\\mathbf{r}-\\mathbf{r}_0}$$\nNote, that since $\\mathbf{r}_0$ is constant, there is no difficulty in switching from $\\boldsymbol{\\nabla}$ with respect to $\\mathbf{r}$, to $\\boldsymbol{\\nabla}$ with respect to $\\boldsymbol{r}$. Next, evaluate expression for $\\boldsymbol{r}\\neq\\mathbf{0}$, you will find\n$$\\boldsymbol{\\nabla}.\\left(\\frac{\\boldsymbol{r}}{\\left|\\boldsymbol{r}\\right|^3}\\right)=0 \\mbox{ for } \\boldsymbol{r}\\neq\\mathbf{0}$$\nThis is a good start, if you are aiming to end up with a delta function. Next stick your candidate into an integral. Let $V$ be a sphere with radius $R$, and centre at $\\mathbf{r}_0$\n$$\\int_V d^3 r \\boldsymbol{\\nabla}.\\left(\\frac{\\boldsymbol{r}}{\\left|\\boldsymbol{r}\\right|^3}\\right)=\\oint_{\\partial V} d^2\\, r\\boldsymbol{\\hat{r}}.\\frac{\\boldsymbol{r}}{\\left|\\boldsymbol{r}\\right|^3}=\\oint_{\\partial V} d^2\\, r \\frac{1}{r^2}=\\int_\\mbox{solid angle} R^2 d^2\\Omega \\frac{1}{R^2}=4\\pi$$\nSo you have a situation where your quantity is zero everywhere except one point, and at that one point, if you integrate your quantity, it gives a finite constant value = that's a delta function. You can do it with more rigour, but basically all you need is here, so:\n$$\\boldsymbol{\\nabla}.\\left(\\frac{\\boldsymbol{r}}{\\left|\\boldsymbol{r}\\right|^3}\\right)=4\\pi\\delta\\left(\\boldsymbol{r}\\right)$$\n\nHaving said it, your approach is strange. You are using magnetic field to find the magnetic dipole. I would go in the other direction. I would define magnetic dipole to be either delta-function of magnetization, or a current due to point-like loop of current (yet another way to go is to consider low-order series expansion of the relevant Greens function - will ignore here). The second approach is more fun, so let us go with it.\nAssume the current is circulating in anti-clockwise direction around the z-axis, in $z=0$ plane, and that loop radius is $R$. The current density is then (using cyllindrical coordinates $\\rho,\\phi,z$):\n$$\\mathbf{J}=\\alpha\\delta\\left(\\rho-R\\right)\\delta\\left(z\\right)\\boldsymbol{\\hat{\\phi}}$$\nIf the current through the loop is $I$, by integrating in $\\mathcal{P}=\\{y=0,x>0\\}$ plane we can find:\n$$I=\\int_\\mathcal{P}dx\\,dz\\,\\mathbf{\\hat{y}}.\\mathbf{J}=\\alpha \\int_0^\\infty d\\rho\\, \\delta\\left(\\rho-R\\right)=\\alpha$$\nThus $\\alpha=I$. As before, delta functions only make sense inside an integral, so let us stick our expression inside an integral with a arbitrary well-behaved vector field $\\mathbf{V}$:\n$$\\int_V d^3 r \\mathbf{V}.\\mathbf{J}=I\\int dz\\, \\int_0^\\infty d\\rho\\int_0^{2\\pi}\\rho\\,d\\phi V_\\phi \\delta\\left(\\rho-R\\right)\\delta\\left(z\\right) = I R\\int_0^{2\\pi}d\\phi \\,V_\\phi\\bigg|_{\\rho=R,\\,z=0}=I \\oint_{\\partial \\mathcal{D}} dl \\mathbf{\\hat{l}}.\\mathbf{V}=I \\int_{\\mathcal{D}} d^2\\rho \\mathbf{\\hat{z}}.\\boldsymbol{\\nabla}\\times\\mathbf{V}$$\nIn the penultimate step I have introduced a disk region ($\\mathcal{D}$) of radius $R$, lying in $z=0$ plane at the origin, and interpreted the integral as the integral around the boundary of that disk. We can then use the inverse of the Stokes theorem (which works in simply-connected space) and deduce the expression for the integral. We can now take the limit $R\\to 0$ to get:\n$$\\lim_{R\\to 0}\\int_V d^3 r \\mathbf{V}.\\mathbf{J}=I\\pi R^2 \\mathbf{\\hat{z}}.\\left(\\boldsymbol{\\nabla}\\times\\mathbf{V}\\right)\\bigg|_{\\mathbf{r}=0}$$\nAll that remains to show, by integration by parts, is that:\n$$\\int_V d^3 r \\mathbf{V}.\\boldsymbol{\\nabla}\\times\\mathbf{\\hat{z}}\\delta\\left(\\mathbf{r}\\right)=\\mathbf{\\hat{z}}.\\left(\\boldsymbol{\\nabla}\\times\\mathbf{V}\\right)\\bigg|_{\\mathbf{r}=0}$$\nThus, setting $\\mathbf{m}=\\mathbf{\\hat{z}}I\\pi R^2$:\n$$\\mathbf{J}=\\boldsymbol{\\nabla}\\times\\mathbf{m}\\delta\\left(\\mathbf{r}\\right)$$ \nwhere $\\mathbf{m}$ is a constant so it can be outside the derivative, there still seems to be sign mismatch. Because I have seen such problems before, I am inclined to think that my sign is correct, but I could be wrong.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/536989", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "4", "answer_count": 1, "answer_id": 0}}
{"Q": "Doubt in a property of Laplace equation One of the Laplace equation's property says that the maxima and minima can only occur at the boundaries.\nOkay so lets take 2 positive charges, one at the origin and the other $d$ distance apart on the $x$-axis.\nSo the potential between them would be somewhat like what I have drawn in the image.\n\nNow lets take a region between\n$x=d/3$ and $x=2d/3$. Now apply the Laplace equation here in the region, (as there is no charge in this region), and so the potential's maxima and minima should occur at the boundary. But its maxima occurs at $x=d/2$ ??\n", "A": "(Assuming that you're referring to the $3$D case and not the $1$D case).\nIn your example, $V(r)$ is not an extremum. Let's place two unit charges at $x = \\pm d/2$, and look at the resulting potential $V(x,y)$ (taking $V(r \\to \\infty) = 0$).\nAt $x = 0$, the potential is $V(0,0) = \\frac{2}{d} + \\frac{2}{d} = \\frac{4}{d}$\nAlong the $x$ axis (close to $x = 0$), we have\n\\begin{align}\nV(x=\\varepsilon, 0) &= \\frac{1}{\\frac{d}{2} + \\varepsilon} + \\frac{1}{\\frac{d}{2} - \\varepsilon}\\\\ &= \\frac{2}{d} \\left(\\frac{1}{1 + \\frac{2 \\varepsilon}{d}}  + \\frac{1}{1 - \\frac{2 \\varepsilon}{d}}\\right)\\\\\n&= \\frac{4}{d} \\left(1 + 4 \\frac{\\varepsilon^2}{d^2} + o\\left(\\frac{\\varepsilon^2}{d^2}\\right) \\right) > V(0, 0).\n\\end{align}\nBut along the y axis, we have:\n\\begin{align}\nV(x=0, y=\\varepsilon) &= \\frac{1}{\\sqrt{\\frac{d^2}{4} + \\varepsilon^2}} + \\frac{1}{\\sqrt{\\frac{d^2}{4} + \\varepsilon^2}}\\\\ &= \\frac{4}{d} \\frac{1}{\\sqrt{1 + \\frac{4 \\varepsilon^2}{d^2}}}\\\\\n&= \\frac{4}{d} \\left(1 - 2 \\frac{\\varepsilon^2}{d^2} + o\\left(\\frac{\\varepsilon}{d}^2\\right) \\right) < V(0, 0).\n\\end{align}\nSo while the partial derivative along $x$ and $y$ is indeed zero, this corresponds neither to a maximum nor a minimum of $V$ but rather to a saddle point.\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/575641", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "11", "answer_count": 4, "answer_id": 3}}
{"Q": "Computing Young's modulus of an ideal elastic substance using it's thermodinamic equation of state \nThe equation of state of an ideal elastic substance is:\n\\begin{equation}\n    \\mathcal{F} = KT \\left[\\left(\\frac{L}{L_0}\\right) - \\left(\\frac{L}{L_0}\\right)^{-2}\\right]\n  \\tag{1}\n  \\end{equation}\nWhere $K$ is a constant and $L_0$ (the value of $L$ at zero tension)\nis a function of temperature only ($L_0(T)$).\nShow that the isothermal Young's modulus is given by\n\\begin{equation}\n    Y = \\frac{\\mathcal{F}}{A} + \\frac{3KTL_0^2}{AL^2}\n    \\tag{2}\n \\end{equation}\nExersice 2.7.a of: Heat and Thermodynamics 7th Revised edition. Mark W. Zemansky; Richard H. Dittman\n\nIf:\n\\begin{equation}\n  Y = \\frac{L}{A}\\left(\\frac{\\partial \\mathcal{F}}{\\partial L}\\right)_T\n\\tag{3}\n\\end{equation}\nCan perform the derivative of equation 3 with equation 1 as:\n\\begin{equation}\n  \\begin{aligned}\n    \\mathcal{F} & = KT \\left[\\left(\\frac{L}{L_0}\\right)-\\left(\\frac{L}{L_0}\\right)^{-2}\\right] \\\\\n                & =  \\frac{KTL}{L_0} - \\frac{KTL_0^2}{L^2}\n  \\end{aligned}\n\\tag{4}\n\\end{equation}\nsubstituting 4 in 3, solvig the derivarives and reducing terms:\n\\begin{equation}\n  \\begin{aligned}\n    Y & = \\frac{L}{A} \\left(\\frac{\\partial}{\\partial L}\\right)_T\n    \\left[\\frac{KTL}{L_0} - \\frac{KTL_0^2}{L^2}    \\right]                                                                                                      \\\\\n      & = \\frac{L}{A} \\left[ \\left(\\frac{\\partial}{\\partial L} \\frac{KTL}{L_0}\\right)_T - \\left(\\frac{\\partial}{\\partial L}\\frac{KTL_0^2}{L^2}\\right)_T \\right] \\\\\n      & = \\frac{L}{A} \\left[\\frac{KT}{L_0} + \\frac{2KL_0^2T}{L^3}      \\right]                                                                                  \\\\                                                                                  \\\\\n      & = \\frac{L}{A} \\left[\\frac{KTL^3 + 2KL_0^3T}{L^3 L_0}      \\right]                                                                                       \\\\\n      & = \\frac{KTL^3 + 2KL_0^3T}{AL^2 L_0}                                                                                                                     \\\\\n      & = KT\\frac{L^3 +2L_0^3}{AL^2 L_0}                                                                                                                        \\\\\n      & = KT\\left[ \\frac{L}{AL_0} + \\frac{2L_0^2}{AL^2}      \\right]                                                                                            \\\\\n      & = \\frac{KTL}{AL_0} + \\frac{2KTL_0^2}{AL^2}                                                                                                              \\\\  \\end{aligned}\n\\end{equation}\nWhich:\n\\begin{equation}\n\\boxed{\n   \\frac{KTL}{AL_0} + \\frac{2KTL_0^2}{AL^2}  \\neq \\frac{\\mathcal{F}}{A} + \\frac{3KTL_0^2}{AL^2}\n}\n\\end{equation}\nThen just by solving the derivative $\\partial \\mathcal{F}/\\partial L$ of eq.3 in eq 1. leadsme to a path where I miss the term $\\mathcal{F}/A$ in eq. 2. That's where I think I'm missing something in the theory, which is what I'm looking for.\nEven if I can demostrate that:\n\\begin{equation}\n  \\mathcal{F} = \\frac{KTL}{L_0}\n\\end{equation}\nthen:\n\\begin{equation}\n\\boxed{\n   \\frac{\\mathcal{F}}{A} + \\frac{2KTL_0^2}{AL^2}  \\neq \\frac{\\mathcal{F}}{A} + \\frac{3KTL_0^2}{AL^2}\n}\n\\end{equation}\n", "A": "Chemomechanics answered your question, I am merely doing the algebra:\nYou say\n$$\n\\boxed{\n\\frac{k T L}{A L_0} + \\frac{2 k T L_0^2}{A L^2}\n\\neq\n\\frac{\\mathcal F}{A}+\\frac{3 k T L_0^2}{A L^2}\n}\n$$\nbut this is not true: From your Eq (1)\n$$\n   \\frac{\\mathcal F}{A} =\\frac{kT L}{AL_0}-\\frac{k T L_0^2}{L^2}\n$$\nThen\n$$\\boxed{\\boxed{\n  \\frac{\\mathcal F}{A} + \\frac{3 k T L_0^2}{A L^2} =\\frac{kT L}{AL_0}+ \\frac{2 k T L_0^2}{A L^2} \n}}\n$$\n", "meta": {"language": "en", "url": "https://physics.stackexchange.com/questions/724962", "timestamp": "2023-03-29", "source": "stackexchange", "question_score": "1", "answer_count": 1, "answer_id": 0}}
